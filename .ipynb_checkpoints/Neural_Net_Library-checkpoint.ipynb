{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as tdist\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from numpy import log, sqrt, exp\n",
    "import imageio\n",
    "from scipy.io import FortranFile\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.interpolate import CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlos = 65536\n",
      "65536 512 3.0 42807.71484375 400.0\n",
      "len(taured)= 33554432\n",
      "nlos,npix= 65536 512\n",
      "dasme\n",
      "(33554432,)\n",
      "shape of taured= (65536, 1, 512)\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "f = FortranFile('C:/Users/Lawrence Huang/Desktop/Research/z3taured.dat', 'r')\n",
    "nlos=int(np.asscalar(f.read_ints()))\n",
    "print(\"nlos = %d\" %nlos)\n",
    "npix=int(np.asscalar(f.read_ints()))\n",
    "zred=np.asscalar(f.read_record('f4'))\n",
    "blenkms=np.asscalar(f.read_record('f4'))\n",
    "blen=np.asscalar(f.read_record('f4'))*0.001  #back into mpc/h\n",
    "print(nlos,npix,zred,blenkms,blen)\n",
    "taured=[]\n",
    "nstep=1 #skipping through in steps of 1\n",
    "for i in range(0,nlos,nstep):       \n",
    "    tauredin=f.read_record('f4')\n",
    "    taured.extend(tauredin)\n",
    "f.close()\n",
    "print('len(taured)=',len(taured))\n",
    "\n",
    "nlos=int(nlos/nstep)\n",
    "\n",
    "print ('nlos,npix=',nlos,npix)\n",
    "\n",
    "taured=np.array(taured)\n",
    "\n",
    "taured=np.reshape(taured,(nlos,1,npix))\n",
    "alternativeTaured = np.reshape(taured, (256,256,1,npix))\n",
    "\n",
    "print('shape of taured=',taured.shape)\n",
    "# print(alternativeTaured[0,0] == taured[0])\n",
    "# print(alternativeTaured[1,1] == taured[257])\n",
    "# print(taured[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauTest = np.reshape(alternativeTaured[0:114,0:114],(114*114,1,512))\n",
    "tauValidate = np.reshape(alternativeTaured[-114:,-114:],(114*114,1,512))\n",
    "tauTrain = np.concatenate((\n",
    "               np.reshape(alternativeTaured[:114,114:],(114*(256-114),1,512)), \\\n",
    "               np.reshape(alternativeTaured[114:-114],(256*(256-2*114),1,512)), \\\n",
    "               np.reshape(alternativeTaured[-114:,:-114],(114*(256-114),1,512))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taured' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-849605079c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmintaured\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtaured\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmaxtaured\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtaured\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtaured\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtaured\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5e9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.e10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtauTest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtauTest\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5e9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.e10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'taured' is not defined"
     ]
    }
   ],
   "source": [
    "mintaured=taured.min()\n",
    "maxtaured=taured.max()\n",
    "taured[taured > 0.5e9] = -1.e10\n",
    "\n",
    "tauTest[tauTest > 0.5e9] = -1.e10\n",
    "tauValidate[tauValidate > 0.5e9] = -1.e10\n",
    "tauTrain[tauTrain > 0.5e9] = -1.e10\n",
    "\n",
    "maxtaured=taured.max()\n",
    "print (maxtaured)\n",
    "# set to realistic max:\n",
    "\n",
    "taured[taured < -0.5e9] = maxtaured\n",
    "tauTest[tauTest < -0.5e9] = maxtaured\n",
    "tauValidate[tauValidate < -0.5e9] = maxtaured\n",
    "tauTrain[tauTrain < -0.5e9] = maxtaured\n",
    "\n",
    "#SCALING\n",
    "\n",
    "# taured=(((taured-mintaured)/(maxtaured-mintaured))*0.98)+0.01\n",
    "# tauTest=(((tauTest-mintaured)/(maxtaured-mintaured))*0.98)+0.01\n",
    "# tauValidate=(((tauValidate-mintaured)/(maxtaured-mintaured))*0.98)+0.01\n",
    "# tauTrain=(((tauTrain-mintaured)/(maxtaured-mintaured))*0.98)+0.01\n",
    "\n",
    "\n",
    "\n",
    "flux=np.exp(-1.*taured)\n",
    "fluxTest = np.exp(-1.*tauTest)\n",
    "fluxValidate = np.exp(-1.*tauValidate)\n",
    "fluxTrain = np.exp(-1.*tauTrain)\n",
    "\n",
    "signalRMS = np.std(flux)\n",
    "\n",
    "rmsnoise=signalRMS/10 #this is the rms noise to add - if it's zero then we are try \n",
    "bignoise=signalRMS/5\n",
    "hugenoise=signalRMS/2.5\n",
    "# 1 is the mean of the normal distribution you are choosing from\n",
    "# 2 is the standard deviation of the normal distribution\n",
    "# 3 is the number of elements you get in array noise\n",
    "\n",
    "#SCALING\n",
    "\n",
    "# minflux=flux.min()\n",
    "# maxflux=flux.max()\n",
    "# flux=(((flux-minflux)/(maxflux-minflux))*0.98)+0.01\n",
    "# fluxTest=(((fluxTest-minflux)/(maxflux-minflux))*0.98)+0.01\n",
    "# fluxValidate=(((fluxValidate-minflux)/(maxflux-minflux))*0.98)+0.01\n",
    "# fluxTrain=(((fluxTrain-minflux)/(maxflux-minflux))*0.98)+0.01\n",
    "\n",
    "fluxRMS = np.std(flux)\n",
    "print(\"fluxRMS\", fluxRMS)\n",
    "\n",
    "# noise = np.random.normal(0.0,rmsnoise,(nlos,npix))\n",
    "# flux=flux+noise\n",
    "\n",
    "# noiseTest = np.random.normal(0.0,rmsnoise,fluxTest.shape)\n",
    "# bigNoiseTest = np.random.normal(0.0,bignoise,fluxTest.shape)\n",
    "# hugeNoiseTest = np.random.normal(0.0,hugenoise,fluxTest.shape)\n",
    "\n",
    "# bigNoiseFluxTest = fluxTest + bigNoiseTest\n",
    "# hugeNoiseFluxTest = fluxTest + hugeNoiseTest\n",
    "# fluxTest=fluxTest+noiseTest\n",
    "\n",
    "# noiseValidate = np.random.normal(0.0,rmsnoise,fluxValidate.shape)\n",
    "# bigNoiseValidate = np.random.normal(0.0,bignoise,fluxValidate.shape)\n",
    "# hugeNoiseValidate = np.random.normal(0.0,hugenoise,fluxValidate.shape)\n",
    "\n",
    "# bigNoiseFluxValidate = fluxValidate + bigNoiseValidate\n",
    "# hugeNoiseFluxValidate = fluxValidate + hugeNoiseValidate\n",
    "# fluxValidate=fluxValidate+noiseValidate\n",
    "\n",
    "# noiseTrain = np.random.normal(0.0,rmsnoise,fluxTrain.shape)\n",
    "# bigNoiseTrain = np.random.normal(0.0,bignoise,fluxTrain.shape)\n",
    "# hugeNoiseTrain = np.random.normal(0.0,hugenoise,fluxTrain.shape)\n",
    "\n",
    "# bigNoiseFluxTrain = fluxTrain + bigNoiseTrain\n",
    "# hugeNoiseFluxTrain = fluxTrain + hugeNoiseTrain\n",
    "# fluxTrain=fluxTrain+noiseTrain\n",
    "\n",
    "\n",
    "taured = torch.from_numpy(taured)\n",
    "tauTest = torch.from_numpy(tauTest)\n",
    "tauValidate = torch.from_numpy(tauValidate)\n",
    "tauTrain = torch.from_numpy(tauTrain)\n",
    "\n",
    "flux = torch.from_numpy(flux)\n",
    "fluxTest = torch.from_numpy(fluxTest)\n",
    "fluxValidate = torch.from_numpy(fluxValidate)\n",
    "fluxTrain = torch.from_numpy(fluxTrain)\n",
    "# bigNoiseFluxTest = torch.from_numpy(bigNoiseFluxTest)\n",
    "# hugeNoiseFluxTest = torch.from_numpy(hugeNoiseFluxTest)\n",
    "# bigNoiseFluxTrain = torch.from_numpy(bigNoiseFluxTrain)\n",
    "# hugeNoiseFluxTrain = torch.from_numpy(hugeNoiseFluxTrain)\n",
    "# bigNoiseFluxValidate = torch.from_numpy(bigNoiseFluxValidate)\n",
    "# hugeNoiseFluxValidate = torch.from_numpy(hugeNoiseFluxValidate)\n",
    "\n",
    "# cleanFluxTest = torch.from_numpy(cleanFluxTest)\n",
    "# cleanFluxTrain = torch.from_numpy(cleanFluxTrain)\n",
    "# cleanFluxValidate = torch.from_numpy(cleanFluxValidate)\n",
    "\n",
    "tauredzero=taured[0,0,...]\n",
    "\n",
    "fluxzero=flux[0,0,...]\n",
    "\n",
    "#orange is the flux and blue is the optical depth, both scaled to 0.01-0.99\n",
    "plt.plot(tauredzero.numpy())\n",
    "plt.plot(fluxzero.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tauredTest = taured[480:,...]\n",
    "# fluxTest = flux[480:,...]\n",
    "# tauredTrain = taured[:480,...]\n",
    "# fluxTrain = flux[:480,...]\n",
    "# print(tauredTest.shape)\n",
    "# print(fluxTest.shape)\n",
    "# print(tauredTrain.shape)\n",
    "# print(fluxTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-17-087df0587740>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-087df0587740>\"\u001b[1;36m, line \u001b[1;32m42\u001b[0m\n\u001b[1;33m    indices = torch.randint(low=0,high=tauTrain.shape[0],size=(num,))\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def onePointTrainSplit(num):\n",
    "    indices = torch.randint(low=0,high=tauTrain.shape[0],size=(num,))\n",
    "    return tauTrain[indices,0,256], fluxTrain[indices,0,...]\n",
    "\n",
    "def fullTrainSplit(num):\n",
    "    indices = torch.randint(low=0,high=tauTrain.shape[0],size=(num,))\n",
    "    return tauTrain[indices,0,...], fluxTrain[indices,0,...]\n",
    "\n",
    "# def revolveTrainSplit(tauredSet, fluxSet, num):\n",
    "#     indices = torch.randint(low=0,high=tauredSet.shape[0],size=(num,))\n",
    "#     taus = torch.zeros((512*num))\n",
    "#     fluxs = torch.zeros((512*num,512))\n",
    "#     counter = 0\n",
    "#     tempFlux = torch.zeros((1024,))\n",
    "#     for i in range(num):\n",
    "#         for midpoint in range(512):\n",
    "#             taus[512*i + midpoint] = tauredSet[indices[i],midpoint]\n",
    "#             tempFlux[0:512] = fluxSet[indices[i],...]\n",
    "#             tempFlux[512:] = fluxSet[indices[i],...]\n",
    "#             fluxs[512*i+midpoint,...] = tempFlux[midpoint:512+midpoint]\n",
    "#     return taus, fluxs\n",
    "\n",
    "def revolveTrainSplit(num):\n",
    "    indices = torch.randint(low=0,high=tauTrain.shape[0],size=(num,))\n",
    "    taus = torch.zeros((512*num))\n",
    "    fluxs = torch.zeros((512*num,512))\n",
    "    counter = 0\n",
    "    taus = torch.flatten(tauTrain[indices])\n",
    "    for i in range(num):\n",
    "        for midpoint in range(512):\n",
    "            fluxs[512*i+midpoint,...] = torch.cat((fluxTrain[indices[i],midpoint-256:],fluxTrain[indices[i],:midpoint-256]),dim=0)\n",
    "    return taus, fluxs\n",
    "\n",
    "noiseDict = {\n",
    "    \"none\": 0,\n",
    "    \"low\": 1/10,\n",
    "    \"mid\": 1/5,\n",
    "    \"high\": 1/2.5\n",
    "}\n",
    "\n",
    "def trueRandomRevolve(num, noise=\"low\", source=\"train\"):\n",
    "    if source == \"test\":\n",
    "        tSet = tauTest\n",
    "        fSet = fluxTest\n",
    "    elif source == \"validate\":\n",
    "        tSet = tauValidate\n",
    "        fSet = fluxValidate\n",
    "    elif source == \"train\":\n",
    "        tSet = tauTrain\n",
    "        fSet = fluxTrain\n",
    "    indices = torch.randint(low=0,high=tSet.shape[0],size=(num,))\n",
    "    points = torch.randint(low=0,high=512,size=(num,))\n",
    "    taus = torch.zeros((num))\n",
    "    fluxs = torch.zeros(num,512)\n",
    "    for i in range(num):\n",
    "        fluxs[i] = spin(fSet[indices[i],0], points[i])\n",
    "        taus[i] = tSet[indices[i],0,points[i]]\n",
    "    fluxs += torch.from_numpy(np.random.normal(0.0,signalRMS*noiseDict[noise],fluxs.shape))\n",
    "    return taus, fluxs\n",
    "\n",
    "def validate(noise=\"low\"):\n",
    "    tSet = tauValidate\n",
    "    fSet = fluxValidate\n",
    "    size = len(torch.flatten(tSet))\n",
    "    taus = torch.zeros((size*512))\n",
    "    fluxs = torch.zeros((size*512, 512))\n",
    "    for i in range(size*512):\n",
    "        taus[i] = tSet[i//512,0,i%512]\n",
    "        fluxs[i] = spin(fSet[i//512, 0], i%512)\n",
    "    fluxs += torch.from_numpy(np.random.normal(0.0,signalRMS*noiseDict[noise],fluxs.shape))\n",
    "    return taus, fluxs\n",
    "    \n",
    "def spin(tensor, midpoint):\n",
    "    return torch.cat((tensor[midpoint-256:],tensor[:midpoint-256]),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spin function works\n",
      "torch.Size([50])\n",
      "torch.Size([50, 512])\n"
     ]
    }
   ],
   "source": [
    "def spinTest():\n",
    "    a = torch.arange(512)\n",
    "    for i in range(512):\n",
    "        assert(spin(a,i)[256] == i)\n",
    "#         print(\"Passed test %d/512\" %(i+1))\n",
    "    print(\"The spin function works\")\n",
    "    \n",
    "spinTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Point Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnePointConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OnePointConvNet, self).__init__()\n",
    "        self.hidden1 = torch.nn.Conv1d(1, 3, 5)   # hidden layer\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.hidden2 = torch.nn.Linear(504,1000)\n",
    "        self.hidden3 = torch.nn.Linear(1000, 2000)\n",
    "        self.hidden4 = torch.nn.Linear(2000, 2500)\n",
    "        self.hidden5 = torch.nn.Linear(2500,3200)\n",
    "        self.hidden6 = torch.nn.Linear(3200,4800)\n",
    "        self.hidden7 = torch.nn.Conv1d(3,1,11)\n",
    "        self.predict = torch.nn.Linear(4790, 1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = F.relu(self.hidden4(x))\n",
    "        x = F.relu(self.hidden5(x))\n",
    "        x = F.relu(self.hidden6(x))\n",
    "        x = F.relu(self.hidden7(x))\n",
    "        x = self.predict(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Regression (Formerly Linear Regression, was used to find slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        self.hidden1 = torch.nn.Conv1d(1, 2, 5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.lin1 = torch.nn.Linear(504,768)\n",
    "        self.lin2 = torch.nn.Linear(768,1024)\n",
    "        self.hidden2 = torch.nn.Conv1d(2,1,1)\n",
    "        self.predict = torch.nn.Linear(1024,512)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMidpoint(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMidpoint, self).__init__()\n",
    "        self.hidden1 = torch.nn.Conv1d(1, 2, 5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.lin1 = torch.nn.Linear(504,64)\n",
    "        self.lin2 = torch.nn.Linear(64,8)\n",
    "        self.hidden2 = torch.nn.Conv1d(2,1,1)\n",
    "        self.predict = torch.nn.Linear(8,1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "#         x = x.view((-1,1,16))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreConvolution1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MoreConvolution1, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1, 4, 5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.lin1 = torch.nn.Linear(504,64)\n",
    "        self.lin2 = torch.nn.Linear(64,8)\n",
    "#         self.hidden2 = torch.nn.Conv1d(4,1,1)\n",
    "        self.predict = torch.nn.Linear(32,1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "#         x = F.relu(self.hidden2(x))\n",
    "        x = x.view((-1,1,32))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "    \n",
    "class MoreConvolution2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MoreConvolution2, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1, 4, 5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.lin1 = torch.nn.Linear(504,64)\n",
    "        self.lin2 = torch.nn.Linear(64,8)\n",
    "        self.predict = torch.nn.Linear(32,1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deeper(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Deeper, self).__init__()\n",
    "        self.hidden1 = torch.nn.Conv1d(1, 4, 5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.lin1 = torch.nn.Linear(504,128)\n",
    "        self.lin2 = torch.nn.Linear(128,32)\n",
    "        self.lin3 = torch.nn.Linear(32,4)\n",
    "        self.lin4 = torch.nn.Linear(4,1)\n",
    "        self.predict = torch.nn.Linear(4,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.relu(self.lin3(x))\n",
    "        x = F.relu(self.lin4(x))\n",
    "        x = x.view((-1,1,4))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "class BigBrain(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BigBrain, self).__init__()\n",
    "        self.hidden1 = torch.nn.Conv1d(1, 4, 5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.lin1 = torch.nn.Linear(504,64)\n",
    "        self.lin2 = torch.nn.Linear(64,120)\n",
    "        self.hidden2 = torch.nn.Linear(120,30)\n",
    "        self.hidden3 = torch.nn.Linear(30,5)\n",
    "        self.hidden4 = torch.nn.Linear(5, 1)\n",
    "        self.predict = torch.nn.Linear(4,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "#         x = x.view((-1,1,16))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = F.relu(self.hidden4(x))\n",
    "        x = x.view((-1,1,4))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.6931, 1.0986, 1.0986, 1.0986])\n"
     ]
    }
   ],
   "source": [
    "def trueLog(a):\n",
    "    x = []\n",
    "    y = []\n",
    "    n = len(a)\n",
    "    for i in range(n):\n",
    "        if a[i] > 0:\n",
    "            x.append(i)\n",
    "            y.append(-log(a[i]))\n",
    "            \n",
    "    func = CubicSpline(x,y)\n",
    "    desiredXs = np.arange(n)\n",
    "    result = func(desiredXs)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-ee14053a9db2>, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-ee14053a9db2>\"\u001b[1;36m, line \u001b[1;32m52\u001b[0m\n\u001b[1;33m    prediction = self.net(fluxs[512*i:512*(i+1)])\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "netDictionary = {\n",
    "#     \"OnePointConvNet\": OnePointConvNet,     DEPRECATED\n",
    "#     \"SimpleConvNet\": SimpleConvNet,         DEPRECATED\n",
    "    \"SimpleMidpoint\": SimpleMidpoint,\n",
    "    \"MoreConvolution1\": MoreConvolution1,\n",
    "    \"MoreConvolution2\": MoreConvolution2,\n",
    "    \"Deeper\": Deeper,\n",
    "    \"BigBrain\": BigBrain\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class NetFactory():\n",
    "    def __init__(self, netType, printAll = True):\n",
    "        self.netType = netType\n",
    "        self.net = netDictionary[netType]()\n",
    "        self.printAll = printAll\n",
    "        \n",
    "        \n",
    "    #to test\n",
    "    def onePointValidate(self):\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        \n",
    "        loss = np.zeros(32)\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i in range(32):\n",
    "                y = fluxTest[i,...].float()\n",
    "                y = torch.reshape(y, (-1,1,512))\n",
    "                prediction = self.net(y)\n",
    "                loss[i] = loss_func(prediction, tauTest[i,0,256].float())\n",
    "        self.net.train()\n",
    "        return np.mean(loss)\n",
    "    \n",
    "    def fullTest(self, noise):\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        fluxs = torch.zeros((fluxTest.shape[0]*512,1,512))\n",
    "        taus = torch.zeros((fluxTest.shape[0]*512,1,1))\n",
    "        noiseGen =  torch.distributions.normal.Normal(0.0, signalRMS*noiseDict[noise], validate_args=None)\n",
    "        for i in range(fluxTest.shape[0]):\n",
    "            for midpoint in range(512):\n",
    "                fluxs[512*i+midpoint,0] = spin(fluxTest[i,0], midpoint) + noiseGen.sample((512,)).view((1,1,512))\n",
    "                taus[512*i+midpoint,0] = tauTest[i,0,midpoint]\n",
    "        fluxs = fluxs.float()\n",
    "        loss = torch.zeros(fluxTest.shape[0])\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(fluxTest.shape[0]):\n",
    "                prediction = self.net(fluxs[512*i:512*(i+1)])\n",
    "                loss[i] = loss_func(prediction, taus[512*i:512*(i+1)])\n",
    "        self.net.train()\n",
    "        return loss.mean()\n",
    "    \n",
    "     \n",
    "    def randomRevolveRun(self, epochs, learningRate, noise=\"low\"):\n",
    "        now = datetime.now()\n",
    " \n",
    "        print(\"now =\", now)\n",
    "        \n",
    "        writer = SummaryWriter()\n",
    "        \n",
    "        writer.add_text(\"Net\", str(self.net))\n",
    "        writer.add_text(\"Epochs\", str(epochs))\n",
    "        writer.add_text(\"Learning Rate\", str(learningRate))\n",
    "        \n",
    "        optimizer = torch.optim.Adam( self.net.parameters(), learningRate, weight_decay=0.0005 )\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 50, gamma=1)\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        \n",
    "        allSame = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            \n",
    "            tauSet,fluxSet = trueRandomRevolve(1000, noise)\n",
    "            tauSet = tauSet.float()\n",
    "            fluxSet = fluxSet.float()\n",
    "            tauSet = torch.reshape(tauSet, (-1,1,1))\n",
    "            fluxSet = torch.reshape(fluxSet, (-1,1,512))\n",
    "            \n",
    "            prediction = self.net(fluxSet)\n",
    "            if torch.std(prediction) < 0.00006:\n",
    "                print(\"std = \", torch.std(prediction))\n",
    "                print(\"They're all\", prediction[1])\n",
    "                allSame += 1\n",
    "                if allSame > 50:\n",
    "                    return 0\n",
    "            else:\n",
    "                allSame == 0\n",
    "                \n",
    "            \n",
    "            \n",
    "            loss = loss_func(prediction, tauSet)     # must be (1. nn output, 2. target)\n",
    "            optimizer.zero_grad()   # clear gradients for next train\n",
    "            loss.backward()         # backpropagation, compute gradients\n",
    "            optimizer.step()        # apply gradients\n",
    "            scheduler.step()        # scheduler decreases learning rate geometrically every n epochs\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            writer.add_scalar('Loss/train', loss, epoch)\n",
    "            \n",
    "            if epoch % 1000 == 0:\n",
    "                hundredth = plt.figure()\n",
    "                a = torch.flatten(tauSet)\n",
    "                b = torch.flatten(prediction)\n",
    "                plt.title(\"%dth epoch predictions\" %epoch)\n",
    "                plt.plot(a,\"r\", label=\"actual\")\n",
    "                plt.plot(b.detach().numpy(),\"g.\", label=\"prediction\")\n",
    "                plt.show()\n",
    "                writer.add_figure(\"Every Hundred Epochs\", hundredth)\n",
    "                \n",
    "                testLoss = self.fullTest(noise)\n",
    "                writer.add_scalar('Loss/test', testLoss, epoch)\n",
    "#             for i in self.net.__dict__['_modules']:\n",
    "#                 if i[0:4] != \"pool\":\n",
    "#                     writer.add_histogram(i + '/weight', getattr(self.net, i).weight.grad, epoch)\n",
    "#                     writer.add_histogram(i + '/bias', getattr(self.net, i).bias.grad, epoch)\n",
    "            \n",
    "            if self.printAll:\n",
    "                print(\"Epoch = \", epoch)\n",
    "                print(\"Training Loss = \", loss)\n",
    "                if epoch % 1000 == 0:\n",
    "                    print(\"Test Loss = \", testLoss)\n",
    "                    \n",
    "            \n",
    "\n",
    "#         a = tauSet.view((48,1))\n",
    "#         b = fluxSet.view((48,512))\n",
    "#         c = prediction.view((48,1))\n",
    "#         testResults = plt.figure()\n",
    "#         plt.plot(a.data.cpu().numpy(), \"r\", label=\"actual\")\n",
    "#         plt.title(\"prediction vs actual value\")\n",
    "#         plt.plot(c.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "#         expPred = -np.log(b.data.cpu().numpy())\n",
    "#         newExpPred = expPred[...,256]\n",
    "#         plt.plot(newExpPred, 'b', label=\"exp\")\n",
    "#         plt.ylabel(\"Tau\")\n",
    "#         plt.xlabel(\"Sample #\")\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        \n",
    "        \n",
    "#         writer.add_figure(\"Test Results\", testResults)\n",
    "        \n",
    "#         taus, fluxs = trueRandomRevolve(100)\n",
    "        taus = tauValidate[0,0,...]\n",
    "        fluxs = torch.zeros((512,1,512))\n",
    "        for i in range(512):\n",
    "            fluxs[i] = spin(fluxValidate[0,0,...],i)\n",
    "        taus = taus.float()\n",
    "        fluxs = fluxs.float()\n",
    "        taus = torch.reshape(taus, (-1,1,1))\n",
    "        fluxs = torch.reshape(fluxs, (-1,1,512))\n",
    "        prediction = self.net(fluxs)\n",
    "        prediction = torch.flatten(prediction)\n",
    "        taus = torch.flatten(taus)\n",
    "        logPrediction = trueLog(torch.flatten(fluxs[256,0]))\n",
    "                                       \n",
    "        example = plt.figure()\n",
    "        \n",
    "        plt.plot(taus.data.cpu().numpy(), \"r\", label=\"actual\")\n",
    "        plt.plot(prediction.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "        plt.plot(logPrediction, \"b\", label=\"log and cubic splines\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        writer.add_figure(\"One Sightline\", example)\n",
    "        \n",
    "        difference = plt.figure()\n",
    "        plt.plot(prediction.data.cpu().numpy()-taus.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "        plt.plot(logPrediction-taus.data.cpu().numpy(), \"b\", label=\"log and cubic splines\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Difference\")\n",
    "        plt.show()\n",
    "        writer.add_figure(\"Difference\", difference)\n",
    "        \n",
    "        fracDifference = plt.figure()\n",
    "        plt.plot((prediction.data.cpu().numpy()-taus.data.cpu().numpy())/taus.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "        plt.plot((logPrediction-taus.data.cpu().numpy())/taus.data.cpu().numpy(), \"b\", label=\"log and cubic splines\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Fractional Difference\")\n",
    "        plt.show()\n",
    "        writer.add_figure(\"Fractional Difference\", fracDifference)\n",
    "        \n",
    "#         taus, fluxs = validate(noise)\n",
    "        taus, fluxs = trueRandomRevolve(10000, noise, source=\"validate\")\n",
    "        taus = taus.float()\n",
    "        fluxs = fluxs.float()\n",
    "        taus = torch.reshape(taus, (-1,1,1))\n",
    "        fluxs = torch.reshape(fluxs, (-1,1,512))\n",
    "\n",
    "        prediction = self.net(fluxs)\n",
    "        \n",
    "        a = torch.flatten(taus).detach().cpu().numpy()\n",
    "        b = torch.flatten(prediction).detach().cpu().numpy()\n",
    "        logP = trueLog(torch.flatten(fluxs))\n",
    "        logP = logP[256::512]\n",
    "        pearsonCoeff = pearsonr(a,b)\n",
    "        if pearsonCoeff[0] != pearsonCoeff[0]:\n",
    "            return 0\n",
    "        print(\"Pearson's Coefficient is:\")\n",
    "        print(pearsonCoeff)\n",
    "        print(\"Compared to log:\")\n",
    "        print(pearsonr(a,logP))\n",
    "        \n",
    "        c = np.zeros(a.shape)\n",
    "        \n",
    "        newA = np.where(a>1.5, a, c)\n",
    "        newB = np.where(a>1.5, b, c)\n",
    "        newLogP = np.where(a>1.5, logP, c)\n",
    "        newA = newA[np.nonzero(newA)]\n",
    "        newB = newB[np.nonzero(newB)]\n",
    "        highA = np.copy(newA)\n",
    "        highB = np.copy(newB)\n",
    "        newLogP = newLogP[np.nonzero(newLogP)]\n",
    "        print(\"Pearson's Coefficient for high numbers\")\n",
    "        print(pearsonr(newA,newB))\n",
    "        print(\"Compared to log:\")\n",
    "        print(pearsonr(newA,newLogP))\n",
    "        \n",
    "        \n",
    "        print(\"percent high:\")\n",
    "        print(len(newA)/len(a))\n",
    "        \n",
    "        newA = np.where(a<1.5, a, c)\n",
    "        newB = np.where(a<1.5, b, c)\n",
    "        newLogP = np.where(a<1.5, logP, c)\n",
    "        newA = newA[np.nonzero(newA)]\n",
    "        newB = newB[np.nonzero(newB)]\n",
    "        newLogP = newLogP[np.nonzero(newLogP)]\n",
    "        print(\"Pearson's Coefficient for low numbers\")\n",
    "        print(pearsonr(newA,newB))\n",
    "        print(\"Compared to log:\")\n",
    "        print(pearsonr(newA,newLogP))\n",
    "        \n",
    "        print(\"percent low:\")\n",
    "        print(len(newA)/len(a))\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.scatter(a,b)\n",
    "        plt.title(\"Scatter plot of Prediction vs Tau\")\n",
    "        plt.ylabel(\"Prediction\")\n",
    "        plt.xlabel(\"Tau\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(highA[:100], \"r\", label=\"Tau\")\n",
    "        plt.plot(highB[:100], \"g\", label=\"Prediction\")\n",
    "        plt.title(\"High values of Tau vs Prediction\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        return 1\n",
    "        \n",
    "    def averageLoss(self):\n",
    "        \n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        \n",
    "        lossList = torch.zeros(100)\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for epoch in range(100):\n",
    "                tauSet,fluxSet = trueRandomRevolve(1000)\n",
    "                tauSet = tauSet.float()\n",
    "                fluxSet = fluxSet.float()\n",
    "                tauSet = torch.reshape(tauSet, (-1,1,1))\n",
    "                fluxSet = torch.reshape(fluxSet, (-1,1,512))\n",
    "\n",
    "                prediction = self.net(fluxSet)\n",
    "\n",
    "                loss = loss_func(prediction, tauSet)     # must be (1. nn output, 2. target)\n",
    "                lossList[epoch] = loss\n",
    "            \n",
    "        self.net.train()\n",
    "        return torch.mean(lossList)\n",
    "    \n",
    "    def judgement(self):\n",
    "#         size = tauValidate.shape[0]*512\n",
    "        size = 1000*512\n",
    "        taus = torch.zeros((size))\n",
    "        fluxs = torch.zeros(size,512)\n",
    "        for i in range(size):\n",
    "            sight = size//512\n",
    "            midpoint = size % 512\n",
    "            fluxs[i] = spin(fluxTrain[sight,0], midpoint)\n",
    "            taus[i] = tauTrain[sight,0,midpoint]\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        \n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            taus = taus.float()\n",
    "            fluxs = fluxs.float()\n",
    "            taus = torch.reshape(taus, (-1,1,1))\n",
    "            fluxs = torch.reshape(fluxs, (-1,1,512))\n",
    "\n",
    "            prediction = self.net(fluxs)\n",
    "\n",
    "            loss = loss_func(prediction, taus)     # must be (1. nn output, 2. target)\n",
    "            a = torch.flatten(taus)\n",
    "            b = torch.flatten(prediction)\n",
    "            pearsonCoeff = pearsonr(a.detach().cpu().numpy(), b.detach().cpu().numpy())\n",
    "        self.net.train()\n",
    "        if pearsonCoeff[0] != pearsonCoeff[0]:\n",
    "            return 0\n",
    "        else:\n",
    "            return pearsonCoeff[0]\n",
    "        \n",
    "    def hybridResults(self, noise=\"low\", low = 0.8):\n",
    "        print(\"Noise:\")\n",
    "        print(noise)\n",
    "        print(\"Low:\")\n",
    "        print(low)\n",
    "#         taus, fluxs = trueRandomRevolve(10000, noise, source=\"validate\")\n",
    "        taus, fluxs = trueRandomRevolve(1000, noise, source=\"validate\")\n",
    "        taus = taus.float()\n",
    "        fluxs = fluxs.float()\n",
    "        taus = torch.reshape(taus, (-1,1,1))\n",
    "        fluxs = torch.reshape(fluxs, (-1,1,512))\n",
    "\n",
    "        prediction = self.net(fluxs)\n",
    "        \n",
    "        a = torch.flatten(taus).detach().cpu().numpy()\n",
    "        b = torch.flatten(prediction).detach().cpu().numpy()\n",
    "        logP = trueLog(torch.flatten(fluxs))\n",
    "        logP = logP[256::512]\n",
    "        for i in range(len(b)):\n",
    "            if logP[i] < low:\n",
    "                b[i] = logP[i]\n",
    "        pearsonCoeff = pearsonr(a,b)\n",
    "        print(\"Pearson's Coefficient is:\")\n",
    "        print(pearsonCoeff)\n",
    "        print(\"Compared to log:\")\n",
    "        print(pearsonr(a,logP))\n",
    "        \n",
    "        c = np.zeros(a.shape)\n",
    "        \n",
    "        newA = np.where(a>1.5, a, c)\n",
    "        newB = np.where(a>1.5, b, c)\n",
    "        newLogP = np.where(a>1.5, logP, c)\n",
    "        newA = newA[np.nonzero(newA)]\n",
    "        newB = newB[np.nonzero(newB)]\n",
    "        newLogP = newLogP[np.nonzero(newLogP)]\n",
    "        print(\"Pearson's Coefficient for high numbers\")\n",
    "        print(pearsonr(newA,newB))\n",
    "        print(\"Compared to log:\")\n",
    "        print(pearsonr(newA,newLogP))\n",
    "        \n",
    "        \n",
    "        print(\"percent high:\")\n",
    "        print(len(newA)/len(a))\n",
    "        \n",
    "        newA = np.where(a<1.5, a, c)\n",
    "        newB = np.where(a<1.5, b, c)\n",
    "        newLogP = np.where(a<1.5, logP, c)\n",
    "        newA = newA[np.nonzero(newA)]\n",
    "        newB = newB[np.nonzero(newB)]\n",
    "        newLogP = newLogP[np.nonzero(newLogP)]\n",
    "        print(\"Pearson's Coefficient for low numbers\")\n",
    "        print(pearsonr(newA,newB))\n",
    "        print(\"Compared to log:\")\n",
    "        print(pearsonr(newA,newLogP))\n",
    "        \n",
    "        print(\"percent low:\")\n",
    "        print(len(newA)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.618033988749895\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NetFactory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-7f6e7280691e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mnet1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandomRevolveRun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mfindIdealLearningRate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-7f6e7280691e>\u001b[0m in \u001b[0;36mfindIdealLearningRate\u001b[1;34m(runs)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.002\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mnet1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SimpleMidpoint\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mnet2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SimpleMidpoint\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnet3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SimpleMidpoint\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NetFactory' is not defined"
     ]
    }
   ],
   "source": [
    "def findIdealLearningRate(runs):\n",
    "    epochs = 10000\n",
    "    phi = (sqrt(5) + 1)/2\n",
    "    print(phi)\n",
    "#     x1 = log(0.0002)\n",
    "#     x4 = log(0.002)\n",
    "    x1 = log(0.000002)\n",
    "    x4 = log(1)\n",
    "    x2 = x1 + (x4 - x1)/phi\n",
    "    x3 = x4 - (x4 - x1)/phi\n",
    "    net1 = NetFactory(\"SimpleMidpoint\", False)\n",
    "    net2 = NetFactory(\"SimpleMidpoint\", False)\n",
    "    net3 = NetFactory(\"SimpleMidpoint\", False)\n",
    "    net4 = NetFactory(\"SimpleMidpoint\", False)\n",
    "    while net1.randomRevolveRun(epochs,exp(x1)) == 0:\n",
    "        \n",
    "        net1 = NetFactory(\"SimpleMidpoint\", False)\n",
    "        \n",
    "    while net2.randomRevolveRun(epochs,exp(x2)) == 0:\n",
    "        \n",
    "        net2 = NetFactory(\"SimpleMidpoint\", False)\n",
    "        \n",
    "    while net3.randomRevolveRun(epochs,exp(x3)) == 0:\n",
    "        \n",
    "        net3 = NetFactory(\"SimpleMidpoint\", False)\n",
    "        \n",
    "    while net4.randomRevolveRun(epochs,exp(x4)) == 0:\n",
    "        \n",
    "        net4 = NetFactory(\"SimpleMidpoint\", False)\n",
    "    l1 = net1.judgement()\n",
    "    l2 = net2.judgement()\n",
    "    l3 = net3.judgement()\n",
    "    l4 = net4.judgement()\n",
    "    for i in range(runs):\n",
    "        print(\"PEARSON COEFFICIENTS IN ORDER\")\n",
    "        print(l1, exp(x1))\n",
    "        print(l2, exp(x2))\n",
    "        print(l3, exp(x3))\n",
    "        print(l4, exp(x4))\n",
    "        if l2 > l3:\n",
    "            x4 = x3\n",
    "            x3 = x2\n",
    "            newx = x1 + (x4 - x1)/phi\n",
    "            newPos = \"2\"\n",
    "        else:\n",
    "            x1 = x2\n",
    "            x2 = x3\n",
    "            newx = x4 - (x4 - x1)/phi\n",
    "            newPos = \"3\"\n",
    "        newNet = NetFactory(\"SimpleMidpoint\", False)\n",
    "        while newNet.randomRevolveRun(epochs,exp(newx)) == 0:\n",
    "            newNet = NetFactory(\"SimpleMidpoint\", False)\n",
    "        newLoss = newNet.judgement()\n",
    "        if newPos == \"2\":\n",
    "            x2 = newx\n",
    "            l2 = newLoss\n",
    "        elif newPos == \"3\":\n",
    "            x3 = newx\n",
    "            l3 = newLoss\n",
    "    minLoss = min(l1,l2,l3,l4)\n",
    "    print(\"The Ideal Learning Rate\")\n",
    "    if minLoss == l1:\n",
    "        return exp(x1)\n",
    "    elif minLoss == l2:\n",
    "        return exp(x2)\n",
    "    elif minLoss == l3:\n",
    "        return exp(x3)\n",
    "    else:\n",
    "        return exp(x4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
