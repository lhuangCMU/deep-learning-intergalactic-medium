{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note this file is obsolete (the code in package lyman_alpha_reconstruction was previously written in Neural_Net_Library.ipynb and Master.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlos = 65536\n",
      "65536 512 3.0 42807.71484375 400.0\n",
      "len(taured)= 33554432\n",
      "nlos,npix= 65536 512\n",
      "shape of taured= (65536, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributions as tdist\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from numpy import log, sqrt, exp\n",
    "import imageio\n",
    "from scipy.io import FortranFile\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FortranFile('C:/Users/Lawrence Huang/Desktop/Research/newz3taured.dat', 'r')\n",
    "nlos=int(np.asscalar(f.read_ints()))\n",
    "print(\"nlos = %d\" %nlos)\n",
    "npix=int(np.asscalar(f.read_ints()))\n",
    "zred=np.asscalar(f.read_record('f4'))\n",
    "blenkms=np.asscalar(f.read_record('f4'))\n",
    "blen=np.asscalar(f.read_record('f4'))*0.001  #back into mpc/h\n",
    "print(nlos,npix,zred,blenkms,blen)\n",
    "taured=[]\n",
    "nstep=1 #skipping through in steps of 1\n",
    "for i in range(0,nlos,nstep):       \n",
    "    tauredin=f.read_record('f4')\n",
    "    taured.extend(tauredin)\n",
    "f.close()\n",
    "print('len(taured)=',len(taured))\n",
    "\n",
    "nlos=int(nlos/nstep)\n",
    "\n",
    "print ('nlos,npix=',nlos,npix)\n",
    "\n",
    "taured=np.array(taured)\n",
    "\n",
    "taured=np.reshape(taured,(nlos,1,npix))\n",
    "reshapedTaured = np.reshape(taured, (256,256,1,npix))\n",
    "\n",
    "print('shape of taured=',taured.shape)\n",
    "# print(reshapedTaured[0,0] == taured[0])\n",
    "# print(reshapedTaured[1,1] == taured[257])\n",
    "# print(taured[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauValidate = np.reshape(reshapedTaured[0:114,0:114],(114*114,1,512))\n",
    "tauTest = np.reshape(reshapedTaured[-114:,-114:],(114*114,1,512))\n",
    "tauTrain = np.concatenate((\n",
    "               np.reshape(reshapedTaured[:114,114:],(114*(256-114),1,512)), \\\n",
    "               np.reshape(reshapedTaured[114:-114],(256*(256-2*114),1,512)), \\\n",
    "               np.reshape(reshapedTaured[-114:,:-114],(114*(256-114),1,512))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tauTest = gaussian_filter1d(tauTest, 6, axis=-1, mode=\"wrap\")\n",
    "tauValidate = gaussian_filter1d(tauValidate, 6, axis=-1, mode=\"wrap\")\n",
    "tauTrain = gaussian_filter1d(tauTrain, 6, axis=-1, mode=\"wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663.7092\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't assign a numpy.float32 to a torch.cuda.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d0d522320a68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# set to realistic max:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtauTest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtauTest\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5e9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxtaured\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtauValidate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtauValidate\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5e9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxtaured\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtauTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtauTrain\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5e9\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxtaured\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't assign a numpy.float32 to a torch.cuda.FloatTensor"
     ]
    }
   ],
   "source": [
    "mintaured=taured.min()\n",
    "maxtaured=taured.max()\n",
    "taured[taured > 0.5e9] = -1.e10\n",
    "\n",
    "tauTest[tauTest > 0.5e9] = -1.e10\n",
    "tauValidate[tauValidate > 0.5e9] = -1.e10\n",
    "tauTrain[tauTrain > 0.5e9] = -1.e10\n",
    "\n",
    "maxtaured=taured.max()\n",
    "print (maxtaured)\n",
    "# set to realistic max:\n",
    "\n",
    "tauTest[tauTest < -0.5e9] = maxtaured\n",
    "tauValidate[tauValidate < -0.5e9] = maxtaured\n",
    "tauTrain[tauTrain < -0.5e9] = maxtaured\n",
    "\n",
    "\n",
    "flux=np.exp(-1.*taured)\n",
    "fluxTest = np.exp(-1.*tauTest)\n",
    "fluxValidate = np.exp(-1.*tauValidate)\n",
    "fluxTrain = np.exp(-1.*tauTrain)\n",
    "\n",
    "signalRMS = np.sqrt(np.mean(flux**2))\n",
    "print(\"signalRMS\", signalRMS)\n",
    "\n",
    "tauTest = torch.from_numpy(tauTest).cuda()\n",
    "tauValidate = torch.from_numpy(tauValidate).cuda()\n",
    "tauTrain = torch.from_numpy(tauTrain).cuda()\n",
    "\n",
    "\n",
    "fluxTest = torch.from_numpy(fluxTest).cuda()\n",
    "fluxValidate = torch.from_numpy(fluxValidate).cuda()\n",
    "fluxTrain = torch.from_numpy(fluxTrain).cuda()\n",
    "\n",
    "tauredzero=taured[0,0,...]\n",
    "\n",
    "fluxzero=flux[0,0,...]\n",
    "\n",
    "plt.plot(tauredzero)\n",
    "plt.plot(fluxzero)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "npHistResult = np.histogram(taured, bins=[0,2,10000])\n",
    "binProportions = npHistResult[0]/(2**25)\n",
    "binProportions = torch.from_numpy(binProportions).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del reshapedTaured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseDict = {\n",
    "    \"none\": 0,\n",
    "    \"low\": 1/10,\n",
    "    \"mid\": 1/5,\n",
    "    \"high\": 1/2.5\n",
    "}\n",
    "    \n",
    "def spin(tensor, midpoint):\n",
    "    return torch.cat((tensor[midpoint-256:],tensor[:midpoint-256]),dim=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spin function works\n",
      "torch.Size([50])\n",
      "torch.Size([50, 512])\n"
     ]
    }
   ],
   "source": [
    "def spinTest():\n",
    "    a = torch.arange(512)\n",
    "    for i in range(512):\n",
    "        assert(spin(a,i)[256] == i)\n",
    "#         print(\"Passed test %d/512\" %(i+1))\n",
    "    print(\"The spin function works\")\n",
    "    \n",
    "spinTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional_Neural_Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Convolutional_Neural_Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1, 4, 5)\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.lin1 = torch.nn.Linear(504,64)\n",
    "        self.lin2 = torch.nn.Linear(64,8)\n",
    "        self.predict = torch.nn.Linear(32,1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "\n",
    "        x = F.relu(self.lin2(x))\n",
    "        \n",
    "        x = x.view((-1,1,32))\n",
    "        \n",
    "        x = self.predict(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_predictor(a):\n",
    "    x = []\n",
    "    y = []\n",
    "    a = a.cpu()\n",
    "    n = len(a)\n",
    "    for i in range(n):\n",
    "        if a[i] > 0:\n",
    "            x.append(i)\n",
    "            y.append(-log(a[i]))\n",
    "            \n",
    "    x.append(x[0] + 512)\n",
    "    y.append(y[0])\n",
    "    func = CubicSpline(x,y, bc_type=\"periodic\")\n",
    "    desiredXs = np.arange(n)\n",
    "    result = func(desiredXs)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(pred, act):\n",
    "    \n",
    "    pred = torch.Tensor(pred)\n",
    "    act = torch.Tensor(act)\n",
    "    result = torch.sqrt(torch.mean((pred-act)**2))\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-34ed99248baa>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-34ed99248baa>\"\u001b[1;36m, line \u001b[1;32m37\u001b[0m\n\u001b[1;33m    if source == \"test\":\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "class NetFactory():\n",
    "    def __init__(self, noise, printAll = True):\n",
    "        self.net = Convolutional_Neural_Net().cuda()\n",
    "            \n",
    "        self.printAll = printAll\n",
    "        self.comment = \"\"\n",
    "        if noise == \"low\":\n",
    "            self.fluxValidate = fluxValidate + torch.load(\"lowValidationNoise.pt\")\n",
    "        elif noise == \"mid\":\n",
    "            self.fluxValidate = fluxValidate + torch.load(\"midValidationNoise.pt\")\n",
    "        elif noise == \"high\":\n",
    "            self.fluxValidate = fluxValidate + torch.load(\"highValidationNoise.pt\")\n",
    "        self.noise = noise\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    def randomSample(self, num, noise=\"low\", source=\"train\"):\n",
    "        if source == \"test\":\n",
    "            tSet = tauTest\n",
    "            fSet = fluxTest\n",
    "        elif source == \"validate\":\n",
    "            tSet = tauValidate\n",
    "            fSet = fluxValidate\n",
    "        elif source == \"train\":\n",
    "            tSet = tauTrain\n",
    "            fSet = fluxTrain\n",
    "        else:\n",
    "            print(source)\n",
    "            print(\"Not valid\")\n",
    "\n",
    "\n",
    "\n",
    "        indices = torch.randint(low=0,high=tSet.shape[0],size=(num,))\n",
    "        points = torch.randint(low=0,high=512,size=(num,))\n",
    "        taus = torch.zeros((num))\n",
    "        fluxs = torch.zeros(num,512)\n",
    "        taus = tSet[indices,0,points]\n",
    "        fluxs = fSet[indices, 0]\n",
    "        points = points-256\n",
    "        scatterPoints = torch.zeros(num, 512, dtype=torch.long).cuda()\n",
    "        scatterPoints = torch.add(scatterPoints, torch.arange(512))\n",
    "        scatterPoints = torch.add(scatterPoints, points.view(num,1))\n",
    "        scatterPoints[scatterPoints < 0] += 512\n",
    "        scatterPoints[scatterPoints > 511] -= 512\n",
    "        fluxs = fluxs.gather(1, scatterPoints)\n",
    "\n",
    "        noiseGen =  torch.distributions.normal.Normal(0.0, signalRMS*noiseDict[noise], validate_args=None)\n",
    "\n",
    "        fluxs = fluxs + noiseGen.sample(fluxs.shape)\n",
    "        return taus, fluxs\n",
    "    \n",
    "    \n",
    "    def validate(self, noise):\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        loss = torch.zeros(512)\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            for midpoint in range(512):\n",
    "                fluxs = torch.cat((self.fluxValidate[:,:,midpoint-256:],self.fluxValidate[:,:,:midpoint-256]),2)\n",
    "                taus = tauValidate[:,0,midpoint]\n",
    "                prediction = self.net(fluxs)\n",
    "                loss[midpoint] = loss_func(prediction, taus)\n",
    "        self.net.train()\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "    def run(self, epochs, learningRate):\n",
    "        noise = self.noise\n",
    "        now = datetime.now()\n",
    " \n",
    "        print(\"now =\", now)\n",
    "    \n",
    "        \n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        sampler = self.randomSample\n",
    "        \n",
    "        pathString = \"ConvNN_default_\" + str(epochs) + \"_\" + str(learningRate) + \"_\" + noise + \"_\" + \\\n",
    "                   now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "        \n",
    "        writer = SummaryWriter(pathString)\n",
    "        \n",
    "        writer.add_text(\"Net\", str(self.net))\n",
    "        writer.add_text(\"Epochs\", str(epochs))\n",
    "        writer.add_text(\"Learning Rate\", str(learningRate))\n",
    "        writer.add_text(\"Comment\", self.comment)\n",
    "        \n",
    "        optimizer = torch.optim.Adam( self.net.parameters(), learningRate, weight_decay=0.0005 )\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 50, gamma=1)\n",
    "        \n",
    "        \n",
    "        validationLoss = self.validate(noise)\n",
    "        writer.add_scalar('Loss/validation', validationLoss, 0)\n",
    "        \n",
    "        self.results(noise, 0, writer)\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            \n",
    "            tauSet,fluxSet = sampler(num=10000, noise=noise, source=\"train\")\n",
    "            tauSet = tauSet.float().cuda()\n",
    "            fluxSet = fluxSet.float().cuda()\n",
    "            tauSet = torch.reshape(tauSet, (-1,1,1))\n",
    "            fluxSet = torch.reshape(fluxSet, (-1,1,512))\n",
    "            \n",
    "            prediction = self.net(fluxSet)\n",
    "                \n",
    "            \n",
    "            loss = loss_func(prediction, tauSet)     # must be (1. nn output, 2. target)\n",
    "            optimizer.zero_grad()   # clear gradients for next train\n",
    "            loss.backward()         # backpropagation, compute gradients\n",
    "            optimizer.step()        # apply gradients\n",
    "            scheduler.step()        # scheduler decreases learning rate geometrically every n epochs\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            writer.add_scalar('Loss/train', loss, epoch)\n",
    "                        \n",
    "            \n",
    "            \n",
    "            \n",
    "            if self.printAll:\n",
    "                if epoch % 100 == 0:\n",
    "                    print(\"Epoch = \", epoch)\n",
    "            if epoch % 1000 == 999:\n",
    "                hundredth = plt.figure()\n",
    "                a = torch.flatten(tauSet)\n",
    "                b = torch.flatten(prediction)\n",
    "                plt.title(\"%dth epoch predictions\" %epoch)\n",
    "                plt.plot(a.cpu().detach().numpy(),\"r\", label=\"actual\")\n",
    "                plt.plot(b.cpu().detach().numpy(),\"g.\", label=\"prediction\")\n",
    "                plt.show()\n",
    "                writer.add_figure(\"Every Thousand Epochs/\" + str(epoch), hundredth)\n",
    "                \n",
    "                validationLoss = self.validate(noise)\n",
    "                writer.add_scalar('Loss/validation', validationLoss, epoch)\n",
    "                self.results(noise, epoch, writer)\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                    }, \"CopyStorage/\" + pathString + \"Copy\" + str(epoch))\n",
    "\n",
    "\n",
    "        self.results(noise, epoch, writer)\n",
    "        \n",
    "        end = datetime.now()\n",
    " \n",
    "        print(\"end =\", end)\n",
    "        \n",
    "        return 1\n",
    "        \n",
    "    def results(self, noise, epoch, writer):\n",
    "        taus = tauValidate[0,0,...].cuda()\n",
    "        fluxs = torch.zeros((512,1,512)).cuda()\n",
    "        for i in range(512):\n",
    "            fluxs[i] = spin(self.fluxValidate[0,0,...],i)\n",
    "    \n",
    "        fluxs = fluxs\n",
    "        \n",
    "        \n",
    "        taus = taus.float()\n",
    "        fluxs = fluxs.float()\n",
    "        taus = torch.reshape(taus, (-1,1,1))\n",
    "        fluxs = torch.reshape(fluxs, (-1,1,512))\n",
    "        prediction = self.net(fluxs)\n",
    "        prediction = torch.flatten(prediction)\n",
    "        taus = torch.flatten(taus)\n",
    "        logPrediction = log_predictor(torch.flatten(self.fluxValidate[0,0,...]))\n",
    "                                       \n",
    "        example = plt.figure()\n",
    "        \n",
    "        plt.plot(taus.data.cpu().numpy(), \"r\", label=\"actual\")\n",
    "        plt.plot(prediction.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "        plt.plot(logPrediction, \"b\", label=\"log and cubic splines\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        writer.add_figure(\"One Sightline/\" + str(epoch), example)\n",
    "        \n",
    "        difference = plt.figure()\n",
    "        plt.plot(prediction.data.cpu().numpy()-taus.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "        plt.plot(logPrediction-taus.data.cpu().numpy(), \"b\", label=\"log and cubic splines\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Difference\")\n",
    "        plt.show()\n",
    "        writer.add_figure(\"Difference/\" + str(epoch), difference)\n",
    "        \n",
    "        fracDifference = plt.figure()\n",
    "        plt.plot((prediction.data.cpu().numpy()-taus.data.cpu().numpy())/taus.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "        plt.plot((logPrediction-taus.data.cpu().numpy())/taus.data.cpu().numpy(), \"b\", label=\"log and cubic splines\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Fractional Difference\")\n",
    "        plt.show()\n",
    "        writer.add_figure(\"Fractional Difference/\" + str(epoch), fracDifference)\n",
    "        \n",
    "        predictionList = np.zeros((512*20))\n",
    "        with torch.no_grad():\n",
    "            for midpoint in range(512):\n",
    "                fluxs = torch.cat((self.fluxValidate[0:20,:,midpoint-256:],self.fluxValidate[0:20,:,:midpoint-256]),2)\n",
    "                prediction = self.net(fluxs)\n",
    "                predictionList[midpoint::512] = prediction.flatten().data.cpu().numpy()\n",
    "        self.net.train()\n",
    "        \n",
    "        logPList = np.zeros((512*20))\n",
    "        for i in range(20):\n",
    "            logP = log_predictor(torch.flatten(self.fluxValidate[i,0]))\n",
    "            logPList[i*512:(i+1)*512] = logP\n",
    "            \n",
    "        \n",
    "        a = torch.flatten(tauValidate[0:20,0,:]).cpu().numpy()\n",
    "        b = predictionList\n",
    "        logP = logPList\n",
    "        pearsonCoeff = pearsonr(a,b)\n",
    "        RMSD = RMSE(b, a)\n",
    "        writer.add_scalar(\"NeuralNet/Total/RMSD\", RMSD, epoch)\n",
    "        logRMSD = RMSE(logP, a)\n",
    "        writer.add_scalar(\"LogPrediction/Total/RMSD\", logRMSD, epoch)\n",
    "        \n",
    "        print(\"Pearson's Coefficient is:\")\n",
    "        print(pearsonCoeff)\n",
    "        writer.add_scalar(\"NeuralNet/Total/Pearson\", pearsonCoeff[0], epoch)\n",
    "        print(\"Compared to log:\")\n",
    "        logPearson = pearsonr(a,logP)\n",
    "        print(logPearson)\n",
    "        writer.add_scalar(\"LogPrediction/Total/Pearson\", logPearson[0], epoch)\n",
    "        \n",
    "        c = np.zeros(a.shape)\n",
    "        \n",
    "        newA = np.where(a>2, a, c)\n",
    "        newB = np.where(a>2, b, c)\n",
    "        newLogP = np.where(a>2, logP, c)\n",
    "        newA = newA[np.nonzero(newA)]\n",
    "        newB = newB[np.nonzero(newB)]\n",
    "        highA = np.copy(newA)\n",
    "        highB = np.copy(newB)\n",
    "        newLogP = newLogP[np.nonzero(newLogP)]\n",
    "        RMSD = RMSE(newB, newA)\n",
    "        writer.add_scalar(\"NeuralNet/High/RMSD\", RMSD, epoch)\n",
    "        print(\"Pearson's Coefficient for high numbers\")\n",
    "        pearsonCoeff = pearsonr(newA,newB)\n",
    "        print(pearsonCoeff)\n",
    "        writer.add_scalar(\"NeuralNet/High/Pearson\", pearsonCoeff[0], epoch)\n",
    "        print(\"Compared to log:\")\n",
    "        logPearson = pearsonr(newA,newLogP)\n",
    "        print(logPearson)\n",
    "        writer.add_scalar(\"LogPrediction/High/Pearson\", logPearson[0], epoch)\n",
    "        logRMSD = RMSE(newLogP, newA)\n",
    "        writer.add_scalar(\"LogPrediction/High/RMSD\", logRMSD, epoch)\n",
    "        \n",
    "        \n",
    "        print(\"percent high:\")\n",
    "        print(len(newA)/len(a))\n",
    "        \n",
    "        newA = np.where(a<2, a, c)\n",
    "        newB = np.where(a<2, b, c)\n",
    "        newLogP = np.where(a<2, logP, c)\n",
    "        newA = newA[np.nonzero(newA)]\n",
    "        newB = newB[np.nonzero(newB)]\n",
    "        newLogP = newLogP[np.nonzero(newLogP)]\n",
    "        RMSD = RMSE(newB, newA)\n",
    "        writer.add_scalar(\"NeuralNet/Low/RMSD\", RMSD, epoch)\n",
    "        print(\"Pearson's Coefficient for low numbers\")\n",
    "        pearsonCoeff = pearsonr(newA,newB)\n",
    "        print(pearsonCoeff)\n",
    "        writer.add_scalar(\"NeuralNet/Low/Pearson\", pearsonCoeff[0], epoch)\n",
    "        print(\"Compared to log:\")\n",
    "        logPearson = pearsonr(newA,newLogP)\n",
    "        print(logPearson)\n",
    "        writer.add_scalar(\"LogPrediction/Low/Pearson\", logPearson[0], epoch)\n",
    "        logRMSD = RMSE(newLogP, newA)\n",
    "        writer.add_scalar(\"LogPrediction/Low/RMSD\", logRMSD, epoch)\n",
    "        \n",
    "        print(\"percent low:\")\n",
    "        print(len(newA)/len(a))\n",
    "        \n",
    "        line = np.linspace(0,a.max())\n",
    "        scatter = plt.figure()\n",
    "        plt.scatter(a,b)\n",
    "        plt.title(\"Scatter plot of Prediction vs Tau\")\n",
    "        plt.ylabel(\"Prediction\")\n",
    "        plt.xlabel(\"Tau\")\n",
    "        plt.plot(line, line, \"k\")\n",
    "        plt.show()\n",
    "        writer.add_figure(\"Scatter/\" + str(epoch), scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
