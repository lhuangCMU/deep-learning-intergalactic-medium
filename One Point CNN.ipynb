{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "from scipy.io import FortranFile\n",
    "\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Writer will output to ./runs/ directory by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlos = 65536\n",
      "65536 512 3.0 42807.71484375 400.0\n",
      "len(taured)= 262144\n",
      "nlos,npix= 512 512\n",
      "shape of taured= (512, 512)\n",
      "13.272697 13.76669\n"
     ]
    }
   ],
   "source": [
    "f = FortranFile('C:/Users/Lawrence Huang/Desktop/Research/z3taured.dat', 'r')\n",
    "nlos=int(np.asscalar(f.read_ints()))\n",
    "print(\"nlos = %d\" %nlos)\n",
    "npix=int(np.asscalar(f.read_ints()))\n",
    "zred=np.asscalar(f.read_record('f4'))\n",
    "blenkms=np.asscalar(f.read_record('f4'))\n",
    "blen=np.asscalar(f.read_record('f4'))*0.001  #back into mpc/h\n",
    "print(nlos,npix,zred,blenkms,blen)\n",
    "taured=[]\n",
    "nstep=128 #skipping through in steps of 64\n",
    "for i in range(0,nlos,nstep):       \n",
    "    tauredin=f.read_record('f4')\n",
    "    taured.extend(tauredin)\n",
    "f.close()\n",
    "print('len(taured)=',len(taured))\n",
    "\n",
    "nlos=int(nlos/nstep)\n",
    "\n",
    "print ('nlos,npix=',nlos,npix)\n",
    "\n",
    "taured=np.array(taured)\n",
    "\n",
    "taured=np.reshape(taured,(nlos,npix))\n",
    "\n",
    "print('shape of taured=',taured.shape)\n",
    "\n",
    "print(taured[0,0],taured[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.892097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f3cfed308>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mintaured=taured.min()\n",
    "maxtaured=taured.max()\n",
    "taured[taured > 0.5e9] = -1.e10\n",
    "\n",
    "maxtaured=taured.max()\n",
    "print (maxtaured)\n",
    "# set to realistic max:\n",
    "\n",
    "taured[taured < -0.5e9] = maxtaured\n",
    "taured=(((taured-mintaured)/(maxtaured-mintaured))*0.98)+0.01\n",
    "flux=np.exp(-1.*taured)\n",
    "rmsnoise=0.0 #this is the rms noise to add - if it's zero then we are try \n",
    "noise = np.random.normal(0.0,rmsnoise,(nlos,npix))\n",
    "# 1 is the mean of the normal distribution you are choosing from\n",
    "# 2 is the standard deviation of the normal distribution\n",
    "# 3 is the number of elements you get in array noise\n",
    "flux=flux+noise\n",
    "minflux=flux.min()\n",
    "maxflux=flux.max()\n",
    "flux=(((flux-minflux)/(maxflux-minflux))*0.98)+0.01\n",
    "taured = torch.from_numpy(taured)\n",
    "flux = torch.from_numpy(flux)\n",
    "tauredzero=taured[0,...]\n",
    "\n",
    "fluxzero=flux[0,...]\n",
    "\n",
    "#orange is the flux and blue is the optical depth, both scaled to 0.01-0.99\n",
    "plt.plot(tauredzero.numpy())\n",
    "plt.plot(fluxzero.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20f3d276f88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tauredzero,fluxzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.linspace(0,1,100)\n",
    "b = torch.tensor([0,10,20,30,40,50,60,70,80,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n",
      "torch.Size([32, 512])\n",
      "torch.Size([480, 512])\n",
      "torch.Size([480, 512])\n"
     ]
    }
   ],
   "source": [
    "tauredTest = taured[480:,...]\n",
    "fluxTest = flux[480:,...]\n",
    "tauredTrain = taured[:480,...]\n",
    "fluxTrain = flux[:480,...]\n",
    "print(tauredTest.shape)\n",
    "print(fluxTest.shape)\n",
    "print(tauredTrain.shape)\n",
    "print(fluxTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  0\n",
      "Training Loss =  tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.033607937030501134\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  1\n",
      "Training Loss =  tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.033910272038781386\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  2\n",
      "Training Loss =  tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03491856441087293\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  3\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03625769042174909\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  4\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03757464968985502\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  5\n",
      "Training Loss =  tensor(0.0123, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.038154954593799584\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  6\n",
      "Training Loss =  tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03790765337924995\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  7\n",
      "Training Loss =  tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03744768263937459\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  8\n",
      "Training Loss =  tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03701979143305678\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  9\n",
      "Training Loss =  tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03650517551568555\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  10\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03637126149970982\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  11\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03624768610542617\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  12\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03613194176692147\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  13\n",
      "Training Loss =  tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03600149602863789\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  14\n",
      "Training Loss =  tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.035837403396961065\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  15\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.035697562438224306\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  16\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03556734643848003\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  17\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03541668178821844\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  18\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03529317055330594\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  19\n",
      "Training Loss =  tensor(0.0253, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.035129999034921866\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  20\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03508719039879793\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  21\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.035048896818295816\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  22\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03501840527587774\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  23\n",
      "Training Loss =  tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349894096607386\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  24\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03496478678528092\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  25\n",
      "Training Loss =  tensor(0.0128, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034938785652911974\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  26\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03492067571028201\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  27\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03491433681563194\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  28\n",
      "Training Loss =  tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034904869105162106\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  29\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03490283091980473\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  30\n",
      "Training Loss =  tensor(0.0350, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03489594024131293\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  31\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034894516717713486\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  32\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03489236423104103\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  33\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034894385299480746\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  34\n",
      "Training Loss =  tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03489858037232807\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  35\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03490479795561896\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  36\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034910303719357216\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  37\n",
      "Training Loss =  tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034913039337538976\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  38\n",
      "Training Loss =  tensor(0.0239, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03491386813209374\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  39\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03491653836692876\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  40\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03491825957917172\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  41\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03492027309528112\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  42\n",
      "Training Loss =  tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034922230944061994\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  43\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03492486333993838\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  44\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03492805770349605\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  45\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03493193830212249\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  46\n",
      "Training Loss =  tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03493593275550211\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  47\n",
      "Training Loss =  tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03493870060020754\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  48\n",
      "Training Loss =  tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494114241925672\n",
      "SHAPE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  49\n",
      "Training Loss =  tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494212530659979\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  50\n",
      "Training Loss =  tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349422410099578\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  51\n",
      "Training Loss =  tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034942338817984364\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  52\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494257158195069\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  53\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349431341254558\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  54\n",
      "Training Loss =  tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034943538469121904\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  55\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494414110105026\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  56\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034944745736311233\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  57\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034945427598984224\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  58\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494613006688496\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  59\n",
      "Training Loss =  tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349470037982087\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  60\n",
      "Training Loss =  tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034947222886501095\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  61\n",
      "Training Loss =  tensor(0.0270, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034947291525668334\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  62\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034947347851186805\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  63\n",
      "Training Loss =  tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034947275773333786\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  64\n",
      "Training Loss =  tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494707016193388\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  65\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494695828936756\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  66\n",
      "Training Loss =  tensor(0.0155, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946838658584056\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  67\n",
      "Training Loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494683860060377\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  68\n",
      "Training Loss =  tensor(0.0227, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494681504884056\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  69\n",
      "Training Loss =  tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946830047204\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  70\n",
      "Training Loss =  tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946847077037546\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  71\n",
      "Training Loss =  tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494685148547205\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  72\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494687006559616\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  73\n",
      "Training Loss =  tensor(0.0179, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494686983782458\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  74\n",
      "Training Loss =  tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349468606048049\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  75\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946860759873744\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  76\n",
      "Training Loss =  tensor(0.0348, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494681965298696\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  77\n",
      "Training Loss =  tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494679898949471\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  78\n",
      "Training Loss =  tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946753715189516\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  79\n",
      "Training Loss =  tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494671455467824\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  80\n",
      "Training Loss =  tensor(0.0499, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946690997799124\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  81\n",
      "Training Loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494668402441903\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  82\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946675446121844\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  83\n",
      "Training Loss =  tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946674122693366\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  84\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667515445826\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  85\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946674012587664\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  86\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946671008185604\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  87\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667390333461\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  88\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667936058704\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  89\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494668016946889\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  90\n",
      "Training Loss =  tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494668075671825\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  91\n",
      "Training Loss =  tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349466791946611\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  92\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667904186599\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  93\n",
      "Training Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667882534941\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  94\n",
      "Training Loss =  tensor(0.0177, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946680314192236\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  95\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946678897426864\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  96\n",
      "Training Loss =  tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667932579887\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667966612042\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  98\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679159986616\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  99\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667958824493\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  100\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679310962736\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  101\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349466795168496\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  102\n",
      "Training Loss =  tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494668023307668\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  103\n",
      "Training Loss =  tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494668068822193\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  104\n",
      "Training Loss =  tensor(0.0232, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494668041582827\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  105\n",
      "Training Loss =  tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946680151392684\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  106\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946680291909615\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  107\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946678701771816\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  108\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679276174564\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  109\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679191250496\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  110\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494668002161916\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  111\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667942061369\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  112\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667918801042\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  113\n",
      "Training Loss =  tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667919528638\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  114\n",
      "Training Loss =  tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667919551375\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  115\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667586085143\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  116\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667899065007\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  117\n",
      "Training Loss =  tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679469555875\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  118\n",
      "Training Loss =  tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667889998482\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  119\n",
      "Training Loss =  tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667866488044\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  120\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667902504034\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  121\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667911598981\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  122\n",
      "Training Loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667909370719\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  123\n",
      "Training Loss =  tensor(0.0238, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946678746962334\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  124\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667916851313\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  125\n",
      "Training Loss =  tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679198696984\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  126\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679291010696\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  127\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.0349466794792761\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  128\n",
      "Training Loss =  tensor(0.0307, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667913594185\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  129\n",
      "Training Loss =  tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667924007899\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  130\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667926918282\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  131\n",
      "Training Loss =  tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  132\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679318750284\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  133\n",
      "Training Loss =  tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667936240603\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  134\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679344216136\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  135\n",
      "Training Loss =  tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667930056039\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  136\n",
      "Training Loss =  tensor(0.0207, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667930056039\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  137\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667930056039\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  138\n",
      "Training Loss =  tensor(0.0161, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.034946679318750284\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  139\n",
      "Training Loss =  tensor(0.0336, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667929328443\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  140\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667929328443\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  141\n",
      "Training Loss =  tensor(0.0301, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667931147433\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  142\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667931147433\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  143\n",
      "Training Loss =  tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  144\n",
      "Training Loss =  tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  145\n",
      "Training Loss =  tensor(0.0045, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  146\n",
      "Training Loss =  tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  147\n",
      "Training Loss =  tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  148\n",
      "Training Loss =  tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  149\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  150\n",
      "Training Loss =  tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  151\n",
      "Training Loss =  tensor(0.0155, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  152\n",
      "Training Loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  153\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  154\n",
      "Training Loss =  tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  155\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  156\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  157\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  158\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  159\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  160\n",
      "Training Loss =  tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  161\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  162\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  163\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  164\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  165\n",
      "Training Loss =  tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  166\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  167\n",
      "Training Loss =  tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  168\n",
      "Training Loss =  tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  169\n",
      "Training Loss =  tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  170\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  171\n",
      "Training Loss =  tensor(0.0168, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  172\n",
      "Training Loss =  tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  173\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  174\n",
      "Training Loss =  tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  175\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  176\n",
      "Training Loss =  tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  177\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  178\n",
      "Training Loss =  tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  179\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  180\n",
      "Training Loss =  tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  181\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  182\n",
      "Training Loss =  tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  183\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  184\n",
      "Training Loss =  tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  185\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  186\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  187\n",
      "Training Loss =  tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  188\n",
      "Training Loss =  tensor(0.0321, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  189\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  190\n",
      "Training Loss =  tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  191\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  192\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  193\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  194\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  195\n",
      "Training Loss =  tensor(0.0256, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  196\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  197\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  198\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  199\n",
      "Training Loss =  tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  200\n",
      "Training Loss =  tensor(0.0311, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  201\n",
      "Training Loss =  tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  202\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  203\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  204\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  205\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  206\n",
      "Training Loss =  tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  207\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  208\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  209\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  210\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  211\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  212\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  213\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  214\n",
      "Training Loss =  tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  215\n",
      "Training Loss =  tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  216\n",
      "Training Loss =  tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  217\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  218\n",
      "Training Loss =  tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  219\n",
      "Training Loss =  tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  220\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  221\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  222\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  223\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  224\n",
      "Training Loss =  tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  225\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  226\n",
      "Training Loss =  tensor(0.0239, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  227\n",
      "Training Loss =  tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  228\n",
      "Training Loss =  tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  229\n",
      "Training Loss =  tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  230\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  231\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  232\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  233\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  234\n",
      "Training Loss =  tensor(0.0415, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  235\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  236\n",
      "Training Loss =  tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  237\n",
      "Training Loss =  tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  238\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  239\n",
      "Training Loss =  tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  240\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  241\n",
      "Training Loss =  tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  tensor(0.0166, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  243\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  244\n",
      "Training Loss =  tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  245\n",
      "Training Loss =  tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  246\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  247\n",
      "Training Loss =  tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  248\n",
      "Training Loss =  tensor(0.0236, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  249\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  250\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  251\n",
      "Training Loss =  tensor(0.0367, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  252\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  253\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  254\n",
      "Training Loss =  tensor(0.0260, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  255\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  256\n",
      "Training Loss =  tensor(0.0278, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  257\n",
      "Training Loss =  tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  258\n",
      "Training Loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  259\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  260\n",
      "Training Loss =  tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  261\n",
      "Training Loss =  tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  262\n",
      "Training Loss =  tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  263\n",
      "Training Loss =  tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  264\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  265\n",
      "Training Loss =  tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  266\n",
      "Training Loss =  tensor(0.0259, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  267\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  268\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  269\n",
      "Training Loss =  tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  270\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  271\n",
      "Training Loss =  tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  272\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  273\n",
      "Training Loss =  tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  274\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  275\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  276\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  277\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  278\n",
      "Training Loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  279\n",
      "Training Loss =  tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  280\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  281\n",
      "Training Loss =  tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  282\n",
      "Training Loss =  tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  283\n",
      "Training Loss =  tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  284\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  285\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  286\n",
      "Training Loss =  tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  287\n",
      "Training Loss =  tensor(0.0179, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  288\n",
      "Training Loss =  tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  289\n",
      "Training Loss =  tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  290\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  291\n",
      "Training Loss =  tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  292\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  293\n",
      "Training Loss =  tensor(0.0240, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  294\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  295\n",
      "Training Loss =  tensor(0.0127, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  296\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  297\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  298\n",
      "Training Loss =  tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  299\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  300\n",
      "Training Loss =  tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  301\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  302\n",
      "Training Loss =  tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  303\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  304\n",
      "Training Loss =  tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  305\n",
      "Training Loss =  tensor(0.0085, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  306\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  307\n",
      "Training Loss =  tensor(0.0348, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  308\n",
      "Training Loss =  tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  309\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  310\n",
      "Training Loss =  tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  311\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  312\n",
      "Training Loss =  tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  313\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  314\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  315\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  316\n",
      "Training Loss =  tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  317\n",
      "Training Loss =  tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  318\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  319\n",
      "Training Loss =  tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  320\n",
      "Training Loss =  tensor(0.0107, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  321\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  322\n",
      "Training Loss =  tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  323\n",
      "Training Loss =  tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  324\n",
      "Training Loss =  tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  325\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  326\n",
      "Training Loss =  tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  327\n",
      "Training Loss =  tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  328\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  329\n",
      "Training Loss =  tensor(0.0319, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  330\n",
      "Training Loss =  tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  331\n",
      "Training Loss =  tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  332\n",
      "Training Loss =  tensor(0.0180, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  333\n",
      "Training Loss =  tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  334\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  335\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  336\n",
      "Training Loss =  tensor(0.0275, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  337\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  338\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  339\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  340\n",
      "Training Loss =  tensor(0.0216, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  341\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  342\n",
      "Training Loss =  tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  343\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  344\n",
      "Training Loss =  tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  345\n",
      "Training Loss =  tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  346\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  347\n",
      "Training Loss =  tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  348\n",
      "Training Loss =  tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  349\n",
      "Training Loss =  tensor(0.0240, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  350\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  351\n",
      "Training Loss =  tensor(0.0317, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  352\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  353\n",
      "Training Loss =  tensor(0.0157, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  354\n",
      "Training Loss =  tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  355\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  356\n",
      "Training Loss =  tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  357\n",
      "Training Loss =  tensor(0.0242, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  358\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  359\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  360\n",
      "Training Loss =  tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  361\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  362\n",
      "Training Loss =  tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  363\n",
      "Training Loss =  tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  364\n",
      "Training Loss =  tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  365\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  366\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  367\n",
      "Training Loss =  tensor(0.0234, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  368\n",
      "Training Loss =  tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  369\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  370\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  371\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  372\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  373\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  374\n",
      "Training Loss =  tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  375\n",
      "Training Loss =  tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  376\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  377\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  378\n",
      "Training Loss =  tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  379\n",
      "Training Loss =  tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  380\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  381\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  382\n",
      "Training Loss =  tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  383\n",
      "Training Loss =  tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  384\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  385\n",
      "Training Loss =  tensor(0.0199, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  386\n",
      "Training Loss =  tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  388\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  389\n",
      "Training Loss =  tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  390\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  391\n",
      "Training Loss =  tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  392\n",
      "Training Loss =  tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  393\n",
      "Training Loss =  tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  394\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  395\n",
      "Training Loss =  tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  396\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  397\n",
      "Training Loss =  tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  398\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  399\n",
      "Training Loss =  tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  400\n",
      "Training Loss =  tensor(0.0128, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  401\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  402\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  403\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  404\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  405\n",
      "Training Loss =  tensor(0.0130, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  406\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  407\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  408\n",
      "Training Loss =  tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  409\n",
      "Training Loss =  tensor(0.0333, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  410\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  411\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  412\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  413\n",
      "Training Loss =  tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  414\n",
      "Training Loss =  tensor(0.0127, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  415\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  416\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  417\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  418\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  419\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  420\n",
      "Training Loss =  tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  421\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  422\n",
      "Training Loss =  tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  423\n",
      "Training Loss =  tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  424\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  425\n",
      "Training Loss =  tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  426\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  427\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  428\n",
      "Training Loss =  tensor(0.0263, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  429\n",
      "Training Loss =  tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  430\n",
      "Training Loss =  tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  431\n",
      "Training Loss =  tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  432\n",
      "Training Loss =  tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  433\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  434\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  435\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  436\n",
      "Training Loss =  tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  437\n",
      "Training Loss =  tensor(0.0347, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  438\n",
      "Training Loss =  tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  439\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  440\n",
      "Training Loss =  tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  441\n",
      "Training Loss =  tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  442\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  443\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  444\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  445\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  446\n",
      "Training Loss =  tensor(0.0118, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  447\n",
      "Training Loss =  tensor(0.0163, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  448\n",
      "Training Loss =  tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  449\n",
      "Training Loss =  tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  450\n",
      "Training Loss =  tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  451\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  452\n",
      "Training Loss =  tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  453\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  454\n",
      "Training Loss =  tensor(0.0290, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  455\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  456\n",
      "Training Loss =  tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  457\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  458\n",
      "Training Loss =  tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  459\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  460\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  461\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  462\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  463\n",
      "Training Loss =  tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  464\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  465\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  466\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  467\n",
      "Training Loss =  tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  468\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  469\n",
      "Training Loss =  tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  470\n",
      "Training Loss =  tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  471\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  472\n",
      "Training Loss =  tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  473\n",
      "Training Loss =  tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  474\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  475\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  476\n",
      "Training Loss =  tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  477\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  478\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  479\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  480\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  481\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  482\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  483\n",
      "Training Loss =  tensor(0.0193, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  484\n",
      "Training Loss =  tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  485\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  486\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  487\n",
      "Training Loss =  tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  488\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  489\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  490\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  491\n",
      "Training Loss =  tensor(0.0225, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  492\n",
      "Training Loss =  tensor(0.0191, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  493\n",
      "Training Loss =  tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  494\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  495\n",
      "Training Loss =  tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  496\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  497\n",
      "Training Loss =  tensor(0.0111, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  498\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  499\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  500\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  501\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  502\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  503\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  504\n",
      "Training Loss =  tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  505\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  506\n",
      "Training Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  507\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  508\n",
      "Training Loss =  tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  509\n",
      "Training Loss =  tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  510\n",
      "Training Loss =  tensor(0.0122, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  511\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  512\n",
      "Training Loss =  tensor(0.0196, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  513\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  514\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  515\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  516\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  517\n",
      "Training Loss =  tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  518\n",
      "Training Loss =  tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  519\n",
      "Training Loss =  tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  520\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  521\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  522\n",
      "Training Loss =  tensor(0.0116, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  523\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  524\n",
      "Training Loss =  tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  525\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  526\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  527\n",
      "Training Loss =  tensor(0.0261, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  528\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  529\n",
      "Training Loss =  tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  530\n",
      "Training Loss =  tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  531\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  533\n",
      "Training Loss =  tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  534\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  535\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  536\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  537\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  538\n",
      "Training Loss =  tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  539\n",
      "Training Loss =  tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  540\n",
      "Training Loss =  tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  541\n",
      "Training Loss =  tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  542\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  543\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  544\n",
      "Training Loss =  tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  545\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  546\n",
      "Training Loss =  tensor(0.0171, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  547\n",
      "Training Loss =  tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  548\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  549\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  550\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  551\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  552\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  553\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  554\n",
      "Training Loss =  tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  555\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  556\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  557\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  558\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  559\n",
      "Training Loss =  tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  560\n",
      "Training Loss =  tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  561\n",
      "Training Loss =  tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  562\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  563\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  564\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  565\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  566\n",
      "Training Loss =  tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  567\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  568\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  569\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  570\n",
      "Training Loss =  tensor(0.0210, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  571\n",
      "Training Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  572\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  573\n",
      "Training Loss =  tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  574\n",
      "Training Loss =  tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  575\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  576\n",
      "Training Loss =  tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  577\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  578\n",
      "Training Loss =  tensor(0.0370, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  579\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  580\n",
      "Training Loss =  tensor(0.0067, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  581\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  582\n",
      "Training Loss =  tensor(0.0132, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  583\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  584\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  585\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  586\n",
      "Training Loss =  tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  587\n",
      "Training Loss =  tensor(0.0127, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  588\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  589\n",
      "Training Loss =  tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  590\n",
      "Training Loss =  tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  591\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  592\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  593\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  594\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  595\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  596\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  597\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  598\n",
      "Training Loss =  tensor(0.0335, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  599\n",
      "Training Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  600\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  601\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  602\n",
      "Training Loss =  tensor(0.0273, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  603\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  604\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  605\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  606\n",
      "Training Loss =  tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  607\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  608\n",
      "Training Loss =  tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  609\n",
      "Training Loss =  tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  610\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  611\n",
      "Training Loss =  tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  612\n",
      "Training Loss =  tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  613\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  614\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  615\n",
      "Training Loss =  tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  616\n",
      "Training Loss =  tensor(0.0099, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  617\n",
      "Training Loss =  tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  618\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  619\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  620\n",
      "Training Loss =  tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  621\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  622\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  623\n",
      "Training Loss =  tensor(0.0326, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  624\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  625\n",
      "Training Loss =  tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  626\n",
      "Training Loss =  tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  627\n",
      "Training Loss =  tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  628\n",
      "Training Loss =  tensor(0.0211, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  629\n",
      "Training Loss =  tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  630\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  631\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  632\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  633\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  634\n",
      "Training Loss =  tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  635\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  636\n",
      "Training Loss =  tensor(0.0193, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  637\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  638\n",
      "Training Loss =  tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  639\n",
      "Training Loss =  tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  640\n",
      "Training Loss =  tensor(0.0288, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  641\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  642\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  643\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  644\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  645\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  646\n",
      "Training Loss =  tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  647\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  648\n",
      "Training Loss =  tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  649\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  650\n",
      "Training Loss =  tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  651\n",
      "Training Loss =  tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  652\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  653\n",
      "Training Loss =  tensor(0.0207, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  654\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  655\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  656\n",
      "Training Loss =  tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  657\n",
      "Training Loss =  tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  658\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  659\n",
      "Training Loss =  tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  660\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  661\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  662\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  663\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  664\n",
      "Training Loss =  tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  665\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  666\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  667\n",
      "Training Loss =  tensor(0.0128, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  668\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  669\n",
      "Training Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  670\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  671\n",
      "Training Loss =  tensor(0.0278, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  672\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  673\n",
      "Training Loss =  tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  674\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  675\n",
      "Training Loss =  tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  676\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  678\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  679\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  680\n",
      "Training Loss =  tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  681\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  682\n",
      "Training Loss =  tensor(0.0122, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  683\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  684\n",
      "Training Loss =  tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  685\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  686\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  687\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  688\n",
      "Training Loss =  tensor(0.0145, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  689\n",
      "Training Loss =  tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  690\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  691\n",
      "Training Loss =  tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  692\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  693\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  694\n",
      "Training Loss =  tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  695\n",
      "Training Loss =  tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  696\n",
      "Training Loss =  tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  697\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  698\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  699\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  700\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  701\n",
      "Training Loss =  tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  702\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  703\n",
      "Training Loss =  tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  704\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  705\n",
      "Training Loss =  tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  706\n",
      "Training Loss =  tensor(0.0231, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  707\n",
      "Training Loss =  tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  708\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  709\n",
      "Training Loss =  tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  710\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  711\n",
      "Training Loss =  tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  712\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  713\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  714\n",
      "Training Loss =  tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  715\n",
      "Training Loss =  tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  716\n",
      "Training Loss =  tensor(0.0236, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  717\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  718\n",
      "Training Loss =  tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  719\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  720\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  721\n",
      "Training Loss =  tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  722\n",
      "Training Loss =  tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  723\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  724\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  725\n",
      "Training Loss =  tensor(0.0196, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  726\n",
      "Training Loss =  tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  727\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  728\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  729\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  730\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  731\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  732\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  733\n",
      "Training Loss =  tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  734\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  735\n",
      "Training Loss =  tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  736\n",
      "Training Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  737\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  738\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  739\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  740\n",
      "Training Loss =  tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  741\n",
      "Training Loss =  tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  742\n",
      "Training Loss =  tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  743\n",
      "Training Loss =  tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  744\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  745\n",
      "Training Loss =  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  746\n",
      "Training Loss =  tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  747\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  748\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  749\n",
      "Training Loss =  tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  750\n",
      "Training Loss =  tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  751\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  752\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  753\n",
      "Training Loss =  tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  754\n",
      "Training Loss =  tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  755\n",
      "Training Loss =  tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  756\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  757\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  758\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  759\n",
      "Training Loss =  tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  760\n",
      "Training Loss =  tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  761\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  762\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  763\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  764\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  765\n",
      "Training Loss =  tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  766\n",
      "Training Loss =  tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  767\n",
      "Training Loss =  tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  768\n",
      "Training Loss =  tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  769\n",
      "Training Loss =  tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  770\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  771\n",
      "Training Loss =  tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  772\n",
      "Training Loss =  tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  773\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  774\n",
      "Training Loss =  tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  775\n",
      "Training Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  776\n",
      "Training Loss =  tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  777\n",
      "Training Loss =  tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  778\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  779\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  780\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  781\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  782\n",
      "Training Loss =  tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  783\n",
      "Training Loss =  tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  784\n",
      "Training Loss =  tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  785\n",
      "Training Loss =  tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  786\n",
      "Training Loss =  tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  787\n",
      "Training Loss =  tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  788\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  789\n",
      "Training Loss =  tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  790\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  791\n",
      "Training Loss =  tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  792\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  793\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  794\n",
      "Training Loss =  tensor(0.0224, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  795\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  796\n",
      "Training Loss =  tensor(0.0175, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  797\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  798\n",
      "Training Loss =  tensor(0.0339, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  799\n",
      "Training Loss =  tensor(0.0171, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  800\n",
      "Training Loss =  tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  801\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  802\n",
      "Training Loss =  tensor(0.0270, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  803\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  804\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  805\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  806\n",
      "Training Loss =  tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  807\n",
      "Training Loss =  tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  808\n",
      "Training Loss =  tensor(0.0211, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  809\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  810\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  811\n",
      "Training Loss =  tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  812\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  813\n",
      "Training Loss =  tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  814\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  815\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  816\n",
      "Training Loss =  tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  817\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  818\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  819\n",
      "Training Loss =  tensor(0.0189, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  820\n",
      "Training Loss =  tensor(0.0123, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  821\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  823\n",
      "Training Loss =  tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  824\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  825\n",
      "Training Loss =  tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  826\n",
      "Training Loss =  tensor(0.0194, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  827\n",
      "Training Loss =  tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  828\n",
      "Training Loss =  tensor(0.0231, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  829\n",
      "Training Loss =  tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  830\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  831\n",
      "Training Loss =  tensor(0.0155, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  832\n",
      "Training Loss =  tensor(0.0232, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  833\n",
      "Training Loss =  tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  834\n",
      "Training Loss =  tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  835\n",
      "Training Loss =  tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  836\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  837\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  838\n",
      "Training Loss =  tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  839\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  840\n",
      "Training Loss =  tensor(0.0323, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  841\n",
      "Training Loss =  tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  842\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  843\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  844\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  845\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  846\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  847\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  848\n",
      "Training Loss =  tensor(0.0215, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  849\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  850\n",
      "Training Loss =  tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  851\n",
      "Training Loss =  tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  852\n",
      "Training Loss =  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  853\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  854\n",
      "Training Loss =  tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  855\n",
      "Training Loss =  tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  856\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  857\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  858\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  859\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  860\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  861\n",
      "Training Loss =  tensor(0.0385, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  862\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  863\n",
      "Training Loss =  tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  864\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  865\n",
      "Training Loss =  tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  866\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  867\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  868\n",
      "Training Loss =  tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  869\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  870\n",
      "Training Loss =  tensor(0.0098, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  871\n",
      "Training Loss =  tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  872\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  873\n",
      "Training Loss =  tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  874\n",
      "Training Loss =  tensor(0.0093, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  875\n",
      "Training Loss =  tensor(0.0155, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  876\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  877\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  878\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  879\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  880\n",
      "Training Loss =  tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  881\n",
      "Training Loss =  tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  882\n",
      "Training Loss =  tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  883\n",
      "Training Loss =  tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  884\n",
      "Training Loss =  tensor(0.0214, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  885\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  886\n",
      "Training Loss =  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  887\n",
      "Training Loss =  tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  888\n",
      "Training Loss =  tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  889\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  890\n",
      "Training Loss =  tensor(0.0202, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  891\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  892\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  893\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  894\n",
      "Training Loss =  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  895\n",
      "Training Loss =  tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  896\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  897\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  898\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  899\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  900\n",
      "Training Loss =  tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  901\n",
      "Training Loss =  tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  902\n",
      "Training Loss =  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  903\n",
      "Training Loss =  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  904\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  905\n",
      "Training Loss =  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  906\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  907\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  908\n",
      "Training Loss =  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  909\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  910\n",
      "Training Loss =  tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  911\n",
      "Training Loss =  tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  912\n",
      "Training Loss =  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  913\n",
      "Training Loss =  tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  914\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  915\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  916\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  917\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  918\n",
      "Training Loss =  tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  919\n",
      "Training Loss =  tensor(0.0282, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  920\n",
      "Training Loss =  tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  921\n",
      "Training Loss =  tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  922\n",
      "Training Loss =  tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  923\n",
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  924\n",
      "Training Loss =  tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  925\n",
      "Training Loss =  tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  926\n",
      "Training Loss =  tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  927\n",
      "Training Loss =  tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  928\n",
      "Training Loss =  tensor(0.0213, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  929\n",
      "Training Loss =  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  930\n",
      "Training Loss =  tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  931\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  932\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  933\n",
      "Training Loss =  tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  934\n",
      "Training Loss =  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  935\n",
      "Training Loss =  tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  936\n",
      "Training Loss =  tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  937\n",
      "Training Loss =  tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  938\n",
      "Training Loss =  tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  939\n",
      "Training Loss =  tensor(0.0296, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  940\n",
      "Training Loss =  tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  941\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  942\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  943\n",
      "Training Loss =  tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  944\n",
      "Training Loss =  tensor(0.0218, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  945\n",
      "Training Loss =  tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  946\n",
      "Training Loss =  tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  947\n",
      "Training Loss =  tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  948\n",
      "Training Loss =  tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  949\n",
      "Training Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  950\n",
      "Training Loss =  tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  951\n",
      "Training Loss =  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  952\n",
      "Training Loss =  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  953\n",
      "Training Loss =  tensor(0.0090, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  954\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  955\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  956\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  957\n",
      "Training Loss =  tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  958\n",
      "Training Loss =  tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  959\n",
      "Training Loss =  tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  960\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  961\n",
      "Training Loss =  tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  962\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  963\n",
      "Training Loss =  tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  964\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  965\n",
      "Training Loss =  tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  966\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  968\n",
      "Training Loss =  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  969\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  970\n",
      "Training Loss =  tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  971\n",
      "Training Loss =  tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  972\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  973\n",
      "Training Loss =  tensor(0.0204, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  974\n",
      "Training Loss =  tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  975\n",
      "Training Loss =  tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  976\n",
      "Training Loss =  tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  977\n",
      "Training Loss =  tensor(0.0122, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  978\n",
      "Training Loss =  tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  979\n",
      "Training Loss =  tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  980\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  981\n",
      "Training Loss =  tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  982\n",
      "Training Loss =  tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  983\n",
      "Training Loss =  tensor(0.0166, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  984\n",
      "Training Loss =  tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  985\n",
      "Training Loss =  tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  986\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  987\n",
      "Training Loss =  tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  988\n",
      "Training Loss =  tensor(0.0109, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  989\n",
      "Training Loss =  tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  990\n",
      "Training Loss =  tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  991\n",
      "Training Loss =  tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  992\n",
      "Training Loss =  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  993\n",
      "Training Loss =  tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  994\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  995\n",
      "Training Loss =  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  996\n",
      "Training Loss =  tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  997\n",
      "Training Loss =  tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  998\n",
      "Training Loss =  tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n",
      "SHAPE\n",
      "torch.Size([48, 512])\n",
      "Prediction:  torch.Size([48, 1, 1])\n",
      "Epoch =  999\n",
      "Training Loss =  tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "Test Loss =  0.03494667927509454\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def trainSplit(tauredSet, fluxSet, num):\n",
    "    indices = torch.randint(low=0,high=tauredSet.shape[0],size=(num,))\n",
    "#     print(indices)\n",
    "#     print(tauredSet[indices,...])\n",
    "#     print(fluxSet[indices,...])\n",
    "    print(\"SHAPE\")\n",
    "    print(tauredSet[indices,...].shape)\n",
    "    return tauredSet[indices,256], fluxSet[indices,...]\n",
    "    \n",
    "\n",
    "#to test\n",
    "def validate():\n",
    "    loss = np.zeros(32)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i in range(32):\n",
    "            y = fluxTest[i,...].float()\n",
    "            y = torch.reshape(y, (-1,1,512))\n",
    "            prediction = net(y)\n",
    "            loss[i] = loss_func(prediction, tauredTest[i,256].float())\n",
    "        # print('Test Accuracy of the model on the test data: {} %'.format(100 * correct / total))\n",
    "    net.train()\n",
    "    return np.mean(loss)\n",
    "\n",
    "\n",
    "\n",
    "# this is one way to define a network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = torch.nn.Conv1d(1, 3, 5)   # hidden layer\n",
    "        self.pool1 = torch.nn.MaxPool1d(5,stride = 1)\n",
    "        self.hidden2 = torch.nn.Linear(504,1000)\n",
    "        self.hidden3 = torch.nn.Linear(1000, 2000)\n",
    "        self.hidden4 = torch.nn.Linear(2000, 2500)\n",
    "        self.hidden5 = torch.nn.Linear(2500,3200)\n",
    "        self.hidden6 = torch.nn.Linear(3200,4800)\n",
    "        self.hidden7 = torch.nn.Conv1d(3,1,11)\n",
    "        self.predict = torch.nn.Linear(4790, 1)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "#         IT IS NOT AN ISSUE WITH PASSING THE INFORMATION IN\n",
    "#         plt.figure()\n",
    "#         plt.plot(x.reshape(-1).detach())\n",
    "#         plt.show()\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = F.relu(self.hidden4(x))\n",
    "        x = F.relu(self.hidden5(x))\n",
    "        x = F.relu(self.hidden6(x))\n",
    "        x = F.relu(self.hidden7(x))\n",
    "        x = self.predict(x)\n",
    "        return x\n",
    "\n",
    "# net = Net(n_feature=1, n_hidden=10, n_output=1)     # define the network\n",
    "epochs = 1000\n",
    "net = Net()\n",
    "# print(net)  # net architecture\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.2)\n",
    "optimizer = torch.optim.Adam( net.parameters(), lr=0.00002, weight_decay=0.0005 )\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.3)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "my_images = []\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "totalTrainLoss = torch.zeros(epochs)\n",
    "totalTestLoss = torch.zeros(epochs)\n",
    "predictedMean = torch.zeros(epochs)\n",
    "tauredMean = torch.zeros(epochs)\n",
    "a = torch.zeros(512)\n",
    "a = torch.reshape(a, (-1,1,512))\n",
    "# train the network\n",
    "for t in range(epochs):\n",
    "    \n",
    "    x,y = trainSplit(tauredTrain, fluxTrain, 48)\n",
    "    x = x.float()\n",
    "    y = y.float()\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)\n",
    "    x = torch.reshape(x, (-1,1,1))\n",
    "    y = torch.reshape(y, (-1,1,512))\n",
    "    prediction = net(y)     # input x and predict based on x\n",
    "    print(\"Prediction: \", prediction.shape)\n",
    "    if torch.equal(prediction[1], prediction[2]) and torch.equal(prediction[2], prediction[37]):\n",
    "        print(\"They're all the same\")\n",
    "        print(\"They're all\", prediction[1])\n",
    "    loss = loss_func(prediction, x)     # must be (1. nn output, 2. target)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    scheduler.step()        # scheduler decreases learning rate geometrically every n epochs\n",
    "    \n",
    "\n",
    "    \n",
    "    testLoss = validate()\n",
    "    totalTrainLoss[t] = loss\n",
    "    totalTestLoss[t] = testLoss\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, t)\n",
    "    writer.add_scalar('Loss/test', testLoss, t)\n",
    "    writer.add_histogram('Hidden1/weight', net.hidden1.weight.grad, t)\n",
    "    writer.add_histogram('Hidden1/bias', net.hidden1.bias.grad, t)\n",
    "    writer.add_histogram('Hidden2/weight', net.hidden2.weight.grad, t)\n",
    "    writer.add_histogram('Hidden2/bias', net.hidden2.bias.grad, t)\n",
    "    writer.add_histogram('Hidden3/weight', net.hidden3.weight.grad, t)\n",
    "    writer.add_histogram('Hidden3/bias', net.hidden3.bias.grad, t)\n",
    "    writer.add_histogram('Hidden4/weight', net.hidden4.weight.grad, t)\n",
    "    writer.add_histogram('Hidden4/bias', net.hidden4.bias.grad, t)\n",
    "    writer.add_histogram('Hidden5/weight', net.hidden5.weight.grad, t)\n",
    "    writer.add_histogram('Hidden5/bias', net.hidden5.bias.grad, t)\n",
    "    writer.add_histogram('Hidden6/weight', net.hidden6.weight.grad, t)\n",
    "    writer.add_histogram('Hidden6/bias', net.hidden6.bias.grad, t)\n",
    "    writer.add_histogram('Hidden7/weight', net.hidden7.weight.grad, t)\n",
    "    writer.add_histogram('Hidden7/bias', net.hidden7.bias.grad, t)\n",
    "#     predictedMean[t] = prediction.mean()\n",
    "#     tauredMean[t] = x.mean()\n",
    "    \n",
    "    print(\"Epoch = \", t)\n",
    "    print(\"Training Loss = \", loss)\n",
    "    print(\"Test Loss = \", testLoss)\n",
    "#     print(x.shape)\n",
    "    for k in range(48):\n",
    "#         print(x.shape)\n",
    "        s = torch.reshape(x[k], (-1,))\n",
    "        r = torch.reshape(prediction[k], (-1,))\n",
    "    # plot and show learning process\n",
    "        plt.cla()\n",
    "        ax.set_title('Regression Analysis', fontsize=35)\n",
    "        ax.set_xlabel('', fontsize=24)\n",
    "        ax.set_ylabel('Tau', fontsize=24)\n",
    "        ax.plot(s.data.cpu().numpy(), \"r.\")\n",
    "        ax.plot(r.data.cpu().numpy(), 'g.', lw=3)\n",
    "        ax.text(0.6, 0.8, 'Step = %d' % t, fontdict={'size': 24, 'color':  'red'})\n",
    "        ax.text(0.6, 0.7, 'Loss = %.4f' % loss.data.cpu().numpy(),\n",
    "                fontdict={'size': 24, 'color':  'red'})\n",
    "\n",
    "#         ax.set_xlim(0,1.0)\n",
    "        ax.set_ylim(0,1.1)\n",
    "\n",
    "        # Used to return the plot as an image array \n",
    "        # (https://ndres.me/post/matplotlib-animated-gifs-easily/)\n",
    "        fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "        image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "        image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    my_images.append(image)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "# save images as a gif    \n",
    "imageio.mimsave('./taured_prediction.gif', my_images, fps=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3hc1dHG39lV77ItW7ItN3DBxsbYxhAwoRMIvYYWegtxgCRAKPnokAAhQIDQewATSoJDIHQMprlig7ssFwnLsmSrl5V2d74/5t5t2tVeSdu0mt/z7LN7+9lb3jN3zpw5xMxQFEVR+j+2eBdAURRFiQwq6IqiKEmCCrqiKEqSoIKuKIqSJKigK4qiJAkq6IqiKEmCCrrSZ4joeSK60/h9IBGt6+V+Hiei/4ts6ZILIjqYiCqjsN/ziWhhpPerxBYVdCWiMPMXzDwx3HrBBISZL2fmO6JXuthDRGOIiIkoJd5lUZIfFXTFDxUeRem/qKAPAIhoMxHdQESriaiOiJ4jogxj2cFEVElEfyCi7QCeM+YfS0TfEVE9EX1FRNN89rc3ES0joiYieg1Ahs8yP5cAEZUS0VtEVENEO4noESLaA8DjAH5CRM1EVG+s63HdGNOXEFEZEe0iovlENNxnGRPR5US0wfhPjxIRBfnvw4mojYgGBZS/lohSiWh3IlpARA3GvNe6OY+vE9F2Y93PiWiKz7JMIrqfiLYYyxcSUSaAz41V6o3/+hMiupWI/uGzrZ8VT0QXENEa4/yWE9Fl3V1fn/08TkR/CZj3NhH9zvh9PRFtNPa7mohOCrGfLm8VRPQZEV3sM32hUcY6InqfiEZbKaMSXVTQBw5nA/gZgN0ATADwR59lxQAGARgN4FIimgHgWQCXARgM4AkA84konYjSAPwbwEvGNq8DOCXYAYnIDuAdAFsAjAEwAsA8Zl4D4HIAXzNzDjMXBNn2UAB/AnA6gBJjH/MCVjsWwD4A9jLW+1ngfph5G4CvA8p4FoA3mLkTwB0APgBQCGAkgIeD/ReD9wCMBzAUwDIAL/ss+wuAmQD2h5yX6wC4AfzUWF5g/Nevu9m/yQ7jv+UBuADAA8Y1CccrAH5hVmxEVAjgSHjP20YABwLIB3AbgH8QUYmF/fpBRCcCuBHAyQCKAHwB4NWe7keJPCroA4dHmLmCmXcBuAvAmT7L3ABuYWYHM7cBuATAE8z8LTO7mPkFAA4A+xmfVAAPMnMnM78BYHGIY84GMBzAtczcwsztzGy14e1sAM8y8zJmdgC4AWLRj/FZ58/MXM/MWwF8CmB6iH29Yv5fQ+zOMOYBQCekIhsernzM/CwzNxnluRXAXkSUT0Q2ABcCuIqZfzTO2VfGej2Gmf/LzBtZWACpcA60sOkXANhn3VMhleY2Y7+vM/M2ZnYz82sANkCuUU+5DMCfmHkNMzsB3A1gulrp8UcFfeBQ4fN7C0RoTWqYud1nejSA3xvulnrDJVJqbDMcwI/sn9VtS4hjlgLYYjz0PWW4736ZuRnAToiVb7Ld53crgJwQ+3oDUhkMh1jMDBE/QCxpArCIiFYR0YXBdkBEdiL6s+GyaASw2Vg0xPhkQCzgPkNERxPRN4arqR7Az41jdItxTebBW1mfBZ+3CCI618eNVg9gTyv7DcJoAA/57GcX5ByO6H4zJdqooA8cSn1+jwKwzWc6MOVmBYC7mLnA55PFzK8CqAIwIsBfPSrEMSsAjKLgDa3h0nxugwgHAICIsiHunx/DbNf1QMz1ECv3dIjIvWpWSMy8nZkvYebhEMvz70S0e5DdnAXgBACHQ1wWY8yiAagF0A5xZ3U5fJB5LQCyfKaLzR9ElA7gTYgLZ5jhjnrXOI4VXgVwqmEt72vsC8b0UwDmAhhs7PeHEPttMb6DlhFyXS8LuD8ymfkri2VUooQK+sDh10Q00mgcvBFAyMY/yIN/ORHtS0I2ER1DRLkQf7QTwJVElEJEJyP0a/siSAXwZ2MfGUR0gLGsGsBIwycfjFcAXEBE0w2RuxvAt8y8uSd/OmB/50J86aa7BUR0GhGNNCbrIALsCrJ9LsTttBMidHebC5jZDWlz+KvRCGs3Gj/TAdRAXFrjfPb1HYCfEtEoIsqHuJNM0gCY2zmJ6GiIH9wSzLzc2PZpAO8blRkAZBv/rcb43xdALPRg+6iBVJznGP/lQvhXVo8DuMFsFDbcTqdZLaMSPVTQBw6vQKzUcuNzZ6gVmXkJxI/+CETkygCcbyzrgDSGnW8s+wWAt0LsxwXgOAC7A9gKoNJYHwA+AbAKwHYiqg2y7ccA/g9iYVZBBOUMy/+2K/MhDZrVzLzCZ/4+AL4lomZjnauYeVOQ7V+EuIB+BLAawDcBy68B8D2kPWEXgHsA2Ji5FdJm8aXhotiPmT+EVKgrASyFNByb/7sJwJUA/gk5v2cZ5eoJr0LeJDwVFzOvBnA/pEKuBjAVwJfd7OMSANdCKrApADzWNzP/y/h/8wz30w8Aju5hGZUoQDrARfJDRJsBXMzMH8W7LIqiRA+10BVFUZIEFXRFUZQkQV0uiqIoSYJa6IqiKElC3BIxDRkyhMeMGROvwyuKovRLli5dWsvMRcGWxU3Qx4wZgyVLlsTr8IqiKP0SIgrVM1tdLoqiKMmCCrqiKEqSoIKuKIqSJKigK4qiJAkq6IqiKEmCCrqiKEqSoIKuKIqSJPQ7QV+4EPjjHwFnb8bAURRFSWL6naB/8w1w111AW1u8S6IoipJY9DtBz8yUbxV0RVEUf1TQFUVRkgQVdEVRlCRBBV1RFCVJUEFXFEVJEvqtoLe2xrcciqIoiUa/FXS10BVFUfxRQVcURUkSVNAVRVGSBBV0RVGUJEEFXVEUJUlQQVcURUkS+p2gp6cDRCroiqIogVgSdCI6iojWEVEZEV0fZPn5RFRDRN8Zn4sjX1TzWEBGhgq6oihKICnhViAiO4BHARwBoBLAYiKaz8yrA1Z9jZnnRqGMXcjMVEFXFEUJxIqFPhtAGTOXM3MHgHkATohusbonK0sFXVEUJRArgj4CQIXPdKUxL5BTiGglEb1BRKXBdkRElxLREiJaUlNT04viCmqhK4qidMWKoFOQeRww/R8AY5h5GoCPALwQbEfM/CQzz2LmWUVFRT0rqQ8q6IqiKF2xIuiVAHwt7pEAtvmuwMw7mdlhTD4FYGZkihccFXRFUZSuWBH0xQDGE9FYIkoDcAaA+b4rEFGJz+TxANZErohdUUFXFEXpStgoF2Z2EtFcAO8DsAN4lplXEdHtAJYw83wAVxLR8QCcAHYBOD+KZUZmJtAHF7yiKEpSElbQAYCZ3wXwbsC8m31+3wDghsgWLTRqoSuKonSl3/UUBVTQFUVRgqGCriiKkiSooCuKoiQJKuiKoihJQr8VdIcDcLvjXRJFUZTEod8KOgC0t8e3HIqiKIlEvxZ0dbsoiqJ4UUFXFEVJEvq1oLe2xrcciqIoiUS/FnS10BVFUbyooCuKoiQJKuiKoihJggq6oihKkqCCriiKkiSooCuKoiQJKuiKoihJggq6oihKkqCCriiKkiSooCuKoiQJ/VLQbTYgPV0FXVEUxZd+KeiADnKhKIoSiAq6oihKkqCCriiKkiSooCuKoiQJKuiKoihJggq6oihKkqCCriiKkiSooCuKoiQJlgSdiI4ionVEVEZE13ez3qlExEQ0K3JFDI4KuqIoij9hBZ2I7AAeBXA0gMkAziSiyUHWywVwJYBvI13IYKigK4qi+GPFQp8NoIyZy5m5A8A8ACcEWe8OAPcCaI9g+UKigq4oiuKPFUEfAaDCZ7rSmOeBiPYGUMrM73S3IyK6lIiWENGSmpqaHhfWFxV0RVEUf6wIOgWZx56FRDYADwD4fbgdMfOTzDyLmWcVFRVZL2UQTEFnDr+uoijKQMCKoFcCKPWZHglgm890LoA9AXxGRJsB7AdgfrQbRjMzRcw7OqJ5FEVRlP6DFUFfDGA8EY0lojQAZwCYby5k5gZmHsLMY5h5DIBvABzPzEuiUmIDMyd6a2s0j6IoitJ/CCvozOwEMBfA+wDWAPgnM68iotuJ6PhoFzAUOsiFoiiKPylWVmLmdwG8GzDv5hDrHtz3YoVHBV1RFMWfft1TFFBBVxRFMVFBVxRFSRJU0BVFUZIEFXRFUZQkQQVdURQlSVBBV5QBQn09cNppQB+zbvRrFi0CLrsseXuY91tBz8qSbxV0RbHGkiXAG28AX30V75LEj//+F3jySaCxMd4liQ79VtDVQleUnmGK2K5d8S1HPGlqkm8V9ARDBV1ReoYpYnV18S1HPGlulu+GhviWI1qooCvKAEEtdLXQE5aUFPmooCuKNVTQvYKuFnoCooNcKIp11OXidbmohZ6AqKArinXUQleXS0Kjgq4o1kkEC33FCmDr1vgdXxtFExgVdEWxTiJY6GecAdx4Y/yOrxZ6AqOCrijWMa3SeAp6bS1QXR2/46ugJzAq6IpiHVPE6usBtzs+ZWhqip/Lx+0GWlrkt7pcEhAVdEWxjinozPERtI4OwOGIn6C3tnpzuKiFnoCooCuKdRobgexs+R0PUTXdHfESdPP4gFroCYkKuqJYg1kEfcwYmY6HHz3eLh8zwsW3LMmGCrqiDADa2wGnMzEE3axcYo1poaenq6AnJCroimINU8BGj5bveLpc4nV800IfMUJdLglJZqY0dCiK0j2moCeChR6v45sVyogRaqEnJGqhK4o1AgV9IFrovoLe2iouqGSj3wu6ywV0dsa7JIqS2JiCPnSoPDfxttDj6XIZPrxreZKF/ifoa9YAL74IMGtOdEWxiCleeXnAoEHxdXkA8bXQR46UbxX0ROCdd4DzzgOam1XQFcUivoJeWBgfQY23hW4KummhJ2PDaP8T9IIC+a6vV0FXFIuY4hVvCz0rC0hNjZ/LJT0dGDxYpgeshU5ERxHROiIqI6Lrgyy/nIi+J6LviGghEU2OfFENCgvlWwVdUSyTKBa6WaHEy0LPzQXy873lSTbCCjoR2QE8CuBoAJMBnBlEsF9h5qnMPB3AvQD+GvGSmqiFrig9prERSEsTCzWeFnpubvwqlOZmOX5enkwPVJfLbABlzFzOzB0A5gE4wXcFZvat67IBcOSKGIAKuqL0GNM6BuIn6GYZ4iXoTU1ATo73PAxICx3ACAAVPtOVxjw/iOjXRLQRYqFfGWxHRHQpES0hoiU1NTW9Ka+foGdlyU8VdEXpHl9BLyyUZ6a9PbZlaGryCno83xAGtMsFAAWZ18UCZ+ZHmXk3AH8A8MdgO2LmJ5l5FjPPKioq6llJTUxBr6tTC11RLBJooQOxt5IbG+PvcsnJkTh8u33gulwqAZT6TI8EsK2b9ecBOLEvheoWs3pVl4uiWCbQQgdiL6q+Fno8G0WJpBwD1UJfDGA8EY0lojQAZwCY77sCEY33mTwGwIbIFTGA1FRJ6qyCriiWCWahx9rt4WuhNzTEPoWu2SgKiF2YjBZ6SrgVmNlJRHMBvA/ADuBZZl5FRLcDWMLM8wHMJaLDAXQCqANwXjQLjYICFXRF6QGNjcBkIzYtXoLua6GboyaZbwuxOn5OjvxOVgs9rKADADO/C+DdgHk3+/y+KsLl6h4VdEXpEfF2uTgcMgRdbq6/Dz9Wgs7sdbkAYqEno6D3v56igAq6ovSQeLtczG73poUOxL5Ccbm8gp6Xl5wul/4p6IWFQH090tKkgUMFXVFC43DIxxT0/Hx5bmIpqKY1bPrQgdge36xQkt3l0j8F3bDQiTQnuqKEw7fbPwDYbPIIxdtCj8fx1eWSiBiCDqigK0o4AgUdiH1v0Xhb6GYudF8LXV0uiUJBgSfuSQVdUbonmKDHOhY83j70QAs9L8/rikom+q+gu92enOgq6IoSmkSz0DMzJVFYPCx0X5eLb7mShf4r6ICn+78KuqKEJtEsdKL4Hd/X5QKooCcGARkXVdAVJTSJZqED8RN0tdATERV0RbFMKEGvq4td9/tACznWg1wEulySNSe6CrqiJDmhXC5ut//AzdEuQ3a2ZDk0j68ul8ijgq4oSU5jI5CSAk/PaiD2vUXNPC4msc6J3tQk5yA9XabV5ZJIBIwr2toa3+IoSiJjdvsnn5ENYh06aGZa9D1+rF0uOTnec6Aul0TCvBpqoStKWHzzuJgkgoXe0CD5VWJ1fN8KRV0uiURKilwdFXRFCUtDQ/wFPZiFbpYtFvjmQgeAjAyJhVdBTxR8Mi6qoCtKaIJZ6LF2uQSz0GN9fLNB1CQZu/8nhaB3dMTu1U1R+huJ4HIJZaHHUtB9jw8kZ8bF/i3oPgNFx3oEc0XpLwQT9MxMifiIl4Ue64GqA10uQHIOQ9e/BV0HuVCUsAQTdCC2vUUTwUIP5nJRCz1RUEFXFEvEW9AdDqCzM7gPPZZRNsEsdBX0RMEQ9KwsmVRBV5SudHbKsxFM0GMVCx6Yx8U8NhBbl4s2iiYyBQVAYyMy0yUZhQq6onTFN8thILGy0IOVIZY+/M5OeUvQRtFEprAQYEYmSzdRFXRF6YopWGZXd1/iaaHH8viBiblMTJcLc/TLECv6r6Ab+VwyXXK1VNAVpSvBEnOZxMpCD1WGWAl6YGIuk7w8sd6TKUKu/wt6p9wtKuiK0hU/Md28GSguBtauBSCC3tIi/TiiSWAucpNYC3puLoDXXwcmTwaczqTs/t//Bb1DWjVU0BWlK2ajX14egBUrgOpqYNEiALFrmIy3he7nclm0CFizBqiu9rihkqlhtP8LuqMegAq6ogTDT0y3b5eJLVsAxK63aCgLPVaDXPi5XGpqZGL7drXQEwpT0NvljlBBV5SuBBX0rVsBDBwL3a9C2bFDJqqqkjInev8X9NadAFTQFSUYfmJaVSUTcbLQc3IALFkClJcDiF0KXdPl4mehV1UlZU50S4JOREcR0ToiKiOi64Ms/x0RrSailUT0MRGNjnxRAzCuhgq6ooSmsVEGdcjORhcLPVaC3tgoYmqzATjzTOB6kRCfcWqiSigLfUC6XIjIDuBRAEcDmAzgTCKaHLDacgCzmHkagDcA3BvpgnbBbgfy8pDRXAtABV1RguE3WpGvoDPHzOXiSczFDFRWSrQNYufy8TSK5rCfD32gulxmAyhj5nJm7gAwD8AJvisw86fMbA4E9w2AkZEtZggKCmBrqEN6ugq6ElvWrgXeeCPepQiPXx4XU9Db2oCaGs/QvLGw0HNzIcre3h4xHz6ztRjypiap0LK4xSsUVVWeRtqB5nIZAaDCZ7rSmBeKiwC815dCWaawUAe5UGIOM/DLXwLnnpv4vQw9gs4sgj5hgizYuhV2u/SWjJmFXl0tM6qrAYejz4L++usSVm9a4N0dPycHoNoa78yqKqSlychFA81CpyDzgt7GRHQOgFkA7gux/FIiWkJES2pqaoKt0jN01CIlDvzvf9K219aW+GLgEfSGBklosu++ssCnYTRmFrrpvwaAyso+C/qyZfK3DIM/JJ5c6ObxBw3yvK0kW050K4JeCaDUZ3okgG2BKxHR4QBuAnA8MzuC7YiZn2TmWcw8q6ioqDfl9UcFXYkxzMBtt3mnTS9GotLYaORxMSNcZs+Wb5+G0VhEufhZ6ABQUdHnQS4qDL9BuGvgyYVuGpHTpsn5YE66BF1WBH0xgPFENJaI0gCcAWC+7wpEtDeAJyBiviPIPqKDCroSYz78EPj2W+C002S6Pwi6Xwz65MkS8mJY6LGIBfdY6L6CvnVrny30ykr5DncNuljoe+0l+Q7q6pIuJ3pYQWdmJ4C5AN4HsAbAP5l5FRHdTkTHG6vdByAHwOtE9B0RzQ+xu8iigq7EENM6Ly31RN71P0EvKQFGj04ICz0jQ3zYvT1+ry30qVM9GyZbTvQUKysx87sA3g2Yd7PP78MjXC5rmDnRMxhtbcFc/YoSOT75BPjqK+DRR0UTgcQX9IaGIII+alTMLHTmAAt9yBBZYKhxb4/vdlu30JuagJEjIRZ6Vhaw226yoKoKeXmTsXFjz4+fqPTfnqKAt7doqhOtrWHWjRBtbcCsWfJwKwMH0zofMQK46CIRotTUxBZ0l0uyKXoEPT1dHOqjR3dpFI1WtI7DATidPhb6sGFSofiELvZG0HfskNS3QA9cLjU1wNChUqkBnu7/A8rlktCYgm7viJnLZc0aYOlS4LPPYnM8JTFYsAD44gvgD38QXbTZRJsSWdD9Rgravl1i/IhEUHfuBFpaMGiQCL+5bqTxG9yiuloEtbS0zxZ6hU8gtWWXy44dQFGRV9CT0OWSJILuiJmgb9gg34aBowwQbrtNdOCSS7zziosTW9C7JOYqLpYZpr8oAg2T4fCrVEwLvbS0zxa6KeijRlkTdD8LPTdXxsAzuv8n06hFySHo1B4zQV+/Xr7Dxb4qycPnn8sb2XXXSSOeSb8S9Koqr6CPGiXfW7dGPZ+Ln4W+Y4fX5dLYCDQ29lnQ99nHG5EZDJcLaG31OX5RkbyllJR4XC5ut7imkoH+LeiGeZGJNhV0JWrcfrvo0KWX+s/vV4IezELfsiV2Fnq6QyZMCx3wxKL35tiVlVK5TpkC1NZ6/emBmEKdk23kcTH7vxiCnmwJuvq3oJsWurs15oJeUSE1u5LcfPkl8PHHwLXXSoCEL8XFYvRFO/1rb/EIepZTVM/0HQ8fLsntYmmhd0hWVI+FDnhcPo2N0nDaEyoqpF4w/9KOEL1fPIm5UtulhXboUJlRUpKUCbqSRNBb0NYWfT8Yswh6RoZYBL5htUpycvvtYtRdfnnXZcXFUqnX1sa+XFbwCLrTCGMxLfSUFAnX2bIl6oLusdAdRgx4gIXe2xS6pqCbfynUm5InF7vbOBmmhV5cHJec6C0t0lE1Wond+reg5+YCRMhyyVVzBE04EDlqa+XGmzNHptXtktzs3Al88AFwxRVGPvEAwolJvDEFPb/dsDzMAgOezkXRdrl4LPRWowzDhol1bLwh9Pb4FRUSW25V0HOdxgF8LfSGBnEFIXYW+qZNwPffR++trn8Lus0G5Ocj0ylXLdpuF9PdcrjRjUoFPbkxI5pmzgy+vL8Iel6L0WroK+hG56KsLCAtLQYWerOR/mnYMHlDGD7cz0LviaC7XMC2bf4ul1DXwONyMV0+vj50APkd8uYQK0E3BmvCuHHR2X//FnQAKChAZoe8L6mgK5HEFPTx44Mv7y+CnlNnhIQEWuiVlSCXM6q9Rc0yZNcZ3TpNC9kIXeyNoFdViaiXlkr9AFhwubTV+B/fOBd5bfLmECuXiynoY8dGZ//JIegOccDFQtBTUyW3T26uCnqys2GDvASGsqbCiUm8aWiQ+9S2wyigWWBABN3lAqqqoprPxYwBt9VUS5tXerosGDWq1xa62eW/tFTaswoKLLhcTJdPgIWe1/QjgNha6Lm5wODB0dl/cgh6u9yNsRD03XaTN0afdBhKkrJhg+heWlrw5Tk58klUQfdLzFVQ4B9Eb0aaGA2j0Yxy8eslalJaKjnR8yVUrCeCbsagm22rRvtmUDwul5btcrEyM2WGKeiNUjvE0kIfN84YEjAKJIegt8ZO0M0BX3wS1ilJyoYNod0tJokci+4n6Kaz2SSgt2g049Dz8uDtVGQyapSMWuQUV0hfBT2sy6W+0mudA5IkzGaDvXobsrNja6FHy38OJI2gS4NHNAXd7ZYH3BR0n/xCShLCnGSC7us/B+JjofsKuqHGGTUVyMzsuaDn5MATQ97dNTAt9Jz6Sv83BLtdyuPT/T/auN0S5aKC3h2FhchskUDgaAp6RYWERfoKupHfSElCamrkId999+7X67eCnp0tjtxYWeiBgh7QuagnFYoZsmi6LcJZ6JmZgL1mu7+FDvh1LoqFy2X7dhnUWgW9OwoKkNkWfQvdjHDxFXTAP+ubkjyEi3Ax6ReC7pvHxRejIWjQIBG+UN3n+1qG3Gy31BhBLHSzYbSnFnqpz6CYJSViWAUbLLpLYi5ffDoXxcJCj3bIIpAsgg5R8ngIurpdkpOyMvm2Iuj19WJ5JRqNjUBeZqeoXTBBN/Ki93Vsz+5oagLy0owH01fQBw+WRtpevCEECnp34aOSC529ibl88UnQpYKeKMRQ0HNygiasU5KQDRvEzRouXti8HxIxDURjI5BnN3yCoQR961YUFkjOjGgIemMjkEtGGXwF3czL3kMLvbNThNuqoDc1ATmZbtkw0EIvKQF27EBeLsfE5VJeLn/bbI+OBiroFjEjXEy/3fDhEqOsgp6cbNgAjBkj/Q66I1E7F7ndhnUMw/QMjHIBRFCbmzEoTXwVkW4YZTbKQEYZfAUd8Ax00RNB37ZN9tsTQc9N75CJYBa62428tLaYWOibNonv3wzFjwYq6BbxDVkE5EEfPlxj0ZMVKxEuQOIKekuLCF8+G0oZykIHUNguQdyRttDb2yWLYq7LyLwVKOhGqFhPBD0wZBHw/rVgsejNzUamRaCroBsb5tuaY2ahR9PdAqigW8LhADZv9hd0QEMXkxWrIYtA4gq6J4+LmcMkVKMogEHNchNH2kL35HHpNHYc6PIoLQWqqlCY50JTk7UUuqagjxzpnTd4sLjHQrpcbK3Bj292LuIGNDVFPx12eXn0uvybJIWgp8CFFLs7aoJeXi4XO1DQtXNRclJdLZZdt4L++OPAued6NCJhBb19h6hdsL7mhoU+qGETgMgLuqcMjhoJkwxMWTlqFMCMQTax4K2k0PWz0CsqgPvug93GGDq0m0ZRMsJfgrlcAOS56jzrRou2NnEXqYUeDjMnekpn1AQ9MMLFxGjT0YEukgwzZDFkDPr8+ZJT96WXkNrRgiFDEk/QTRdCXkuVuDpsQR71oiIgIwMFNfKHI+1y8cujEuhuATx+k0KX9d6iFRXSoSg3F8DTT8u4gBs3miHlQcuQ4zZORiiXi5FxMZpul82b5VsFPRw5OYDNFhNBD7TYRo3SgS6SkW5j0FeuBM46yxhGHsD69QkZi+6xjpt+DO5uATyRJikVm5CXF0ULvXlb94LeJs5vK8evrPTxn3/3nXyvWxf0GjAbFrqzXmoA31w2gCezV17rdr/yRoNYhCwCySDoNpv40W2OqAp6UZHnZcCDhi4mJxs2SAK2MWMCFlRXA8cdJzeCOeTM2rWJLegNFaEFHVBCPfsAACAASURBVPAb6CJqFnpDZfeC3iIJsqxa6F0EPcQ1aGuTt+fcjp1d/ecmJSXIb5Fc7SroiUJBATKpHa2t0dm9bw4XNDcDe+4JvP++CnqSUlYmjVcpKT4z29uBE0+UHofz5wM//alYuCGsw3jjEfSdm4KHLJr49BaNmoVetyW4oOfkAIWFKKwXH36PBL2uzvvgGYJeXe3v/vQk5mqv7epuMSkuRl6jOOaj6XIpL5cxaUPVK5EieQQdbVG10D2CvnAhsGoV8J//JKSgmzex0nu6RLgwAxddBHzzDfDSS8CMGfK6PmaMn3UY7TFte4JHTGvLw1vo1dUYUeLCpk3RKUNu3dbggg4Ao0ahsNaaD9/hkA6fpaUAVqyQmWlpnkrV5ZL8Siae1Lmt27u10PN2bfErbzSIdtpck+QRdG6NiqA3NUl8q0fQFyyQ7+XLPY0zfRH0Bx8Ezjuvz8UEIPd4YaHojtI7mMVC9xP0u+8GXnkFuPNO4JRTvPMnTfKISXt7Yo0c7xFTd333gm5YJXuPrcfatZFNNucJW0RDaEEvLUVh9VoA4QXdHNhi5Eh43S0/+5mnUgX835Q8Lp/mqtAWekkJ8neKPyTaFnq03S2ARUEnoqOIaB0RlRHR9UGW/5SIlhGRk4hOjXwxw1BQgEx3S1QE3Wwg6yLo330Hcrv6PNDFq68CL74I/PBDn4oJAHjvPbFSPvus7/saqFRViah5BP2NN4A//hE4+2zgxhv9V544UQR9qLznJ5LbpbERyMpwIwWu8BY6gJlDK+F2ew3fSJWBiJGNlm4t9PTKjZZS6PqFLH73nfyvgw4CampQnCU1mG/nIo/LpWFbaAu9uBh5xiDa0aqQmX0EnVke+Ci91ocVdCKyA3gUwNEAJgM4k4gmB6y2FcD5AF6JdAEtUVCATFdzVATdL2SxtRVYvFhMhNZWYP36PnUucrlkBHAAeOqpvpfVFPKlS/u+r4GKX4RLczNw/vnAfvtJiFzg+/KkSUBbG4rtEvaWaIKel2WkT7Qi6FlrAADLlkWuDE1NQG6mEwR0a6Gjrg6DCt09E/QVK4Dp0+UaAChp3QjA/xp4XC7u+m4t9Bw0g4ijJug1NSIX48ZB+v+fdx7w7rtROZYVC302gDJmLmfmDgDzAJzguwIzb2bmlQDiE5FdUIDMzqaoCTqRDD2Hr7+W7my/+Y0sXL68T52LysqkJT4vTyrtvpTf6QS+/FJ+R/Kh7CmHHw789rfxO35f8YtB/+YbMddvvbVryBsgFjqA4pauYhJvGhuB/HSjy3t3gj5iBECEEY1rUFQUWWOgsdEnj0p3gg6gMLvDustlaIe0Y02f7r0GtfKKG8zlkoPmbn3oNjBys1xRc7n4Rbh8+61M7LtvVI5lRdBHAPDN+l1pzEscCgqQ6WpCW1vkW6XWrxc3Y2YmxN1iswEXXywZdpYt69NAF+br7S23SC85MxKuNyxbJhbJjBlyA0VrwILuaGkBPv0UeO21xGog7AkbNkienlGjIA3gNhvwk58EX9mwDot3rgKQeIKeZzfCvroT9LQ0YPhwUMVWzJwZWUFvagLyzDwqoQTV8OEXpreFjbKpqJAOr1lb1kgHkL32kobptDTkbP4B2dkhfOho6tZCB4C8dEfULHRT0MeOhRgJmZnA1KlROZYVQQ/WLturx5WILiWiJUS0pKampje7CE5BAbLQirbW6Ai6n/98xgxg0CC5IMuX92mgi5UrpVf2FVeIRdgXt4vpbjGt43hY6cuWSdhYVZUYUP2RDRvEkkpJAfDFFyIaeXnBVx42DMjLQ2HFSqSmJqCgU5N3JOvuMBqCZs4EVq+OXE6kxkYg194ixk+oc2ha6CmNllwuHv85IBZ6Sor4x4KEj3pcLmjq1ocOAPlRzLhoCvqYMRALfdasgJjYyGFF0CsB+OQ2w0gA23pzMGZ+kplnMfOsolA1Zm+IUtgis4+gt7fLxTjoIFk4Y4ZY6KVSifTG7bJihRh5GRnApZeKfqxZ07uyLlgg+zr6aJmOhx998WLv7w8+iP3xI4EnwqWzU6ypOXNCr0wETJoE27o1GDYssQS9oQHI4zARLiaG33DGDGnXWbkyMmXwpO8dNix0vJ7h8inkXdYFfcUKsXLNluuJE4N2LvJzuYTSm4ICID0deVHMuFheLi8CWXYHsHy5tMlECSuCvhjAeCIaS0RpAM4AMD9qJeoNhYUi6O2RDfKsqZEHY8IEiJg7HF5B33tvoL4eo2zi2OutoO+1l/w+7zx51e+Nle50SmVw8MHySjp6dHws9MWL5YGbNKl/Crrb7SPoy5dLS9aBB3a/kRnpkmCdixobjSyHVgTdSEo0c29pAouUMdDYCOS6uglZBOSmLylBYWeNJUH3hCxOmyavt4DccBs3oniou4uFnmZ3Ig2dwJAhwXdKJLHo3BhVC33cOMg91dERX0FnZieAuQDeB7AGwD+ZeRUR3U5ExwMAEe1DRJUATgPwBBHF9oXbsNBdLorouIh+ES4LFsjFNy22GTMAAMO3LenVQBe7dskNagr60KHASScBL7zQ8+HMvvtOrBGzrom0L9QqixcD++wDHHkk8PnniTksW3ds2ybuhvHjITUk0L2FDoiYVFaieIgz8QS9o8a6hd7RgVHp1Rg8OHL3TlMTkNe5s3tBB6RzUds2NDeHHte0tVWemdKRLDe8+eAAcg2cThRnNnSx0HNT2yWbV3ejShQXI9+1K6oWeiwaRAGLcejM/C4zT2Dm3Zj5LmPezcw83/i9mJlHMnM2Mw9m5ilRK3EwopQT3U/QP/9crILCQpk5dSpgtyP1+2W9GujCfK31vS8vuURu2rfe6tm+zNB4X0EvK4vNSOYmu3YBGzcCs2eLoLe1eaNu+gt+IYsLF0poU3fd5gFvlEVGfcIIOrMh6K3V1gUdAG3dYnoSI0JjI5DrqA0v6KWlKGyWRqhQVroZ4VKavUtWmj7du9C4BiW0HXV1XkNCcqG3hXa3mJSUIK+jNioWusMhZR83DuLCGzlS3ExRInl6ikZJ0FNTgdElHcBXX3kVExAf3h57eCJdemqhmxEuvoJ+6KFy4Z98smf7+uwzqXRM7TFeHrB8ec/20xeWLJHvffaR05Sa2v/cLh5B351F0MO5WwCvoGM7duwQH3S8aW0V91GeY4d1lwsAbJVIlx9+6PvblQw/x8hrC5E615fSUuxR/zUA4KOPgq/iiUFvXSc/ggh6cftmAN7sp5ILvZsGUZOSEuS1V0dF0LdskXPhsdCj6G4BVNC7Zf16iT6xL18iO/YVdED86EakS08FfeVKMRx873WbTaz0BQuAdeus7cflEu+Ab9FmzpTvWLpdzAbRmTMlqGL//YEPP4zd8SPBhg0SxTeyZR1QWxve3QLIDWKzodixBW63bBZvPHlc0Bj+DQPwjlpsRLo4nd4Ob72lrQ1wuQi5HMaHDgCjRuHQzv9hwm5OPPRQ8FU8gr5jqbg+fcP+8vOBkhIUN8hDY74pSS70bkIWTYqLkd9ejZYWa6Mm+VJeLm7x7pYDwLiCXdKpKIruFiBZBD07G5nkABB5Qff4zwHJsOfLjBlAVRVGD2nu8UAXZoNoYOP/+edLRNPTT1vfT0ODNIiaFBVJ42QsBX3RIjGU8vNl+sgj5Q1hx47YlaGvbNggXhb7V4b/3IqFbiTpKm6QfCSJ4HbxE3QrFnpenlw4Q9CBvrtdvHlcGi1Z6DYwrjy1CosWBc9FZAr6iE0LpRINDMWcNAnF1fLa6yvoua46axa6MZh2T5LbrVgh+nD33aHXMROejdtpWDxqoVuACJk50uIdKUF3ucQP7RH0KVO6tpQbvo1R7i09GujC6ZTXWl93i0lxMXDCCcDzz4v/LRyB/nPfosXaQt9nH+/0EUfId6hX6ETEk2Xxiy9EBKwMKgqImOwQk7ZfCjogVvrmzRgzRpqJ+nrveJKDdRcDbmK4fM6dvhJ5ecDf/tZ1lYoK2U36D0v93S0mEyeieOsiAN5r0NzMyO3YZcmHno8Gv3KHgxmYO1d04qmnQlv25eVS5xdv+EKickx/aJRIDkEHIi7oFRUiqBN2c0nrXqBiAp4ba1SjdDu26nZZv172vddekD7/11zj17Xy0kvl1f3f/w6/rwULxKocMQLSKjl1KrBmDWbOlOPEIgPgjz9KZyJfQTf7X/UXt4vbLafP0yA6Z471XKcTJ6K4Qiywfivos2YBCxeCOjsiYgz01EIHgNzaTbjoIuD11+We8qWiAigd7pKLFEzQJ03C0AaJYvBY6A1u5FipUHwsdKuBBK+8IrfJiSdKdNR77wVfzxwY2vbt1/LAZ2VZO0AvSR5Bz5WeV5ESdE+EC9ZL60qguwWQV9Xdd8eoKglHsirofg2id98N3H+/9Jc3OPxw6VUWrnHU7ZbgG4+75ZFHxPR/4QXPq7PZqS6amP5zj6Azw26X//HBB/0jDUBlpVSy44vq5D3ZirvFZNIkDHNImFMiCXo+GsNbpyYnnyxq9sknmDlTfOjd+YatliEXTeEFvahIwgq3bvVYvY895r9KRQVQmmuMIh3s1XbSJKTCiSH5nV4LvYm77/ZvUlzsEXQrBlBTE3DttXK/z5sndWaoZ7W8HBg3luUhibK7BUgmQc9PAxAFQf/xU/kRzEIHgL33xqgNHwPomaCnpgKTUsqk9TM9XRJ+GS1qZuPoJ5903zj6/fcSwXXQQZA//sILsuDNNzFzhqhoLNwuixeL33/6dEjFd8UVAMTtsm1b73u/xhJPhEuzUQNaaRA1mTgROWhBTmZixKJ7LPRBKXKjWeGwwyS5/1tvYcYMiQfvS0pnj4Vub/WG+obCZpNwvooKjBsHHH888MQT/pE2lZVAqc0w20O4XACgJKfRa6G32Ky5fIYOlcoP1iz0O+6QN9KHH5ZH98ILJXmiGVppYqbNHZu/S05IlBtEASA6CQWiyDvr38HL378Mh9MBh8vh+a6f6gIWA1fO/wPuql6AVHsqUm2pSLOnIdWeCjvZ4WIXXG5Xl28AsJENNrKBiEBsx7K/34vUnLE4p/kW8OWZcL9/JtzsBjP7b7/nNnQO3gbbc8248z9v4an0u5GZmomMlAxkpmR6fmekZMDpdsLhdODL/92EtOJBOPitI+C4FODdRiCtbBPS75uCtD2nId2eDvfgoUjJeBQHnbYRh/zfn0A2BgW4ANa8cySA8/Ba8xX4z6NL4T6iDjxyBBzby9DxrwOQVvA27nptKV7MugEdLjG3zLKk29M9v9Psaeh0d6LD1eH5OJwOdLg64Ga3nBNQl28Xu+B0O1H21qOwFxdi+mM/h2vvzbDzF8h4eAGodTyAt3Hy3Y9jwjHvItWe6rd/8/qZ8zrdneh0dfp9u9ntOZcZKRl+59Zus8s1A/lfPxDYSDfExusBg8HMcLMbbnZ7rqH5e/unJwK4AVc0XAX7XIL7m1/C9bUsT7OnITM1E1mpWchKzUJmivy22+xo6WhBa0s9Wi4AOt+uwDOfr8abD/wKdpsdafa0Lp9UW6qnrIEfhrd85oeZPf8lGJ2uTs+5M89jzadnALgFR5++DTlPzpLrnZLuue4M9ty/bnZ7f1+eCa5/Hq2bmgC8itMfugfDDpoPZkaKLaXLJ9We6jnXvuVkZmz94kAAv8fck1uQ8vxP/e4tIupyTtKO2YUU1/vgV47BjslTUPv2vZgx9y8YduB/0dGajoaG/+Ed27/x3SUp4PfP8GSYIpDxrKcg9Rwbqr9cgx9XDcNZ/7wbnc7n8N7kZmzZcj/4zWe81974v063Ey63fDee1gq8Dlz99s24ddt7cLqdnk+nqxMMRqotFe6aCdhw/1soOuBdXLv6L0hdl4q2whK43f/AAb95BqXHPec5TmdzHhobP8D/Gp/C0WcDaR0vIPWf85FmT8NFe1+Ew8YdFiFV9NLvBH1783Ys3bYU6SnpSLenI82ehvSUdBSmSYhJvn0Y8jPyPYLQ0tmCTlcnXOyCneyw2+yebxvZYCfxvTMYne5OMDO2fXQK6tZMx9hz70JbSx1sg4fAxm4QCHabHamUihRbCuxkR0qBHfbV27B10A5kt+6BacOmod3ZjnZnO9qcbWhqaUJbZxvane1IsaUgPSUdDVtGo3CPZciubcQg5IBKJ6OjldCxeSNaiipRl5cNh3sLBp14N6rn3YGPX98d+Qf6p5pnZmxfeh5SB1egzPUJbNVbQcPTQKNzkN4MpO2oQO6Y9Wiv2AOleaVIT0kHM8PhcnjK19zajHZnOzpcHUi1p/o9ZNlp2Si0F4rQGA9r4HeKLQU22LGqYipG7vct9m7Kgb0ScNuA9kIX2id0YH3xVlSvmIbMA59Ap6vTs//0lHTkpuViSNYQvwc71ZaKVLucX1P8HC6HnENXu+dctjnb5GGE0yN8HhEEeyoeQB56ACAizzW32+xISUnx/K6pmwRbqgOT2rciJb0I9uJpsJPcIx2uDrR2tqLN2YZGRyO2N29HW2cbnG4nstOykZ2ajSyyIzurBimOMThs3GFwsztoBdnmbPMrq28FEyjwZkUVWJH73gPmtfK9dmvTJmMngMk2Gzpyij3Xu6G9AQ6Xw7P/wOfAVjQYVLMDWRlrkZLZjLaKychKlVZtU/jane0ickala+Jb2QPArnrxv3FuK9JThiIvPc9jXAHwOzcdrg60ZtnR2dwAW8sO0NhaZI7YiC3vn4jB+89Hxy5x2WSmbkJKdi5gT/UcxzzPzR3N6BySjo6sCjRXjcGXZeLXrBzShJbGdbC1+VeknufXliLnIFte7VM7B2No9tAulReB0OHqxIInb0BKRjsmn/kP2GwpcDgdsA/egoLJS1D9xTHY/YTXYLeLgVi/TRrVUzLWYGeuHZ2uXeio3Y4OVweOm3Bcr/QvLMwcl8/MmTM5kmy7/DYGmB97rG/7WbOGOSOD+ZhjmN1LlzEDzP/4R+gNqquZAT560kbee+/w+6+pkV3+5a425tRU5muukQUOB/OUKcwjRzI3NDAzs9vNfMQRzNnZzBs3+u/H5WIeNIj5/POZ+YcfZKf33ScL58xhnjaNb72VmYi5qann58EqGzbIoZ98kpn33FOOfdJJUriWFp47lzkri7m9PXpliATHHcc8ZZJTTthtt/V8B/vuy6cWfcaTJkW+bD3l2muZM6iN+dxze7ZhU5Pc/FdeyYccwrzPPr0vwz33yH3RdPiJ1ja46SZmu525s5OZmZ96Srb/9FPm//1Pfi9MPZj5978PvY/TT+drC57g9HTmTZtkm2dwAXNHR9jDNx9+AgPM//d/odd56y3Z59/+1nXZP/8py9591ztv3jyZt3L3k5iPOipsGawCYAmH0NXk8aEPltbjtqYe9gzwobMT+OUvgexsY4Caz0PEBPoydCgwYgRGOTdZ8qGbDaLTHEvkgMceKzPS0oBnnxWn8/Uyyh8R8MwzEu104YX+ce6rVkl3+4MPhrTIpKVJEDsg416uXImZJdvAHN2GUU+D6OBycbqefjpw9dVSuJdewpFHSs/Fr76KXhkiwYYNwPjCGnF89qRB1GTiRBS3lieGD72BkccN1iNcTHJyZIzOt97CjL0ZK1eGzq0SjqYmgOBG9vB8axuMGSOtoUYQ+tlnS6K5hx7yxqCP7CwP7j83mTQJxQ3r4HB4t8nNZkvtCFkjB2GPlPW44w45BQsX+i9vbZXU1FOnAr/6VdftTzhB2l59k+t58qCXfRiTBlEgmRpFh2QDANrqet9n+U9/ki7sjz9uPAsLFkif3ZEju99wxgyMblhpaaALT4TL+tcldef++3sXzp4tYvjYY54A89JS4IEHZPLRR72reuLP922X0MdTTvHGyZ90khRrq8Q9RrNhdPFiibOdsuIVqYFOOUUEccYM4MEHcfBP3UhJSew0AC6XPHzj3euldbc3jVcTJ6K4pQz19fFPSta4s7NnIYu+nHwyUFmJmYXlcDh6n9e+sUEiTKg4TISLyWmnSTz6hRcCLS3IzJTw3bfflkguIsZwbAsv6CyDipaVyazcArulw1NJMb7lfXHPn91Yvlxu4UMOkQFbmIF77pFu/A8/7JPKvK0NuOkm4IcfPPbUf/7jHde0vBwYWtAh6XtV0HtG2pA8pKIDmzf2zkJfskRar88+Gzj1VHhjAoOFKway994YVStd68INdLFiBVBczBj6yTwxBQKth9tvl0rk4os9ITsXXCB5zv/wB++N+tlncv+P+fY1Ge7ossu8+xg9Gpg5E8M/fgnFxdFNpbt4sWh36pvz5CkYPlyE/be/BdauRe5X7+MnP0nsePStWyVEb/zObyR3QW9ihSdNQjHEPLfawSwaMAPr17pQiLreCfqxxwIpKZhZIcZAb++dpl2d1mLQTfLzxTApKwN+/3sAEixlswH/+AdQkt2I1DSbJ5olKD7XwIxayhmUZu34JSXIddXjugtqsXmzGFHr1kl+pTlzRNDPPNPnZb2jQ4Ti7ruBX/wCcDhw8cXSwej552WV8nJgXK4xkM/s2dbK0UeSRtCpsADn4QU8+2Z+j8Ot2trE1TJsmIRyA5ChW3bt6t7dYjJjBkbxZgDhQxdXrgT2GtMofeJNd4sv2dny3lZWJmNZQvTxqae8XhWnUyz0gw+GxHdNmtS14jn5ZOCbbzBzSnvULHSnUx74fcbtFFPutNO8C08/XfKIPPAAjjxS1ovkIFWRxBOyuPnDnoUr+jJxokdM4ul2ef11YOmqTFyEZ6zlcQlk0CDgkEOw+ydPIjeXe33vNNY6rIUM+nLQQdLJ7okngP/8ByNHygsfM1Bq3wbsuWf37pMJE1CCAAu9KMhYsMEwz9X27cjKkhfl8nJ5K66okPDE++4z1nU6gbPOkljFCy4QrbjnHkyYIM/k00+LPbhpEzDOXSaVULjQzUgRyrke7U+kG0V54UKuxSAenOfgOXOk0dAqV18tjRcffOAz8/77ZWZ5efgdbNnCmzGKAWnMCUVHB3NaGvN1+3/BbLNJC2koLr5Y1vnwQ8+sF16QIl18sdHgc1uF/PjrX7tuv2YNM8A3H72IbTbm5ubwf6OnrFxptBmf9IY0Jm7b5r/CXXcxA/ztK2UMML/6auTL0FfcbuZbbpH/UYnhzP/+d+921N7OS2gWA73fRV9paWEuLWWePnoXO2GTe6A3PP44M8A/ndnM++7bu10cuc8u3hdfBzxUFmhvZ95rL+ahQ5mrq/nLL+XanJr2NvOFF4bdfNeIPRlgnj5dttt4xo3WjvvFF7LB//7XZZHDwbxzpzHhcjGfc46s+8ADMu/MM+XBXr2aX35ZFr33HrPd7uY/Zt3f88bpMKCbRtHkEXQj0uOZyxcxwPzss9Y2++QTOQtz5/rMnDdPIlD23Vee+HC43dwxaBjbyNVtK7lHAMfcxLz//t3vs66OeepUuVHefNM8DB9/vOwDYN54zs3M6ek+d1sAe+zB/576RwaYv/wy/N/oKc88I+VYt9vRzAcd1HWF2lrmzEx2XngJFxZaeh77TG0t82uvMZeVdX/pduyQoKAJE+Q/TB66g91A95VsGCpH78+A6GE8MCumz39thFfU1fVuR1VVzET82598zRkZnsCTHrHf+Fo+HB8wr1jR842//17u6+OOY7fLzZee08zzcHrw8JIA3IcfwWnk4OxsNwPM1b/9k7VjlpXJOXvuuW527ma+5BJZ7667vPOrqyWq64ADuK3FxYMGMc+aJas9i/OZ//53a2WwyMAQ9MpKZoBdf3+cDziAefBgebi7Y+tWsWgmTBDrhpmZH3pIrM0DD+zZA3H44Twytarbyvill+SMf48pzHffHX6fu3Yx/+QnYqk//TQzy7M2aBDzyBEudufmibUQiptu4gqbvDk8/LD1v2KVyy9nzs91sgvE/OijwVe67DLm9HQ+9bh2HjnSWv1o0tHRNVwz3Ppz5ngrvGHDmE8+WV62vvlGjL9PPmH+xS+kvgaYDzhA3nxafnYS8x57WD9YsOMffTwDzLfe2qfd9IrNmyXi8Be/YIlbTE/v2ckOZM4cfmnUDRJ2t7Lnm08pqeWT8Qbz9u29O/4DD8gFeuIJiQUEmBcsCL/d3Lk8irZ47oHW+x6xdryWFtlg332Zn39eanxf3G7mq66SdW4MYvU//7ws+/vfPW/8APNn+CnzsmXWymCRgSHo5gX58595xQoJab3kktCrb97MPHYsc14e89KlLBfs+utlHyedxNza2rPjX3cd709f8sEHhfb1XHMNc1qKkzuQYv0paW6WGFaA+d57mVnE6bPr/ivzvvgi9LZLl7Ib4KF5rRKv3kPWr2euqAi9fMYM5sPGlkmFU1UVfKXVq5kBfvbEtxmQa9LWFv7Ymzczz57NPXLV/O537HkTfuwxqevGjvU+XDabfBcUyLP5ww/Ghk4nc34+86WXWjtQNwUYgh18+WU9E9KODjFKt23rvQafdhpzZqYYKfzLXzKPHt27HZn89a+8GpPCGq2hKM2r4/PxnJzb3uByMR92mHRiuPBCuXD19eG3e+QRno1v5HrDye5XeuDnu+km5uHD5VhEUtv/+c9yD994o8y/+urgF8ntZj78cObcXF71cZXnntuSPr53rzjdMDAE3e0Wv9uECcxVVfz738u/++qrrquWl8v9XlDAvGgRyxN1/vmywWWX9e4mnDePz8ArPGxwR8iOPEccwbx3fpm8FvTkyXU4mM84Q8p33XWy7ezZzJMnd78ft5t5zBg+qmgxT51q/XBtbcw33CCV4tChPsIXsE5KipuvH/wk88EHd7/Do47izqHD+fprOj3+zQ0bQq8+fz5zYaFUttOnizX98cfdH+L11+X0/PrXXZf9+KMsv+465hdfDFJXf/edbPzii90fJBxPPsl7YiWfeGT3DRYtLfJ/br1VNCs721vpZGUxT5smbxbXXScdtlav7v6wn30m2952GzMvXy6V089+1rf/smkTO2Hj7DQH/+Y3Pd+8IK2Zf5PZTYOSFSoq5CEFpGa2wkcf8fH4q+106gAADYlJREFUNwPM+ahj/uijnh3T7RYL75ZbmPfe23thAKnwu3veysqkVj3+eD7gADenUgc75xzUs+NbYGAIOrNYq9nZzJMnc1P5Dh4xQtpXfCvIMkNPCwsNy7y5mfnnP2fPu3JvTaR16/gDHM42cvExxwSvlIcNc/P5KS8y/+pXPd+/0ynbAdKNFRD3UDh+9zu+yXY32+1uSy8dCxZ4/cpnn81cUhJc1L/5RtZ5EyeF9xG+/76s/Pzz/M47cu5zc0VkfenoEG8BIM9SWZl4naZMkfW/+y747teuleX77mv0SLXaLfXHH5lfecV7/TdtsrZdKBYs4MPxAe83Kbir7o03pIwpKV4jcK+9pP3mpZeYH3lEDMBjj2WeNEmaTwCpWG+6KfjfcjplH6NHM7eu3CAXq7SUecuWvv0XZuaZM3lO7vKwzT2BuN1iHd9U9ETfy2B2tzzpJGvrV1bypXicAeaR2No7f5EvW7fK/X3PPdYiLe67jxngZXf+l5+zXyQ3dIQZOILOLOZKZibz1Kn8xrMNfo3R69czjxgh/vXly1lMn332kXfxvrZkuVzMOTn82EGvMiD+Zd+6Yft2Odt/xdXM77zTu2O43dI3GRCH6a5d4bdZuJDfwokMiAiHor5eXk5MY8gMrlm7NrioP/ywrLuVRoX3k7rdosp77cXc3s5btjDvt59s/5vfiFBVVMgbLiD1VlsbS2PTwoW8dYubR4yQcgRqbnOz7HrwYOata1u8bzJFRdLwfN55zHfeKS2lixYxv/yy+H3Gj/daXnl5zBdc0DefM0t5z8GLPGZQV9fA00+LgE+ZIp69//43fBON0yltCObL4557Mi9e7L/OY4/JstcfrxVVHzJELlokuOsuvhIPclamq0cvrR7v5+59tNBN/vY36636bjffknoXA8yTsDq0KzBadHaKLzIjQ07CG29E/BADS9CZ5TUrI4Pde03now93cE6OvOKWlMhzvvLbVvGJpaaKufivf0XmuHPmMM+axdddKy3s99zjXWQaqR+nHdVz/3wgL7wgjTBWcLl4S9FMBoK3WzY0SBDN8OFSr/3ud8zNTW5pPTz3XOZrruG1S5q6iPq557p5mH0Huw851Fo5XnxRTsCIEcz338+OnU382996rfEhQ5hzcgx/+ebNYraaD8XPf87ff1rDBQXMEyd6G7vdbnmLIGL+4KXt4p8hYr7iContPOggr0/U95OfL8lb/vIX5iVLeu/nDcTt5mvS/8YZdodf3WBWfkcfbVx6l0tqsI8+Euvv6quZTzhB/sxvfyt+22efFdVfvJi5vp7feUf+it0ut257u9TngwczH3yAg92T9vBpEIoQa9bwC/ilhA2eKr70ysrwm1VVyf/9+z4WQ80izGOj7maAeR98G3H/tSWWLpULBVg7YT1k4Ak6s8STpqXxxj2P54wMEdihQ5l/+PsCb0vZueeKFRgp/vQnZoBdRx7Fvzih1a9B7957pAy1R54ZueNZxH3Z5TwYtTx9movPOYf50ENFGHNyvBo3bRrzog/qRORMn0tengjk8OG89uEPuLjYK+p7jGvjYzHfejY0t1tqtYMPln0PGsR866381guNnJ8vEZpr39kg1yQlRT4XXCDilpHBPGQIL7jrC05Pl8CflhbRQoD5jgvLpUbIz/fPjmTS3Cz+mrfekoctUgIehL+Mesiv/e7ee6WMJx3v5PZb7pa3lKws/womK0tM93Hj/B3q5icjg/n887nuk2Uea33KFOZTTmG22dy8YvIZso6VKJAesmvCvnxe8Xs8bJi3OFOmSL3z3nvBbZP162W9l47qJqldFPnXT//KAPOhKZE/H5a54w6JlIsCA1PQmcW1kZrKD46+n8ePbufVR1wpf3nSJEnjFmncbnHdZGZy25CRfOCUWk5LY/78c+azj63jEajoezrI3vDBB3wenuPUFBePHi2eiNNOc/NVVzj43pvq+PWbV3LHGb/0Om3331/eAlpbxU8zbRozwGsP/RUXFzm5qIiZ4OLb6ObeVYhffSUWMsCcnc2NV/yBO44/xStuV11lhGsYrFrlaaB687BHmcjNBx7InJrq5p9P2cwue6pc03XrInbKess/DhT/7Zo10iQDMJ9x0DbuGDdRJg45RNTwscfktbGysqurp7lZWu6//lp6KV1+uVfoZ8/m//7uIx5eIgbCr4b/Wyq/3rrxwnHTTcw2G7tuv5O/e/BTvu/6Wj7icDenp3vr/IsvluYr828s+UKMmbfPjby7wQpfX/IMA8zH5/SwQbSfMHAFnVkeCLMVKiNDOgQ4HNE95qpVzNOm8U4U8sSC7VxY6OaR+Q18NP7rL1SxoqODuaCA3cOKxfouKvIGYvu6IebODd6I1NEh/qPMTF6TNYOL85oZYH5v+vV9K9fKlcxnnSW+noICaR8I1bHH4ZDQGyJ+ZPDNDDCPzqnhnSiUVkQrIW0x4KMLX2aA+YhDJKLn/FEfS6/NiRP9ev32mPp68SVPlIqhbtA4fnTUn7kBedIuEC3WrWPebbcubxStM+fwe0fcz+fNXs3ZmU4GZLXbbmN+7p5qBpg/ue696JWrGzY98o406he9H5fjR5uBLejMEgd33nk966XSV9ramK++mjdiLA9NqWWA+fqhT8fu+IE8/LDETZ5+urR+Xn+9uDOeeEIqPSu5AcrLmY86itdiAt+IO7n9kQg1eu3YYT03weefM48ezW/hRN6A3cSC7Emehyjzw4MfenTvVylPsCsjSzqRRSohvNstvveTTpJKOVSHrkjT0CBvDE89JW9Qhx0m/jeAm5DNL2RcyocOWuan+0seWhibsgXQuuh7BpgvG6uCnpyCHk/efZcXFR7JxdjGH50ZR0GPFG63hJKdckrvu5b3lYYGCQd76634HL8bmhat5kGo5WtwL7tPPEkaeKNFPBr8fHG75f+9/LKEJk2dypsxmu/EjXw65nHLVyHiTKNNaytPxzJ+ZE4CJg+KAN0JOsny2DNr1ixesmRJXI4dc6qrwQ/9DfSbub3LgKf0H9xuuG6+Dfb99wV+/vN4lyb21NUBX38tScEvvFBShcaDhx4CDjgAmDUrPsePIkS0lJmD/jFLgk5ERwF4CIAdwNPM/OeA5ekAXgQwE8BOAL9gNvLJhmBACbqiKEqE6E7Qw+ZDJyI7gEcBHA1gMoAziWhywGoXAahj5t0BPADgnr4VWVEURekpVga4mA2gjJnLmbkDwDwAJwSscwKAF4zfbwA4jEINVa4oiqJEBSuCPgKA78Bqlca8oOswsxNAA4DBkSigoiiKYg0rgh7M0g50vFtZB0R0KREtIaIlNYk6HpmiKEo/xYqgVwIo9ZkeCWBbqHWIKAVAPoBdgTti5ieZeRYzzyoqKupdiRVFUZSgWBH0xQDGE9FYIkoDcAaA+QHrzAdwnvH7VACfcLziIRVFUQYoKeFWYGYnEc0F8D4kbPFZZl5FRLdDAtznA3gGwEtEVAaxzM+IZqEVRVGUroQVdABg5ncBvBsw72af3+0ATots0RRFUZSeELeeokRUA2BLLzcfAqA2gsXpj+g50HMA6DkYiP9/NDMHbYSMm6D3BSJaEqqn1EBBz4GeA0DPwUD//4FYaRRVFEVR+gEq6IqiKElCfxX0J+NdgARAz4GeA0DPwUD//370Sx+6oiiK0pX+aqEriqIoAaigK4qiJAn9TtCJ6CgiWkdEZUR0fbzLEwuI6Fki2kFEP/jMG0REHxLRBuO7MJ5ljCZEVEpEnxLRGiJaRURXGfMH0jnIIKJFRLTCOAe3GfPHEtG3xjl4zUjPkdQQkZ2IlhPRO8b0gDsHoehXgm5xsI1k5HkARwXMux7Ax8w8HsDHxnSy4gTwe2beA8B+AH5tXPeBdA4cAA5l5r0ATAdwFBHtBxlM5gHjHNRBBptJdq4CsMZneiCeg6D0K0GHtcE2kg5m/hxds1f6DiryAoATY1qoGMLMVcy8zPjdBHmYR2BgnQNm5mZjMtX4MIBDIYPKAEl+DgCAiEYCOAbA08Y0YYCdg+7ob4JuZbCNgcIwZq4CRPAADI1zeWICEY0BsDeAbzHAzoHhavgOwA4AHwLYCKDeGFQGGBjPw4MArgPgNqYHY+Cdg5D0N0G3NJCGkpwQUQ6ANwFczcyN8S5PrGFmFzNPh4xJMBvAHsFWi22pYgcRHQtgBzMv9Z0dZNWkPQfhsJRtMYGwMtjGQKGaiEqYuYqISiBWW9JCRKkQMX+Zmd8yZg+oc2DCzPVE9BmkPaGAiFIMCzXZn4cDABxPRD8HkAEgD2KxD6Rz0C39zUK3MtjGQMF3UJHzALwdx7JEFcNP+gyANcz8V59FA+kcFBFRgfE7E8DhkLaETyGDygBJfg6Y+QZmHsnMYyDP/ifMfDYG0DkIR7/rKWrUzg/CO9jG/7d3hzYIBEEYhd+EDigAQQFUgLgCsDjKQGFISKiF5BQ9UACCDnCUgBrECgSHhMvtva+CyYg/m9nJ7rHnkn4uIk5AQ3kq9AHsgTPQAjPgDqwz8+PbvxpExBK4ADfes9MdZY4+lh4sKBd+E8pBrM3MQ0TMKcsBU+AKbDLz2V+l/xERDbDNzNVYe9BlcIEuSeo2tJGLJOkLA12SKmGgS1IlDHRJqoSBLkmVMNAlqRIGuiRV4gUpAx0qgmlMzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponential Regression Loss =  0.062321406\n",
      "Prediction Loss =  0.02800857\n",
      "[[0.0169518  0.02430245 0.0581379  ... 0.32572156 0.03213215 0.01877131]\n",
      " [0.02084443 0.05110617 0.19253376 ... 0.25722444 0.03678198 0.01669036]\n",
      " [0.03550763 0.02196178 0.0184156  ... 0.2034663  0.40730435 0.12171448]\n",
      " ...\n",
      " [0.01298948 0.01083501 0.01290114 ... 0.0463999  0.02280471 0.02361302]\n",
      " [0.06318071 0.09395584 0.05473219 ... 0.09070434 0.14090253 0.15361412]\n",
      " [0.02140797 0.01290259 0.04268584 ... 0.02168478 0.06265602 0.0210081 ]]\n",
      "tensor([[[0.0635]],\n",
      "\n",
      "        [[0.0639]],\n",
      "\n",
      "        [[0.0636]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0640]],\n",
      "\n",
      "        [[0.0634]],\n",
      "\n",
      "        [[0.0639]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0640]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0639]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0641]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0640]],\n",
      "\n",
      "        [[0.0643]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0636]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0639]],\n",
      "\n",
      "        [[0.0641]],\n",
      "\n",
      "        [[0.0634]],\n",
      "\n",
      "        [[0.0641]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0636]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0641]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0636]],\n",
      "\n",
      "        [[0.0640]],\n",
      "\n",
      "        [[0.0636]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0634]],\n",
      "\n",
      "        [[0.0635]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0641]],\n",
      "\n",
      "        [[0.0637]],\n",
      "\n",
      "        [[0.0638]],\n",
      "\n",
      "        [[0.0635]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deZwUxdnHf8/e3Mspp+wKKHK7LiiCqKBcajCoEQ80HkETMSqviZjE20Q0iRo8oiZi8ATjFSICUREFQWC5b1juhQWWBXa59pidev/o7pmenj6qj7l66/v5KDvd1dXVVdVPP/XUU08RYwwCgUAg8C9piS6AQCAQCGKLEPQCgUDgc4SgFwgEAp8jBL1AIBD4HCHoBQKBwOcIQS8QCAQ+Rwh6gUAg8DlC0AvqNUS0i4guT3Q5BIJYIgS9QCAQ+Bwh6AUCHYjoF0RUTERHiGgWEbWXjxMRvUhEh4iogojWElEv+dxoItpIRMeJaB8RPZTYpxAIJISgFwg0ENFQAM8C+BmAdgB2A5ghnx4OYAiAswHkArgBQLl87i0AdzPGmgDoBWB+HIstEBiSkegCCARJyM0ApjHGVgIAET0C4CgR5QGoBdAEQHcAyxhjm1TX1QLoQURrGGNHARyNa6kFAgOERi8QRNMekhYPAGCMnYCktXdgjM0H8AqAVwEcJKI3iaipnPRaAKMB7Cai74hoYJzLLRDoIgS9QBDNfgCdlR9E1AhASwD7AIAxNpUxdj6AnpBMOL+Rjy9njI0B0AbA5wA+inO5BQJdhKAXCIBMIspR/oMkoG8non5ElA3gTwCWMsZ2EVF/IrqAiDIBnARQBaCOiLKI6GYiasYYqwVQCaAuYU8kEKgQgl4gAL4EcFr138UAHgXwCYBSAF0AjJPTNgXwD0j2992QTDp/kc+NB7CLiCoB3APgljiVXyAwhcTGIwKBQOBvhEYvEAgEPkcIeoFAIPA5QtALBAKBzxGCXiAQCHxO0q2MbdWqFcvLy0t0MQQCgSClWLFixWHGWGu9c0kn6PPy8lBUVJToYggEAkFKQUS7jc4J041AIBD4HCHoBQKBwOcIQS8QCAQ+J+ls9AKBIHmora1FSUkJqqqqEl0UgUxOTg46duyIzMxM7muEoBcIBIaUlJSgSZMmyMvLAxElujj1HsYYysvLUVJSgvz8fO7ruEw3RDSSiLbIW6tN1jmfTUQz5fNL5Q0aQER5RHSaiFbL/73OXTKBQJBwqqqq0LJlSyHkkwQiQsuWLW2PsCw1eiJKh7TJwhUASgAsJ6JZjLGNqmR3AjjKGOtKROMAPAdpizUA2M4Y62erVAKBIGkQQj65cNIePBr9AADFjLEdjLEaSHtnjtGkGQNguvz3xwCGkQ97x/JdR7D14PFEF0MgEAhswSPoOwDYq/pdIh/TTcMYCwCogLQjDwDkE9EqeWu1i/VuQEQTiKiIiIrKyspsPUA8uf71JRj+4veJLoZAUG8oLy9Hv3790K9fP7Rt2xYdOnQI/a6pqeHK4/bbb8eWLVtM07z66qt4//33vSgyBg8ejNWrV3uSl1fwTMbqaebaIPZGaUoBnMkYKyei8wF8TkQ9GWOVEQkZexPAmwBQWFgoAuQLBAIAQMuWLUNC84knnkDjxo3x0EMPRaRhjIExhrQ0fb317bfftrzPvffe676wSQyPRl8CoJPqd0dIe2rqpiGiDADNABxhjFUzxsoBgDG2AsB2SHtsCgQCgWOKi4vRq1cv3HPPPSgoKEBpaSkmTJiAwsJC9OzZE0899VQoraJhBwIB5ObmYvLkyejbty8GDhyIQ4cOAQD+8Ic/4KWXXgqlnzx5MgYMGIBzzjkHixcvBgCcPHkS1157Lfr27Ysbb7wRhYWF3Jr76dOncdttt6F3794oKCjA999LloF169ahf//+6NevH/r06YMdO3bg+PHjGDVqFPr27YtevXrh448/dl1fPBr9cgDdiCgf0ubI4wDcpEkzC8BtAJYAuA7AfMYYI6LWkAR+HRGdBaAbgB2uSy0QCOLOk//dgI37K60T2qBH+6Z4/Oqejq7duHEj3n77bbz+uuTMN2XKFLRo0QKBQACXXXYZrrvuOvTo0SPimoqKClxyySWYMmUKJk2ahGnTpmHy5ChHQjDGsGzZMsyaNQtPPfUU5s6di5dffhlt27bFJ598gjVr1qCgoIC7rFOnTkVWVhbWrVuHDRs2YPTo0di2bRtee+01PPTQQ7jhhhtQXV0Nxhj+85//IC8vD3PmzAmV2S2WGr1sc58IYB6ATQA+YoxtIKKniOgncrK3ALQkomIAkwAoNTcEwFoiWgNpkvYextgR16UWCAT1ni5duqB///6h3x9++CEKCgpQUFCATZs2YePGjVHXNGjQAKNGjQIAnH/++di1a5du3mPHjo1Ks2jRIowbJ20d3LdvX/Tsyf+BWrRoEcaPHw8A6NmzJ9q3b4/i4mJcdNFFeOaZZ/D8889j7969yMnJQZ8+fTB37lxMnjwZP/zwA5o1a8Z9HyO4Fkwxxr6EtIGy+thjqr+rAFyvc90nkDZYFggEKY5TzTtWNGrUKPT3tm3b8Le//Q3Lli1Dbm4ubrnlFl1f86ysrNDf6enpCAQCunlnZ2dHpXGzv7bRtePHj8fAgQMxe/ZsXHHFFZg+fTqGDBmCoqIifPnll/jNb36Dq666Cr/73e8c3xsQsW4EAoEPqKysRJMmTdC0aVOUlpZi3rx5nt9j8ODB+OijjwBItnW9EYMRQ4YMCXn1bNq0CaWlpejatSt27NiBrl274v7778eVV16JtWvXYt++fWjcuDHGjx+PSZMmYeXKla7LLkIgCASClKegoAA9evRAr169cNZZZ2HQoEGe3+O+++7Drbfeij59+qCgoAC9evUyNKuMGDEiFIvm4osvxrRp03D33Xejd+/eyMzMxDvvvIOsrCx88MEH+PDDD5GZmYn27dvjmWeeweLFizF58mSkpaUhKysrNAfhBnIzHIkFhYWFLFk3HsmbPBsAsGvKlQkuiUAQHzZt2oRzzz030cVICgKBAAKBAHJycrBt2zYMHz4c27ZtQ0ZG/PVlvXYhohWMsUK99EKjFwgEAg5OnDiBYcOGIRAIgDGGN954IyFC3gmpUUqBQCBIMLm5uVixYkWii+EIMRkrEAgEPkcIeoFAIPA5QtALBAKBzxGCXiAQCHyOEPQCgSBp8SJMMQBMmzYNBw4c0D13yy234PPPP/eqyEmJ8LoRCARJC0+YYh6mTZuGgoICtG3b1usipgRCoxcIBCnJ9OnTMWDAAPTr1w+/+tWvEAwGEQgEMH78ePTu3Ru9evXC1KlTMXPmTKxevRo33HAD90ggGAxi0qRJ6NWrF3r37h0KFbxv3z4MHjwY/fr1Q69evbB48WLdeyYbQqMXCAR8zJkMHFjnbZ5tewOjpti+bP369fjss8+wePFiZGRkYMKECZgxYwa6dOmCw4cPY906qZzHjh1Dbm4uXn75Zbzyyivo149v++p///vf2LhxI9asWYOysjL0798fQ4YMwXvvvYerr74aDz/8MOrq6nD69GmsWLEi6p7JhhD0AoEg5fj666+xfPlyFBZKK/5Pnz6NTp06YcSIEdiyZQvuv/9+jB49GsOHD3eU/6JFi3DTTTchPT0dbdu2xeDBg1FUVIT+/fvj7rvvRlVVFa655hr07dsXXbt29eSesUQIeoFAwIcDzTtWMMZwxx134Omnn446t3btWsyZMwdTp07FJ598gjfffNNR/noMHToUCxYswOzZs3HzzTfjkUcewc033+zJPWOJsNEL4sr2shPImzwb8zcfTHRRBCnM5Zdfjo8++giHDx8GIHnn7NmzB2VlZWCM4frrr8eTTz4ZCvHbpEkTHD9+nDv/IUOGYMaMGairq8PBgwfxww8/oLCwELt370bbtm0xYcIE/PznP8eqVasM75lMCI1eEFdW7ZHsl1+sKcXQ7mckuDSCVKV37954/PHHcfnllyMYDCIzMxOvv/460tPTceedd4IxBiLCc889BwC4/fbbcdddd6FBgwZYtmxZxAYkAHDXXXdh4sSJAID8/Hx89913+PHHH9G3b18QEV544QW0adMG06ZNwwsvvIDMzEw0btwY7733Hvbu3at7z2RChCm2gQhT7J5PVpTg//69BmPP64AXbuCbGBMkDhGmODmxG6ZYmG4ECSG51AuBwN8IQS+IK0SJLoFAUP8Qgl6QEJLNZCgwRrRVcuGkPYSgF8QVodGnFjk5OSgvLxfCPklgjKG8vBw5OTm2rhNeN4KEIMRGatCxY0eUlJSgrKws0UURyOTk5KBjx462rhGCXiAQGJKZmYn8/PxEF0PgEmG6EQgEAp8jBL0grhCEkV4giDdC0AsSgpjbEwjihxD09YSF28qwu/xkooshvG4EggQgJmPrCePfWgYgecI3CIVeIIgfQqMXCAQCnyMEvSAhiAU4AkH84BL0RDSSiLYQUTERTdY5n01EM+XzS4koT3P+TCI6QUT2d/UV+AoSRnqBIO5YCnoiSgfwKoBRAHoAuJGIemiS3QngKGOsK4AXAWgDMr8IYI774gr8gtDnBYL4waPRDwBQzBjbwRirATADwBhNmjEApst/fwxgGMmqGxFdA2AHgA3eFFmQygh9XiCIPzyCvgOAvarfJfIx3TSMsQCACgAtiagRgIcBPGl2AyKaQERFRFQkYmrUE4RKLxDEDR5Br6eEaV9TozRPAniRMXbC7AaMsTcZY4WMscLWrVtzFEmQqggTvUAQf3j86EsAdFL97ghgv0GaEiLKANAMwBEAFwC4joieB5ALIEhEVYyxV1yXXJDSMKHSCwRxg0fQLwfQjYjyAewDMA7ATZo0swDcBmAJgOsAzGeS/9zFSgIiegLACSHk6zci1o1AEH8sBT1jLEBEEwHMA5AOYBpjbAMRPQWgiDE2C8BbAN4lomJImvy4WBZakPoIN3qBIH5whUBgjH0J4EvNscdUf1cBuN4ijycclE/gM4SNXhBvPiraiy6tG+P8zs0TXZSE4b9YN3W1QLAOyLS31ZYgvgiNXhAvfvvxWgDJE+cpEfgvBMJ7Y4Fntd6fgmRBKPQCQfzxn6Df+T0QDACVWscgQTIhvG4EgvjhP0GvcGhjoksg0EHY6AWC+OMvQR+oCf9dtjVx5RBYImz0AkH88Jegr64M/122OXHlEJggVHo9GGN4+ZttOHS8KtFFEfgQfwn6qorw34eFRm/FtoPHseXA8UQXQwBgbUkF/vrVVjw4c3WiiyLwIf5yr1Q0+kZtJI2eMWEUNuGKF78HUL/dzpKFQFCyZZ2qqUtwSQR+xF8afbWsnXYZCpw+Cmydl9jyCAwRJnqBIH74S9ArppsBvwBanQPMnQwEqhNbJkEEYoAlEMQffwr6Rq2AUVOAozuBJSKGWjIivG4EgvjhT0GfkyuZb7pfBXz/F6BiX2LLJQghFHqBIP74S9CfPgaAgOym0u/hz0hxb75+PKHFEughVHo9xEhHEAv85XVTVQHkNAXS5O9Xi3xg0K+B7/8MNM8Hel2LdzbWYXi/fLRtkikHQJODoNXVSqETgrVAXSD8dzAgnQfQj4qlfEuKEvSAztEreyKep9mRI+hHxcivKgdKhH6v0LCsEv2oGN1qGwMl2Ykujq9Iqfe2QXOgZRfPsyWWZCpEYWEhKypy2CCfTgD2LAEeWBc+VnMS+PhOYOscbwooEAgEsaLnWOD6tx1dSkQrGGOFeud8qNE3izyW1Qi4aQZwdDcOb/gWb875EW0bMtxxcVcgLQNIywTSM4G0dOnvtAz5d0bo7yOn6zDpozWhLP91+4A4P5h7fv72MgCRZdc75kW+ZqzccxRTv9mGvh1z8eAVZzu+Lw/Hq2px34erMOTs1rhjUH5M7+WWbYeO44+zN+GsVo3w2NU9E10cX+FFP48bjc+ISbY+FPS5+uead8bJc6/Hm1+0xpmZDXHHkMu4s62trMKCoMrM0O0KlwWNPwuCchwgVdn1jnmRrxlHag9iQbAR0hu2Abr1d3xfrnuVn8SCIMP2Qw1wR7ehMb2XWyqzjmJBMBvHsnOBboMSXRxf4UU/T3X8Nxmr1egFSUk8DIZif1qBQMJfgv5UOdDAQKN3gRAX3pGIBVNJNg1lilhQBtQEghj35hKs2H000UXxDf4R9Ed3AycPAW37ep+3xy/f7LWlWLmnfnfieDgBKEIzlQS9XllX7jmKitO18S9MgthVfhI/7jiChz9Zm+ii+Ab/CPra08A5o4H8IYZJkuWFv/eDlRj72uJEFyMheKmxHj5R7fvomzWBIMa+thh3/mt5oosSN8Sgxnv8Mxnbpjtw44cxyVrYer3Hi2/u0L8sQGVVwNfRN4OydrJ2X4VFSoHAGP9o9Bw41SaF3dQ7vPxoVlYFzO8l2i2lSbY1PqlMvRL0TvuNkBfeE8932M8C42BlFaZ+s81XzxiaW0lsMXxFvRL0giQgjl9NSiGV3rKoBlLvvg9W4YWvtmLD/kr9BCmJ/Xarqq3DG99tR6AuGIPypD5C0HOQTALj05Ul2Hwg9V/qeGprftYMT9VK5isfKfRhbDzTq98W49k5m/HxipLYlSeFEYKeg2QaFk/6aA1GvrQw0cXgIm/ybEyZo9mkXa7K9XGYXFQ+z0nUfDGD+ehz5kSvOlEdiPhXEIkQ9IKY8vp323WPHzlZg3kbDsT03v4Rff4S5LEgI036OgTrw1fdAULQcyC6jneoBdauwydjey8fvPS8j+BHF2A7rZcmC3photdHCPoUZt+x0xj50vc4dLwq0UVJSnwg50NYPYufNP6wyY3/mdJIaPRmCEHPgRd9pzpQ5z4TDdMX78LmA8fx2crU2Soxvm6V8r8pLAStyu5HTd6J80M6KRp96rZ1LOES9EQ0koi2EFExEU3WOZ9NRDPl80uJKE8+PoCIVsv/rSGin3pb/PjgVlCsLTmGc/4wF/M3H/SoRBLp8nA1IDq3Lqks4BXCHyuD8z54RiOcmW78Wx9usBT0RJQO4FUAowD0AHAjEfXQJLsTwFHGWFcALwJ4Tj6+HkAhY6wfgJEA3iAi/4Rd4GSlHIVvwZYyT/Pl1WKSyVadEI0+eR7fMcnUhrHGyRglXZhuTOHR6AcAKGaM7WCM1QCYAWCMJs0YANPlvz8GMIyIiDF2ijGm+DvlIEnmNW2PDF2W2mgoerzKXUTCdKHFmOKHWrF6Bj+abpyQLksy8S7owyPoOwDYq/pdIh/TTSML9goALQGAiC4gog0A1gG4RyX4QxDRBCIqIqKisjJvtV494v3RN9LG3lq001W+GZyCPpmUnLgulJIfPIke3xJjE039wUl46ZDpJpk6exLBI+j1VAZtbRqmYYwtZYz1BNAfwCNElBOVkLE3GWOFjLHC1q1bcxQpviRr10lLcRt9rBccK7WSyu9+fTLZKCijFDvzD4rpJt7VVRdkePw/67H/2On43tgmPIK+BEAn1e+OAPYbpZFt8M0AHFEnYIxtAnASQC+nhU0UbjtPrEIo8C4SSSZRoRZcsX4p/SAjY/0IK/ccxRsGi9pSiUSZMZftPILpS3bjoX+viet97cIj6JcD6EZE+USUBWAcgFmaNLMA3Cb/fR2A+YwxJl+TAQBE1BnAOQB2eVJyQdjrpi75JFpyaKJM86/8i7EkKR8/ln70Dh9n7GuL8aw2TEWCceJJlJYg90qlrMk+CWwp6GWb+kQA8wBsAvARY2wDET1FRD+Rk70FoCURFQOYBEBxwRwMYA0RrQbwGYBfMcYOe/0QdrGrYCerC1tYizFfDphMQk1dkpibbgweO/+RL3F7iuzY5KTpGGNYvP1wUrW7E+wUXzgmmMPl6sgY+xLAl5pjj6n+rgJwvc517wJ412UZU55Y7V2akcQTUDxFirnpxuQ+Xru6Jhr1R3PehgO4572VeGpMT9w6MC9hZXKKk34hJmPNEStjOXDbd4yud5tveprUfJZeN+5u4whD75EE+NGnElGDHM5nUD9ryVFpYnBnjGMJxQonk+jhydjENHqy9zUh6Dnwqg29NlVkJLGNnofYe92kvnulZQgEnTpMpv0T4kWs/ejLT1Tj6pcXoeToqYjjqbKOQQj6OKL96rt9H3mXfVtpG/9cuANVtd7G4jHWrOIndsMrY1NJ1NvD7NGsHntjku5K5aS9lMnYWLka/2f1fqzbV4F/LnS39iVRCEHPgVtBYSTQ7WarLUdIi3FZvmdmb8Ir84td5aFFXaLSitM4dqrG0/y5yuAD+e7kGXj1h9FTk3MDGyfNpkzG+qHNY4EQ9CmEVlnhdSnj8RpyG47BjIHPzseAP30jlcXBi/jPhTvw7JxNtq9LRdONGUdORn8s/WylsaNgJdrrJtn7WL0S9LyNcfhENbaXnQhf51ErunXTNOr4yehSpi1qTcDcBTRQF8R9H67ClgPHo849M3sT3vhuh+sypCLqRyh4+iuua1Jd+CvtduRUDU7V8G0NqMxLxNvrJlXqun4Jes5OcPFz32LYX7/z7L5GfcG+P78+yRjrxuijZlSUzQeO479r9uPBmau9L0sKCHyjruDGbJi6cxNSuatqgxj+4ve2rgwmodKTDNQrQc/Laa8nJo2O27bR6//2QqtIxOvxpy83IyDv/aZMomWme6cipaycc0mKKJlcKK6ivNTXNreiXgl6p30gWTqPVktO1hW7AP/agUXF0kJpZXWvYmt1w/GqWpyuqQvb6JOlAU24/vUluseTv+Te43Q1cCxJ9XaoV4I+UahFl7uhuPnvVGTyJ+sAhNcCZKS575K9n/gfBk75Ju71s6m0Egu3OVtx69YtUO/qVO0eXpbb6w+A4ejZ5m3eXbILeZNno+J07Jwg1NQrQe+0zb3UnL00ISp5WS3a4H3uYJDhlfnbUBlDDxxtXR6olDY2VwSdFxo9ABw7VWsQ0ix2jPrbQox/a5mneTpyr0yVGcIYEO9RrtOanr5kNwDgoNz/Y029EvROX3nPvG6Ydxr9nvJTOFAh2S+9eq+/2XwIf/nfVjz1342u87L7mLWyrT7DUxu9smLKsyxjj6bieAWXn0S7M9ONd3nFk3i1m+/3bz1eVYtlO49g2LlnJK4QKknM2+++3XwIVbV1GNW7nera8NVD/vwt9+15hAVjYRdIXpc2J/c0evHqQpOx3ukeP+44Yp3IJyS5PLOFE63crpdXolGUkHgNvnyv0T84czXunF6EvUdOuTDdeAdvGW7/13L88v2Vjq5NRbw23QDAf1bvA5C8L7su2jffReG96i+Hjldh+uJd3mQmAKBum/hIet9r9EoEv+pAXVK88G42KEglryHDobTOsRW7j4Tc6DI8FPR+/jCa4bWW+MCM1Vi8vRwXdWmJbmc08TZzHbw13cSnEzidG4iXRu97Qe8FyeKeZ1QOrzqLlxNZdnK69u9h10IvNfpUcq80wqrkZrXlVXuerJZMeSeq3Zv0ePBS0McapxPf8S6u7003apLNdGM3X6P0ll43Nu8Ty9CrHyzdbXreSxt9Csv3EMnwDNmZ6QCklarxwM0HKsoF2WVZwvl62xAhG72nuRpTrwR9MuBlJ/YSr93S9F6MTaWVlhOk3mr09ROvhUeOIugD3q4Y95J4tbXXSlC8XGHrlaBXC7Pvtpbh7R928l3nohdtO3gcW+VAXQyRfvS2m9hmOfYeOYV731+Jag9DOuRNno2HP17r6NqTHEN/L230ynxISgl8h+6VHFlZpDVOnJMhiYnqeGn0HjZYvEZEtsOZxKYYhtQvQR9aYATcNm0ZnvTAX9yKK178Hu/+GDZXuBkC2p3IfXzWBsxeVxoKM6Bm5Z6jjssxs2ivZRq9ktZy7ITlpR99akl4fRx1Fwdaotl9FNNNtazRf7qyBIdPVDsoWOwweq9ivYDKqUKulkXxoF4JegUnXrqxuLdXNnqj3qIox3rRLce+ttjm3e2h994pi6LM8CIEQqgMJmXxG3qCzqvHVjT6qto6lFacxqSP1uDud1d4lLvExv2VOF3jfOSZak2sfICEH30McDwZy3HdS19vRd7k2TErg3StvYsV+1+yRG4NBK0FvZcdP5W9bRQcKfQe3ydHNRmrLKo7dNy7pfvHq2oxeupCPDBzlVQWzodevfcYbp22DL94pyh0THtpsnaBsEYvbPQpxUtfb+NKpxY+dpvYqs8Ggwx5k2fj9e+2R+TvxnffMboavXU5vOz4IY0+5fQ9Yya8U4QL5d261OhN6nllo1c8odQjMi/bSQkLvmK3ZE7Uay89ReqaV3/A91vL8NXGgymn0nsZYpyHeiXo7b7wi4sPY+IHK5PHvdLgAqWvKLvr/HneFgDhrQZ5NFuvvwV6dc1junF0LyP7rAfPFAyyUMz8RKB9tv9tPBgKBGeUzonw4K2qmOgMHKtErRSpkCnEoyLZJdkXM9YvQW9zAuTWacvwxdpSy23w7NzfTbvyfqiUl14xd8dKTtmNchk7QW9wPLRgynnet729DF1/P8d5Bg6oCQRRJWu5lmVXPuYxLI/6w8F0jrlFnefByipMeMe5/T/ephu31RCv0Wa9EfROGjwWJg9XdmMjjV7z1mnDF/M+h92iXf3yIlt51QY4TDee2ujlf13ksXBbtMdSrBnx0vfo/uhcvsSmjcb/5Hbb3qiZ9h45hTdk06HdexOAF/63VXfEwptHrPFsFTpzr4TYod4IeicoAtOOwLcS5G4mRq0uVd/6je+2hzql7Y8LZ2feXX7KuCw6x2o5JmOdYPR08XZh8wolPpMd1E3sxH5ud7RoxG3TluHZOZttTdba8UAJC0jtegPzvGPN0ZM1KD50wvZ18ZpaqDeCXm/4yYsd4Wz+HrCYLoBR5/3snM0hG32yeN3MXX8g0UXwH6GOreNeGYN2D5tZ9KXySTnEtZ1vOu8GOkD4mZKlTyvsOHwSl7/wHXf6sOuvMN14jtM61fNDN7yH6wRml5pfrH0+Mz/66Ly9Ra8Dx8oMYjwZ6/ypvtl0EN9sOuj4eq9wtsNU7O9jdIuwcsGfYTBoQ6OX/9X2afXt7n63CC99vTXquB6vfluMrzeat/P6fRWGPv5uF0wJjd4hpRWn8cwXG0OdR43TmXk7AsM8LUU0rP1yGOWqj5OXzivieUfjYbtz7pxehDunF1knjDG8I9xjcY0AACAASURBVMBdh0/hyMmayGu99qRi1nk66XOK0Dbqx+tKKqKOafNX19O8DQe53Z3/PG8L7nrHuJ0rq2px1cuL8NevtoaOvfptMfImz0agLpgU25Py4DtBP2nmGvxz0U6scLHEX4udYaJZ2sqq2oil47bdKw2Oh23x2uM2J2NtlicWECQN7+dvL8MilyMA7WO/s2QXXltQ7DCv2NTO2z/sxNC/LnCdz//9ew0ukXcdUwTmniOn8PvP1kVpvyeqA1GeZGaPFymAzSc+lL5ox3SjuAUTka6GfPUr4Ul/pR2MNlP3OnqlXnyfV+ZLfaimLujarTJeOpjv4tHXmLjwxcd0Y5x29tpSzF5b6qwQsBY22nuHXroYdKaF28rMy+JY0wEWFh/Ggi1lWFxcjq1/HBU6V1VbF1qlyXMvbX089p8NzgoFSbBkphOKDx3H0VO16J/XwnFeaqziLdmpx+NVkUHjluwox5Id5Ti/c3P8/rP1mPfAEJzZsiF6PT4PhZ2bOyluiFiYbnjgMd1EHo+tJHUf+jyJbPRENJKIthBRMRFN1jmfTUQz5fNLiShPPn4FEa0gonXyv0O9LX40RnGe3fiwl8qbcPPd3+FNPMjbyEbP+9LZMSWNf2uZeVkc1vanK0tw2zQpb+1H+5FP19m6l5dtoQiWy1/4Hte/vsQidWLRasWfrCzB6do6zFqzL3SsaHfkiJff68b8vN0+Bxhr52b3134c4msqdHa33eUnsfdIpKda0rhXElE6gFcBjALQA8CNRNRDk+xOAEcZY10BvAjgOfn4YQBXM8Z6A7gNwLteFdyIsFeAd3lO+miNd5npcPhENSZ+sJIrjK8Z2j4TXhlrL5/Za0uj7L1SPrHvlUdPGS/CWrcv2larRW2S8LK0bhZ7vbagGIOmzHd0bbwEGG/TWnndGHl6rdl7DEd1+hSgstFzTcZKaes8Nkfe9I8fsWR7uWU6ivibbL0Tl/x5AS5+XjKvJeNk7AAAxYyxHYyxGgAzAIzRpBkDYLr898cAhhERMcZWMcb2y8c3AMghomwvCm5EuN4jew1RfASVk4nPv329DV+sLcUnK0sc5R1ysNOcD9tL7ZfpnSW7oo7ZejSPqnrx9rCdnifUwcBnv9E97pYAR5weNev3VSBv8mzsKDuB5+duwb5j/KNCNckamM1IJoeFdWS5x7z6A679u37EVKVfp3FIeqU6osypLutp8fbyUFC10orToZDMpmVx5ywt/T9ZNHoAHQCoA5CXyMd00zDGAgAqALTUpLkWwCrGWFQgayKaQERFRFRUVmZu+7VCqTe9/SvmxMGP2+uG+8Pn60KakLUffSR2o1daJUuAnMdN/1jKleeh41UY8+oPKI/QGr1rDL3FXrsMFjZ9urIE/5Nd9j5duU83jVfoiUZnC6Y406kS1gUZinZF7hhmtnZjh0F92dHotdeEymWQzu77GAwyDHx2Ph6YsdoyLY8XkmUeSWSj16v+KJliloaIekIy59ytdwPG2JuMsULGWGHr1q05imSCagZfy5vf73CXN8/tPc7vvR/34Hk5SJmx142+ieaDpXsARA9zJ83k68RqNpVW4ukvYr9Ri1M+WLoHa/Yeizjm5eS7VqNftO0wLv3LAnyqMwqb9NEadG7REIDk+eIGLz++pvmYVFbIqwsM/1i4I3Ts7wuKcd3rS7B0R9jk4Wgy1mBeTb+c0r/cYRJsVpDyrszdYK0Uuqn7eHvd8Aj6EgCdVL87AthvlIaIMgA0A3BE/t0RwGcAbmWM2QuC4QCvvuyO7x/D+DhO89Ze9+kq+1rm9a8vwb8W7+JO73a+wQ7GXjfO0Bu2awX91oPS9pBrdXy8AaBRtuTQFs96AIDPV+3Dbz9xttWjFUEGfLxC+rARCFsPSkv+SyvCQlf5KNjxVFOmP3j2T1U0YO3GOV69dqHtJ03yCwtphs9WmZtbDfNwdJVzeNwrlwPoRkT5APYBGAfgJk2aWZAmW5cAuA7AfMYYI6JcALMBPMIY+8G7YhtjFN8kXhXrhSvjYp2t/wCOZzBIwLUyVpNE+86dsCmwrouFZ0qcGlHPC8R+nB6m+r9zrASYtp8rIapt38dBWdSavkJIo7fjR2+xYErNVxsPWuxdqzXp2GsBO+WuOF2Lj4ocCvo4BzWzFPSMsQARTQQwD0A6gGmMsQ1E9BSAIsbYLABvAXiXiIohafLj5MsnAugK4FEielQ+NpwxdsjrBwmV1yBAUtzmtGwZsvUT/3etdsBkmjw8GWtwcycfH7f1pee14xbD0RqYrl3a+Qgo+pjdyVjv+lt8Oi5PedX9i0jtBICI4wC/VwygMvNwSPr7DWznTtpa7xpb5XYRo4+F/o1P+3ItmGKMfQngS82xx1R/VwG4Xue6ZwA847KMtgj3mcTELHTScNprmjfMMkxpdtTtopFk9fBQsLvBiOOn0bnQrnvld1slp4Jym5toJ6wFeAR9lEYfPTekaPT2TDf8Gr1h2YyOmxRDr4xWcwtqBdKNC3cy2uhTilAkPK1Gn0SaUQiDnmIk6K0EudGtE7KVYAwwewq9qnT62Hr1ZUdwAcCM5ZKj2hoDGz4vXjadl3kRkWokGcbJgil1CASvMSuFXpNGL8SKTpSKb5PvBL1Cokw3boSqUuSWjSMFfdgWao6RxpvAnfDigrE259B0o3NMu7F5Kr3sXOF/TZ4orLlrVXpEHScdjd5yjwYvNHoHDRIVGI3p+efzX28HsfGIC8a/tRSbSit1z5lV6IrdR5E3eTa2yZ4UvKzfV4EPl+2JvI+dDAwKpV048t2WMhysrLI0UbjV6GOhUXmJ3ZeissqZx4ueYOLZ2DwWxG1qyabphqC/8jqk0UcIevN8lSihrkwhRsdNbq43StPa6PWuDu3R7MLzIt42el8JerN452YV+t810uTn99sO29ICr3p5UVT8FS++0Nqy7q+owphXfrCM6eLORu+u4PGw7xs/P/N0Rkbv/dVOxnp1P72FfWqSyeqmrpeIyVgdrxu1wOR9BC/m1ezUl97Eq/aQWX5eeNgJjd4ldhostJk2ua94W19oAxXmwZnRsXUOcGn0+gm4V8Ymk1TRwfNJV6P76OSoda/06p48y/7jAZ8qoPnY6YTH1vOj5+1XWvOYHQwn6k2u0QsNEr3i1jgHV3NfLOKfmONbQW8HpW3TiNxPXNq53Oa9LDV2g/PxmIxN8m+EKfuOncYd/1oeXtzEodF7RZqFSm+lONj5Tpil5RHGWoEeMt0AmLZoJxZtO6y7BwJvzW0vOxmx+MqMi7poI6zYRyvUifjCHyuHXNnoHV/pDN8K+pCbJUcEx6BKo3c7HIvlXpaWWwkaHFd3SCcBznhIpJx3+5H5y7wtmL/5EObJy97VVaTI4YAHM9p6wtTKdGOdp7vrQ/mY3oNFpSGENwkJMoanvtiIW95aqtq+kr+MWelhMaS4pVrRPrcBVzpT90qdk/bi6HMnjcLtane7+FfQg78ilRRE5HpyxJEfPbdpxeie5ufVWsozszfppik5ehrbHexiH08M68mi/oj4PnDhgVE4bbosuWoNrl+99xiunLoQVbUc0Q51sjAz3TDGkmKkxAw7mJkfvSQFV+89hsdnmW/4MrhbK9tl0vOY0cPU9KIR1Acrq6PiYUU9saq99D4K3GtWDPKPFb7bYUoh2kvKeCgZttGTexu9m+stxuFOBZ26Lqb9sFM3zcJthyMms+0+hlSHibM3W5kwnGxuIeVLAJihRr9aDqS2+YC1x5ZeCcwEfZBZ9yevTPymc1jyv8tUkSqJ9O8dFvTS75+9sSRq20ItTrxXtOVdv9/+egU9jf79pRovuqgPimp0bDCZyxVXn0X+G2v8q9GbfPG1lRsMBVVyZneb+k14I+JYtlvZCX37ZWj0YjgZGwcbfczvILWpXlx3S5MWszfRp66vdPmttfpQZHDYYPS0PTOhEM+FbgwM324+hBW7j0Sfk4vx4w6VoAd0F0xpQyBkp0eLmJpAEJ+v2heqDyfPqa3L/6zeH1UW/QNh7Izy9PLUXXBl+1mE6cYVUVq76m9tY7i10b+g2iE+VjZwwFhrtHavtH8v7ZZnycD+iioMmjIf8zcftHUdkbmg1tt2UiFso3ffrvY1endbW9jl9n8tx7V/jw5GZ1SGsNdN+LzywVO0+MyMaBEz9ZtteGDmaszbILWjE0HP85pZha1w4wdvdP3JamsTHqA2LbsqAjf+FfRa043aCyDKrCNBZG9rMC/Yefhk1HDRCKuiGZ128iJ9ZjOUcTyrbf2+yEVx0nDZWGASCHU6gnoux0Y0ileM1YjAbFN6Bb06MveEsczSFqb5mZlu9M4Rhfze1efbNssBIO2PCkROtCoclGPJV5yWAt85Ebiz1ugH/lNX553Ti3Qf679r9mPKnM1cAcx43LLV3DF9uWWe6nzj9dr4VtBrq1D9S9tA6o0P3Crk6qz/XbTXOKHMom3udtQCpBDCP+4oN/xIxdITSCGemmf0va3R0+jveW9FxO8dh0+gti4YabpRJmMtNHrz0LlKOaPzsNToPazWv361FZsPGKwcd5CfnkafKQv2XeXSiDBLR6PXrqj1sn+qs/p+a5lu/d334Sq8/t12TkcN4zR65V6h2XTdOF/5X6HR2yMqGJH8U8+9Ulu3yrXSi8VX84sMVuEyMBw5WYMFWw7hNx97uwGEUdkWbjuMcW/+iKMn9TfW9ktQM6dIphtrQfzqt9vx/NzNEX0lZKO30Ni59hjVaQYz034sPtA3q7Zm5EW33zEW4UevOgwg7HWjJ+hnygqQ8nyxNHeq2VEW6VXG4zGr70fvfG5BlUlc8Y+g106+Kv8azIxDdV7pZ4Eg4365xk/Tf2GCDLht2jL8/G2+IZwdrPpVlYGwcWOOYoyFdlMyTycJw7zJs/HneZsd388JVs+XRsRtY1+x+6hmclF/Mla7X2y1hWeJWdmMiMUH2ihPHq8bo2PqqlkibyuofFczdUw3Ch8s243yE9WePmeUE4aqpF+uK8VylecQ14Y8JueMPlBrS47pHtcrl/Cjt4nW3hbdCOHfEav2WPhMMMiv0RtPfDJsO8QfHM3LZubxo7fLzOV7MfzF77nSfr1Jmlz7x8Kdju/nBKunI/DXQVZGmsZ0I/2rndh798fdEb95BL1tG33QXAAHgyxqn1ynqAXi9a9bb9MXZEzXdFMsr8VQ6lBPo1dYv68S989YjXjFizteHYgwrfDtvBaZJtKPXv+aA5rVvadqooPrCRu9Q4wmWPXOM0065aNgR6M3LIdOWbzCKttYhCnesF/fpqvHPe+tBBC/obgaU99lC68b9QxeVka6riuuVZtW8yyYsvlaW3ndvLVoJ1d/5bmv+vmW7woLw71HTmGNjoYaDFqvAQD03SvVlJ+s8VSr1U7Kq7M+URWIMJXxmPNMNXqDch9XRU1dW3IMPR6bZzjxL2z0NrFaKadnR5T+ZqEGf/K/GzHsrwtclcNtw5l1eqdeN3GJLKm6hZ3t2Ly6t9ktCfx+9N9vLcP6feHFN2YmQDU8Gv1XGw+izxPzuFbRAuamG8YY1yItKa3qb64rwlz8/Le6G6AHWThiqL4JXzqYkW6+vsDOaIsHs3Y6UR2I+Dg52UtZjVE/P14VnitTNp5ZqHG6CPUr4UdvD22jvb90N+qCDNvLJFuqVriH/tZcyxPDvPujcwzPMcbfdHrav7mt1FmniPdkbLLN/ZINGz0gacoKZcelrQCtZAJPHf9x9iZUVgUiFn2ZheY1Wxlrp4550tptssiPR/TV4bUpFoJeJ5CYl6hzPl4ViND4rRbBzVy+B3o1Ex7l6V/PI0OsAhF6jW8EvbbNvlhbitKK8AulFe4KX288aHtTiSoTVzq77abV7syHiuZ5Gb3Q/nevZJbLzu0IEzPBZQTXKkvuEsjpTe558HgVKqv0vayi72vfFm1FpI1e77z+dZ9r1meQB6HBzVA/V21dMMJ0Y9UnHv5knblGbyAGrEI+qB1A4vXW+CbWjd6LZjRkVb+0v3x/JTq14IuEx4OdTrvnyKnQ0u3w9WYqvXnmRi/0iWpnOy3ZwWhnr7hgUedWK2O16Fl5LD+yHPnyTMaqzSRBZpzvwGfnc9wxnI/XBA3cK9Xn9Xhg5uqI3wRCHYvPXpeBOhYxwuDpE3op9GLuq7FSCmYuD6+vETZ6m+hV7v82HtQ9r01aedo7QWhHs/1m06GoY2Z9z+kLy7uIww16S+djyQv/2xLx28wEQrAXZlivmq3ala9t7DXgEa8mKnlMNzZvwxhCk9hGwb0A6wBfTuNL8RIxdxRkGo3emadU+Jz+Sas5qoXF6uCBwkZvC73KffqLjaG/731/ZehvbQPxTo7xwBi432etpi3FSTS+2OqFSDbbeKx44autmDq/OPT7w2V7cfhEtWF6IrJlujmuYxKxnAjnqHy9IpjJwdFTF+J0jfu+qe5TXsUXlSZjjfd6qAsy0zZRCNSxuHlpBYLBiC8Pz7xN1K5aCD+vUbH1wm0kGt+Ybqzes6Onwi+vNinvYpcGmelII+CkycvnVjuxu3BFTSwntZKZF7/eanpe8rrhr5uSo9ERMoNBhrzJsw2v4ZrwdNA3zPqal9gtWpCZa+tLdpSj8Jmv0bxhpmk+G0sr0YFzExEezB6jjsGWjR5w5nVj5zUUphub2Jpsc1i5HZo34JoQjdVwLBSTx+AFq++hDozwwrPDC68bfXtv7GP483SLI6dqbOUp2ejlv00qR61gGeF0VTEPkaabYISN3mgzGaPro885s9GrN/iJ1xvrG0FvawswhwKRXFzLC89crJFoiEXZkmTvapeQachaM/u+gqXXTQzs4NI17tuUJwe1aZOH9s0ahOrN/fabDJkW/vZeIE3Ghn/z2OhHT10Y8dvIqUONlVKhXv8gQiDYxGu/Yj14Jo6sFu9YYZa/ojkZaYFu9rA0wi+DBLcavdULyaXRO6hML6qf575qV2TA2l30zJYNI/aMdUOgLhiKEuo16tF1XZBFfNSd7DEQscOUwftmZ8Gg0Oht4tZPmgcCcQ3h3TSe2bWWNnq/SGWPIQ82fbe6/M/ztlikiN9L7cV97Uz8u9VKA0GGjDRvRJFZO9exyPUWTrcwVK4ytNHbMtLbLoIjfCPo7WgVbjR6q87htt1chUAQphtdGHP/ETxUae1BYl2Q6ENW9euJ6UYtlI3SaH5b1Ze0SI240loRCDLPNHqzLUQl90p7fvRR+ZvcS30f/vyE6cYW8RD0fHk7z5zIamWsed5ugpfpEe/dtmIHf1RSI+ZusN6NyroU9vHCkYonC231WFYXC88VORGYagJ1Qa49d3kwClcOyII+LfK3XdTZG7pXRg53TPObt/6grTUeTvGRoOdP69h0w6HeutboTdpcEVbxmoz1i7cmY8nhkaS0n52Pjicusw6enWfkahYCwQ5BZh38jDsvk/fHG40+0uavXwb+fGcW7cVrC7bbLodduAQ9EY0koi1EVExEk3XOZxPRTPn8UiLKk4+3JKJviegEEb3ibdEjsfNCOH13eLoiY+60R7OPkNUQ2XtBn3jh6AUM5qOdeJmnlNpU9z+re3vRBk5yqKyqxciXjPchKK04jSXbpU1GvPgYeWWj174/6ndRK9h5vG6i8mfWH2xljjcYZFzupfuPRa/b8BrL2iWidACvAhgFoAeAG4mohybZnQCOMsa6AngRwHPy8SoAjwJ4yLMSG2DPdONUo+fJ21HWXNe/96O0ibiRJiIEvT5SEKnEP0swJCDsX+OGYyphw/tNW7j1sGkY5B93HMHSndJuTV4Ieq9s9KaTsZqTbk1ORpcrGv3z87bgha/MF/MBwIzl1ntLu4XnMzoAQDFjbAdjrAbADABjNGnGAJgu//0xgGFERIyxk4yxRZAEfkyx83F2rNHzCHq4M9+4udZr98okkI2ewJBc8w1q4W3lw++F+XbPkVO2r7EzwerFx8grG330VoJhApqN32sDTmz01qYbZc3G3PWltvOPFTyCvgMA9SenRD6mm4YxFgBQAaAlbyGIaAIRFRFRUVlZmfUFOsRDY+NZWOPeXuk8A6HR6yPZ6I3Pf7yiJG7lAOKzuM8tJ21EPPWijPHQ6CurAnhw5prQ70PH7euf6uytFkwl0xwXj6DXawHtI/CkMYQx9iZjrJAxVti6dWveyyLItYip4QU8Gn2QMVfCPlaLrZzl52l2CYMxlhRxgJTmUTdTPNwrnfDM7E3cab0YdWRYbDnIi9VOc2qcjHR4HGpqQ4I+8X1Ogad2SwB0Uv3uCGC/URoiygDQDMARxJHOLRthyNnOPhJAZLAjI/gmYx0XQbrehfHGa1mWTB3VDclmurFTlDh43rnGyaSmFu9MN1FHDNMqu4fZyl/1hhq9H4qNPom6HJegXw6gGxHlE1EWgHEAZmnSzAJwm/z3dQDmswS8WW66CpdGweVe6VrSO8ZrrZUFvQtrm1BMTDfx7KaKYEgF040dvPgYxWrBlBlOgqmpn9VoHmNR8WGs2nM0Lg4ivFiGKWaMBYhoIoB5ANIBTGOMbSCipwAUMcZmAXgLwLtEVAxJkx+nXE9EuwA0BZBFRNcAGM4Y26i9jxe4cZPLSk+z3AKMCw98ih3fOgY2+uQXM9YwmGhfcXzAkNeNg2t44HUW8BovNPpY2ejNqs/J+67eu8LMX/6nry3GGU2zufMNBGMb2I0rHj1j7EsAX2qOPab6uwrA9QbX5rkony2sNiI2g6uSOV469zFVnGfgtUafCtokD2Y2+nhq9HpDfqteZ2fxTaJGX27dFAEg3aPFDHb6bI2DocjJ6oC8QZDzPZz1CNQxZKbbLg43vlkZC7jr6JkcphuednMjqKXFGI4vj4GN3h+mG8lGr38unhp9eDKW/6Z2AizyrNw+xrGAxy5eKBgerZeK1uhN0lY72FnuVE1dOKiZxXPbqZbaWISeVeEvQe9Ko+cQ9BwN58rjBi796D3WTpNpAtMNZiEQEjFqsbVgyoa0iFGkX0s80ejjENRMixON/lRN2O3U6v1Qn1+155hpWichk+3gm60EAZc2+gxrQe9013huXIZPEO6V+pyurcPxKn2/8EQI+sgQCOad1p6NPjGS3hON3qOy22lOJzb6lSqBbWfXsY2llaZpYx3YzFcavRulIItDo+eZdHIjOMxMDDx43Vf8YqMHgFe+LdY9ngj/ejv1mgp7DHih0Xsl6KOjVxqXzW2xrWNP8efFs62hG3wl6HlWrhqRk8kj6K0bo9aF5457G733k7FOhrepRKyHzHpELJiykdY6YyelcY+tjTYM8M7rJv7usk7Pq6mLcT/0l6B30VeyOaa8eTQXNxsdM8ZcTuZ621nW76vAh8tiH3ApkXihjdolVmGKa+qCEe5/8SLgwUSiV/ML2qqNpdy3ytvOvWuDQXyxdn/M2s9Xgt7N8C+HR9BzfHXdNJRb043XMmulxQSSH0iE6SYQZPhuaxne+G47dhw+aZrWbvnKT9a4KZojkil6pbYksRT01l43/DdfvL0cEz9YhT/aCD1hB19NxrrxBczmmIzlabgql6YbN0NPz1fGpoB92A5E0S++F9qoXX7/+TrsPcIXgzwV2iCZvG5S1XRTfkIKxxCr2PRCo5fh0uh5TDduNXrHV3svFFJAxthCr38Mfu7buJeDV8gDQMnR2G9K4RYv5jm88hiyMxnrFqv3w873T6nDWDlO+UrQr9571PG1ORwaPY/G7Mp0wxgWFx92fL3XHhp+ca9U8Gr1ZTz5dNU+rnQtG2XFuCTGrNtX4ToPr9rGzkfULVYaux3FSyyYsoGbRs5Wed1kphP6dsqNSsMn6J032KmaOjz6nw2Or/daMCfCrOEVZ5/ROOoYETCufyed1KnPHYPzE10EV3hlutGy02IOxA1W8qDWxkgn1t5fvhL0bsjJCJtujFbJ8gj66oBzjZ5n2zEz/u7xJsOeBHlLEHptlUaErm2iPwB+IJYBseJBrAZbj3y6LjYZw1vF6q1FO73LTAch6GXUNnojQc+j4e4qt7+ZgdeM7NnWk3zcuIommoZZ0X4GiQoREA/SvQoWkyC8ikevxauFWHqkwkS5Qmr3Dg/JiTDdpOnOtPBo9F9tPOhpuZzQp1MzT/JJ5cVSzRpE7ziWlkYJCxMQa2IlKBV+PbRrTPOPlemm4rT3QdwUkmHXMl6EoJfJVplusgyGwanSsF5NbKWy6UZX0BPFVavncdn1ilgJSgWeWFBucBeQMD6Nqq1jJ+KgeRy2PNVDCHoZtUafkZ6m65SVInLes+GqlaDXE6bJAhHwwOXdIo6lkbOlFo2ynAUKj6egj7VGb0fQ8xblo7sHhv52o5zEa5SmjYf1yUr7m8o3ybF6Z2JkwopJrilIdsRkbGoP773yHbYS9Iogi7U26YTauiAeuPzsiMnXNLJvunni6h7o3dGZKYxnbYZXxFoH4QnjrfCTvu250qm7jZsuFC+3WaOP3aXn8O9VnSjZIgS9jLoRM9PTUnqxkB23LjOqLDyIFJfUZDRpKR8pdcCtNAfSxI22GGstW02sw9zy7KmsPK6Z9t9N9eFV162TtlGIl6JhNEJrYOODbueD6SW+EvS/GXGO42vVjZgRx69upxYNPM+z1qOX/nSNhaDPiJ/GahflY6deRJZG9jVHIiDL4XPG8/tXE+uNKywqrnvbJhjavQ0Ac2HWUGUGU2fpRiuP1/fU6APWJIc/koyV4nD7oDw7ReLGV4L+7iFnOb5W3YjHqwIxXTqtcE2/9vjfA5d4nq9XbpFGm3UoqD+OeS0bRpwbkN/CkzI4JaTRRwh6cuSwPbhrS0dlcBJ3xenQPuYavUqa6gk2SbhLacw0erWNWj2X5EYrj5dGb/RcrZvwbwJu5ZI5qGsrW2XixVeCPiM9DS0cLgVXayG74+QL/9K489DA4USfGVaaOA/paYR9FgGW2qg6+NUauyzvuzfn/oux+emRtstnxZ/G9gIAqJc+pJH9HQsIQMtG/C+yGicaawCodgAAEm5JREFUvVOzmxeBxfRWgyuohZyedp+ZTlymm0bZao3eG9NNvNAbwRIBPdvzz+EkyszpK0EPACsfvcLRdVr7m/rDe3E3vq9sGxtf9ljihW2Yp0O+eEM/AMCNAzohQ7NgRxGpd19iPso6t11Tz23ZTXMy0LVNEwCRz5GZTvYVeiI0dehdFE9zrBfmOiMbdI92TUNmGUDfXl9aURWqW7Pd2hpnh+tS3RYdm9s3YZ7ZQhpF2hWeNxQ6C4Oh9wHLSk/Dpee0xq0DO+OSs60nZRO1a5vvBL0Rgy2GRG78hO8YlI8591+Mbx+61HEeTnjxhr66xwdxfpjs0rdjM1wmexjkZKYht2EWiv84Cn/6aW9c0eMM3WvOaJJjOcry2j1O/SqpNd02TXNCHyDej3dmGtmywapNWM0b2h9dWvVTI2Ip6L+4b3CEyUXvw8xYWEPPSk/DnPsvxh2DouPvqOvyZHXYNNi2aQ4W/vYyW+U9o6mkWNmR80M4hLER2TofsPQ0QsOsDDw1phem3zEAvTo0Nc0jUX4L9ULQ/3pYN9wxOM80jZmg1wqi128piBBszRpk4tx2TSMmmrzg5xflmZ4feo6+cI1VgKS/jTsPb95aCAD4+UXSS5yRngYiQo/2TXH5uZLWl0YIuTUyWK9O5FHox/STTENX9WmHK3u34y6z2ibaukl2SIvk9ZRo0zQbeS0bcaX96sEh+OvP+oV+n9E0Rzed2QT8wyO748dHhuGqPpHPaOXLf0G+NI/w2s0FWPb7YVzl1WI0ua41q+h9wKoDdWguf9AzM9JwbrumGN07OhRHh9zws7dR1U9+q0bo1KIhvrhvsGU5L8hvgaI/XB4aRdrR6H9W2BEXnOVs/ihHboP0NMKIntK7p51ErrYIavj0mF6O7u2WeiHoJ11xtqVbk1qbydK4V7ZuHGmSKejcHP+4tRB/uV7SqPNbS4LAS830tyPPwRM/6Wl4/qO7B6JZw0xdDcJqYs5IUE4Z29v0uvQ0QmZ6Gnb8aTQeHhnt4aS8eK/dXBDyXGKMoaGFUCUirHlsuGmaBy4/G7umXIlXbirAsHPbmKZVM+3n/UN/d8xtgHbNJOFiZo9Wc0bTHLRtpi+wteS3aoTzOzfH5qdHYvyFnTF5VHfddL8bdS7yWjbEszr1nZOZhrbNcvDyjedFHL9MZTq5UCOoXru5AEPObo0NT47A6N7t0KZJdHm7cQRz03bfKWN744NfXBCVzmqElmOyvqJ7uyahv/NbNcLGp0Zg57OjcVZrqXy9Oujbu1/4Wd+QcnVuu6Zo1Tg71MfUnlUv/Ex/lAtIzhojerbFT8/r4MjM2kk2LwUZw/Ae0kesuaYutI4QSx4ZGvF7sGok+cFdkXWrV9deUS8EPQDkNjDvnGptZvXjV0RoI0+N6Ynnr+0Tsj1mp0tpry3ogI/vGYir+/BpmDufHY2dz47Gkz/piT4Wi3CsNlxWvFo++9UgLPtdpAan3VF+RM8zIlxPOxjYQ9WTSv93xdlR5xXvAqOYMenyi1dbx0Lx0Zs2yMRn914Uqru8lg3x3LXRAq5Zw0x88suLMGviIPyssGPoeMtGWVj/5Ajktwpr1QVnNgcANM6WzABa00pTlZlBLdB/eWkXXHpOG7x/1wW455IuEddMvCw6lkvzhpnoIgugp68x1sRyG2Zi4W8vC9muczLT8fQ1vaIE4q+HdsWuKVdiVO92WPCby3DjgDOjPq5Ky2nrV/EiuvSc1vjgrgvxT3lkBQCj5Q93o2x9E9PC316GryZdgrVPDMeaxyM/qN3bhgWvVjPu0b4pLuoSbUpq3SQ7SllonJOBOwblY0TPM3CdbAPXLhgbW9ABg7u2irDHN8zKiHrWHyYPxbntmmqu7YhzzpDKqtSrorwpK7Qfu6oHxhZ0xLY/jgpp3H+/uSCUxyOjz0WmPAL9732Dbbtjd5bNcowh5ETRsrFW0Ec6QrRrFv2uLfztZfjsVxfhoq6t8MkvB2LseR3w6a8u0q1rr/C9oFcETK5FjImOzRtg4mVd8e1Dl6JhVgZ+dWn4xW+UnYGf9e8UCvKVmSF1TCJCYV4LS03+krNbY/VjV4DklZm3XZSHWRPNh6haL4oVf7gcr91cgAcvPxsXdQm7+2Wmp6FN0xw8PLJ7yHTEGAuFdNj57Gi8Mb4Q96oE2S0XdMYb489HwZmRWm0LVae9b1hk+ADAeqXn5JHdMeTs1hjavQ3uvqQLnh3bG9cVdETXNk1CppdfXtoFN/Q/U/f68zs3R5+OuXhqTC/8+bo+eOu2Qix+ZGhIoCvktWqENY8Nx7LfD8NDw8/GqkevCAn7J67ugQ9/cWFEeuWjlSubHAZ1bSXbVtPRrEEmfn5RHu65NCz4Z0y4EFueGYlVjw0PPfP4Cztj15QrsWvKleifJ31o2suafl0dQ6cWke6lQPRi9pG9ohWCcQP06wKIXHGp2OBbNMxCWhpZtoWiSPzj1sJQ2ZrmZEaErfhh8lA8dnWP0G+lz11b0BF/v7kAfTpG9o+bLpDKekWPM/DqzQX4/jeXhUYlbZrkoGubxnhjfGGovbq3bYJHr+qBQbJ76sXdWoGIMPeBIVj6O2PzUofcBrqKznlyf1VcEJW5gp+e1wEA0E3egyAzPQ1TxvbB3UPOwuVGc0dNc3DvZV0xIE9SmGZNHBRxfz15MfCsVmjVOBvPju2NE7Lrccfmke2ut5p8WPfIEWinFg1xnqysnN+5BV64oV9IeYkV/tozVsOuKVeG/tYOsf42rh8K5UZulJUOIsJDqi+8mbuXmVdBz/ZNsWF/ZcQxorCQ4UXp6I+M6o5z2zVFy8bZkubWGwCihfAvL+2CGwd0wsvzizG6dzsU5rXA7vKTuh+htDRgRM+2OK9TLuZtOBDa7ETRwrVzDX+5vi8OVlZZlrlTi4Z4544Bod83qoTYmH4d8O8VJSFbshk5mem43sIzopn8Ik4cKtXF/x4cgh1lJ3X9kO8b1k33w7XqsStAoKj5mcLOzU1Xgk4c2g23TVuGjs0bYn9FleEKYkUx6NK6Eb75v0tNn0ePf9xaiDv+tRwLtx1Gn465+HZLGa6WP5gnqs3XOHx090BUB4Km8Yi0AvXXQ7uiZaMsPDK6O1o1jjZt/PGaXhh/YeeQtn1my4bo2LwT9h45hVsu7ByVnohw5+B87Cg7gR+Ky0PCsXF2RtTHW8tpnZ3ahp17BtY9MTw0MXzpOW3wv40HcW1BRzx4+dkRrsrNG2XhkdHnApDas2i3/u5z79w5ACeqAxGm2tm/HoyauiAG/PGb0LEXftYXvTs2Q9EfLgcArNl7DIDkcabmjfGFePuHnVi99xhKK6R35vXx56Pb7+eYPm+s8bWgV6OezBqQ1wJj+nVwnJeZEPjvxMGoCtRh0sw16NOpGZ6fuwUHK6u58r3wrBb4cccRDO3eJrRj0N0aE4MZuQ2z8OhVkobWIbdBxMQXIE16BlnYLNCmaQ7GD8wLCfqczHQsevgyNNLEcr+2oIPr+YfB3VpFfHh/N7o7Bp7l3VC1XbMGusNkM7STjy/feB5e/2675QIc5bQysntouL4JoENuA/x6WDdcf35H3fN6nKGyr2emp+E3I87Bit1HccuFnfGgypxWWSVNcA/trj9fkZOZbqj1z5hwITaVSspIO9X8Q2Fei5DyowcRRZlU0tIIvx2pPxeh8JO+7fH+0j04vzP/JOgpg7Ugau+fGwd0woieZ6ClzkdJzfu/uMBw5zd1Pd04oBN6dWgWUsr65zXH8l3SB6KpJhhZ30652PbHUVFzfwPyW2BAfgucrA6E7PWJCnugpt4IeiLC9j+NliIYcgqttk1z0C43/CJ8cNcFmLP+gOk1abK71evjz0cwyHD4eA2us3jRr+7bHhfkt8DYgg7YUXbScELKLQ+NOAfPz90SNTn6xNU9MH9LGYDIoejtg/Lw9g+7YhIdcMIQ/g9YvLi6b/uohV96dJLr6OJurfH+XRcapiMiTNKZ69Cy/skRyM5I0xUIfTrmYuNT0QvKFHs6zySrlgvPaokLz5JGVhnpaZh643no2d7cLdANF5zVMuIjz8P5nXMxb4P53g5EZCnkAemDzhOu49mxfSJ+/+v2AVi/rwJv/7ArYhJVwUyAN8rOgHqdXbtmOSENPxFQsu2SUlhYyIqKilzlkTd5NgDY7lz1gVM1Ad3dl/RQ+oZfN+tww6HKKtldMzF1UxMI4pX523DPpV242zOVOF1Th71HT2FTaSVKjp6OmGNKRapq6xBkLKZtRUQrGGOFuud4BD0RjQTwNwDpAP7JGJuiOZ8N4B0A5wMoB3ADY2yXfO4RAHcCqAPwa8bYPLN7eSHo564vRWZ6Goadqz8RIxAIBH7DTNBbfl6IKB3AqwCuAFACYDkRzWKMbVQluxPAUcZYVyIaB+A5ADcQUQ8A4wD0BNAewNdEdDZjzH0wFhP0vBsEAoGgvsIzSzAAQDFjbAdjrAbADABjNGnGAJgu//0xgGEkjWnHAJjBGKtmjO0EUCznJxAIBII4wSPoOwDYq/pdIh/TTcMYCwCoANCS81oQ0QQiKiKiorKyMv7SCwQCgcASHkGvN9ukNewbpeG5FoyxNxljhYyxwtatnQcdEggEAkE0PIK+BIB6VUBHAPuN0hBRBoBmAI5wXisQCASCGMIj6JcD6EZE+USUBWlydZYmzSwAt8l/XwdgPpPceWYBGEdE2USUD2lJ5zJvii4QCAQCHiy9bhhjASKaCGAeJPfKaYyxDUT0FIAixtgsAG8BeJeIiiFp8uPkazcQ0UcANgIIALg31h43AoFAIIjElwumBAKBoL5h5kef+CAMAoFAIIgpSafRE1EZgN0usmgF4LBHxUkF6tvzAuKZ6wvime3RmTGm67aYdILeLURUZDR88SP17XkB8cz1BfHM3iFMNwKBQOBzhKAXCAQCn+NHQf9mogsQZ+rb8wLimesL4pk9wnc2eoFAIBBE4keNXiAQCAQqhKAXCAQCn+MbQU9EI4loCxEVE9HkRJfHK4ioExF9S0SbiGgDEd0vH29BRF8R0Tb53+bycSKiqXI9rCWigsQ+gTOIKJ2IVhHRF/LvfCJaKj/vTDnuEuQ4SjPl511KRHmJLLcbiCiXiD4mos1yew+sB+38oNyv1xPRh0SU47e2JqJpRHSIiNarjtluVyK6TU6/jYhu07uXEb4Q9KpdsEYB6AHgRnl3Kz8QAPB/jLFzAVwI4F752SYD+IYx1g3AN/JvQKqDbvJ/EwD8Pf5F9oT7AWxS/X4OwIvy8x6FtKsZoNrdDMCLcrpU5W8A5jLGugPoC+n5fdvORNQBwK8BFDLGekGKpaXsUOentv4XAO0O77balYhaAHgcwAWQNm96XPk4cMEYS/n/AAwEME/1+xEAjyS6XDF61v9A2tZxC4B28rF2ALbIf78B4EZV+lC6VPkPUjjrbwAMBfAFpH0NDgPI0LY3pGB7A+W/M+R0lOhncPDMTQHs1Jbd5+2sbEzUQm67LwCM8GNbA8gDsN5puwK4EcAbquMR6az+84VGD86drFIdeah6HoClAM5gjJUCgPxvGzmZH+riJQC/BRCUf7cEcIxJu5cBkc9ktLtZqnEWgDIAb8smq38SUSP4uJ0ZY/sA/AXAHgClkNpuBfzf1oD9dnXV3n4R9Fw7WaUyRNQYwCcAHmCMVZol1TmWMnVBRFcBOMQYW6E+rJOUcZxLJTIAFAD4O2PsPAAnER7O65Hyzy2bHsYAyAfQHkAjSKYLLX5razNc7dZnhF8Eva93siKiTEhC/n3G2Kfy4YNE1E4+3w7AIfl4qtfFIAA/IaJdkDaiHwpJw8+Vdy8DIp/JaHezVKMEQAljbKn8+2NIgt+v7QwAlwPYyRgrY4zVAvgUwEXwf1sD9tvVVXv7RdDz7IKVkhARQdrYZRNj7AXVKfWuXrdBst0rx2+VZ+8vBFChDBFTAcbYI4yxjoyxPEjtOJ8xdjOAbyHtXgZEP6/e7mYpBWPsAIC9RHSOfGgYpA17fNnOMnsAXEhEDeV+rjyzr9taxm67zgMwnIiayyOh4fIxPhI9SeHhZMdoAFsBbAfw+0SXx8PnGgxpiLYWwGr5v9GQbJPfANgm/9tCTk+QPJC2A1gHyaMh4c/h8NkvBfCF/PdZkLahLAbwbwDZ8vEc+XexfP6sRJfbxfP2A1Akt/XnAJr7vZ0BPAlgM4D1AN4FkO23tgbwIaQ5iFpImvmdTtoVwB3ysxcDuN1OGUQIBIFAIPA5fjHdCAQCgcAAIegFAoHA5whBLxAIBD5HCHqBQCDwOULQCwQCgc8Rgl4gEAh8jhD0AoFA4HP+H/16jJDKLJ8CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "#compare to exponential regression\n",
    "a = x.view((48,1))\n",
    "b = y.view((48,512))\n",
    "c = prediction.view((48,1))\n",
    "plt.figure()\n",
    "plt.plot(a.data.cpu().numpy(), \"r\", label=\"actual\")\n",
    "plt.title(\"prediction vs actual value\")\n",
    "plt.plot(c.data.cpu().numpy(), \"g\", label=\"prediction\")\n",
    "expPred = -np.log(b.data.cpu().numpy())\n",
    "newExpPred = expPred[...,256]\n",
    "plt.plot(newExpPred, 'b', label=\"exp\")\n",
    "plt.show()\n",
    "newLoss = np.sqrt((a[1].cpu().numpy()-newExpPred)**2).mean()\n",
    "oldLoss = np.sqrt((a[1].cpu().numpy()-c.detach().cpu().numpy())**2).mean()\n",
    "print(\"Exponential Regression Loss = \", newLoss)\n",
    "print(\"Prediction Loss = \", oldLoss)\n",
    "print(expPred)\n",
    "print(prediction)\n",
    "plt.figure()\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(totalTrainLoss.detach().cpu().numpy(), label=\"Training Loss\")\n",
    "plt.plot(totalTestLoss.detach().cpu().numpy(), label=\"Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(totalTrainLoss.shape)\n",
    "print(totalTestLoss.shape)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(predictedMean.detach())\n",
    "# plt.plot(tauredMean.detach())\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction1 equals prediction2:  False\n",
      "prediction2 equals prediction3:  False\n",
      "prediction3 equals prediction1:  False\n",
      "prediction1 - prediction2\n",
      "tensor([[0.0004]])\n",
      "tensor(0.0004)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction1 equals prediction2:  False\n",
      "prediction2 equals prediction3:  False\n",
      "prediction3 equals prediction1:  False\n",
      "prediction1 - prediction2\n",
      "tensor([0.0004])\n",
      "tensor(0.0004)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f340c4648>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotY = torch.linspace(0,1,512)\n",
    "LinearY = torch.reshape(plotY, (-1,1,512))\n",
    "NegLinearY = 1-1*LinearY\n",
    "negplotY = 1-1*plotY\n",
    "heavySidePlot = torch.cat((torch.zeros(256), torch.ones(256)))\n",
    "HeavySide = torch.reshape(heavySidePlot, (-1,1,512))\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    plots = torch.zeros((3,1,512))\n",
    "    plots[0,0] = plotY\n",
    "    plots[1,0] = negplotY\n",
    "    plots[2,0] = heavySidePlot\n",
    "    inputs = torch.zeros((3,1,512))\n",
    "    inputs[0] = LinearY\n",
    "    inputs[1] = NegLinearY\n",
    "    inputs[2] = HeavySide\n",
    "    predictions = net(inputs)\n",
    "    for j in range(3):\n",
    "        plot = plots[j]\n",
    "        forecast = predictions[j]\n",
    "        plot = plot.reshape(-1)\n",
    "        forecast = forecast.reshape(-1)\n",
    "        plt.figure()\n",
    "        plt.title(\"Prediction for %d\" %j)\n",
    "        plt.plot(plot.detach().cpu().numpy())\n",
    "        plt.plot(forecast.detach().cpu().numpy())\n",
    "        plt.show()\n",
    "    print(\"prediction1 equals prediction2: \", torch.equal(prediction[1], prediction[2]))\n",
    "    print(\"prediction2 equals prediction3: \", torch.equal(prediction[2], prediction[3]))\n",
    "    print(\"prediction3 equals prediction1: \", torch.equal(prediction[3], prediction[1]))\n",
    "    print(\"prediction1 - prediction2\")\n",
    "    print(prediction[1]-prediction[2])\n",
    "    print((((prediction[1]-prediction[2])**2)**.5).mean())\n",
    "\n",
    "    prediction1 = net(LinearY)\n",
    "    prediction1 = prediction1.reshape(-1)\n",
    "    plt.figure()\n",
    "    plt.title(\"Prediction for positive linear\")\n",
    "    plt.plot(plotY.detach().cpu().numpy())\n",
    "    plt.plot(prediction1.detach().cpu().numpy())\n",
    "    plt.show()\n",
    "\n",
    "    prediction2 = net(NegLinearY)\n",
    "    prediction2 = prediction2.reshape(-1)\n",
    "    plt.figure()\n",
    "    plt.title(\"Prediction for negative linear\")\n",
    "    plt.plot(negplotY.detach().cpu().numpy())\n",
    "    plt.plot(prediction2.detach().cpu().numpy())\n",
    "    plt.show()\n",
    "\n",
    "    prediction3 = net(HeavySide)\n",
    "    prediction3 = prediction3.reshape(-1)\n",
    "    plt.figure()\n",
    "    plt.title(\"Prediction for Heavyside\")\n",
    "    plt.plot(heavySidePlot.detach().cpu().numpy())\n",
    "    plt.plot(prediction3.detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    # print('Test Accuracy of the model on the test data: {} %'.format(100 * correct / total))\n",
    "net.train()\n",
    "\n",
    "print(\"prediction1 equals prediction2: \", torch.equal(prediction1, prediction2))\n",
    "print(\"prediction2 equals prediction3: \", torch.equal(prediction2, prediction3))\n",
    "print(\"prediction3 equals prediction1: \", torch.equal(prediction3, prediction1))\n",
    "print(\"prediction1 - prediction2\")\n",
    "print(prediction1-prediction2)\n",
    "print((((prediction1-prediction2)**2)**0.5).mean())\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Three predictions, side by side\")\n",
    "plt.plot(prediction1.detach().cpu().numpy(), \"r.\")\n",
    "plt.plot(prediction2.detach().cpu().numpy(), \"go\")\n",
    "plt.plot(prediction3.detach().cpu().numpy(), \"b--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
